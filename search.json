[{"authors":["Ravishka Rathnasuriya","Nidhi Majoju","Zihe Song","Wei Yang"],"categories":null,"content":"","date":1743379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1743379200,"objectID":"ef84691b1b2cb70b829306f0fc2d4974","permalink":"http://youngwei.com/publication/gpubug/","publishdate":"2025-03-31T00:00:00Z","relpermalink":"/publication/gpubug/","section":"publication","summary":"General-purpose graphics processing unit (GPU) computing has emerged as a leading parallel computing paradigm, offering significant performance gains in various domains such as scientific computing and deep learning. However, GPU programs are susceptible to numerical bugs, which can lead to incorrect results or crashes. These bugs are difficult to detect, debug, and fix due to their dependence on specific input values or types and the absence of reliable error-checking mechanisms and oracles. Additionally, the unique programming conventions of GPUs complicate identifying the root causes of bugs, while fixing them requires domain-specific knowledge of GPU computing and numerical libraries. Therefore, understanding the characteristics of GPU numerical bugs is crucial for developing effective solutions. In this paper, we conduct a comprehensive study of GPU programming numerical bugs (GPU-NBs) by analyzing 397 real-world bug samples from GitHub. We identify common root causes, symptoms, input patterns, test oracles that trigger these bugs and the strategies used to fix them. We also present GPU-NBDetect, a preliminary tool designed to detect numerical bugs across six distinct bug categories. GPU-NBDetect detected a total of 226 bugs across 186 mathematical functions in four libraries, with 60 confirmed by developers. Our findings lay the groundwork for developing detection and prevention techniques for GPU numerical bugs and offer insights for building more effective debugging and auto-repair tool.","tags":null,"title":"An Investigation on Numerical Bugs in GPU Programs Towards Automated Bug Detection","type":"publication"},{"authors":["Dezhi Ran","Zihe Song","Wenyu Wang","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1736467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736467200,"objectID":"c310dc29d96067cd7cf574e1bee49925","permalink":"http://youngwei.com/publication/taopt/","publishdate":"2025-01-10T00:00:00Z","relpermalink":"/publication/taopt/","section":"publication","summary":"The emergence of modern testing clouds, equipped with a vast array of real testing devices and high-fidelity emulators, has significantly increased the need for parallel automated mobile testing to optimally utilize the resources of testing clouds. Parallel testing aligns perfectly with the characteristic of rapid iteration cycles for mobile app development, where testing time is limited. While numerous tools have been proposed for optimizing the testing effectiveness on a single testing device, it remains an open problem to optimize the parallelization of automated mobile UI testing in terms of resource and time utilization. To optimize the parallelization of automated mobile UI testing, in this paper, we propose TaOPT, a fully automated, tool-agnostic approach, which improves the parallelization effectiveness of any given testing tool without modifying the tool's internal workflow. In particular, TaOPT conducts online analysis to infer loosely coupled UI subspaces in the App Under Test (AUT). TaOPT then manages access to these subspaces across various testing devices, guiding automated UI testing toward distinct subspaces on different devices without knowing the testing tool's inner workings. We apply TaOPT on highly popular mobile apps with three state-of-the-art automated UI testing tools for Android. Evaluation results show that TaOPT helps the tools reach comparable code coverage using 60% less testing duration and 62% less machine time than the baseline on average. In addition, TaOPT consistently enhances automated UI testing tools to detect 1.2 to 2.1 times more unique crashes given the same testing resources.","tags":null,"title":"TAOPT: Tool-Agnostic Optimization of Parallelized Automated Mobile UI Testing","type":"publication"},{"authors":["Ravishka Rathnasuriya","Zijie Zhao","Wei Yang"],"categories":null,"content":"","date":1736380800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736380800,"objectID":"63ad3b8755767d1d3b7eb545f4d701a5","permalink":"http://youngwei.com/publication/codeimprove/","publishdate":"2025-01-09T00:00:00Z","relpermalink":"/publication/codeimprove/","section":"publication","summary":"Leveraging deep learning (DL)-based code analysis tools to solve software engineering tasks is becoming increasingly popular. Code models often suffer performance degradation due to various reasons (e.g., code data shifts). Retraining is often required to address these issues, but frequent model updates are costly in labeling and deployment. In this paper, we explore an alternative solution: Adapting the program inputs to the code models. This can be achieved by two steps: 1. input validation that focuses on identifying whether an input is an out-of-scope input program that are beyond a model’s handling capability, and 2. input adaptation that adapts out-of-scope inputs to become in-scope inputs. Validating program input is challenging, as current techniques focus on continuous inputs such as image data and fail with discrete inputs like code data, which have unique characteristics and are processed differently by deep learning models. Adapting out-of-scope programs is also challenging due to their vast search spaces. Therefore, in this paper, we propose CodeImprove, which distinguishes out-of-scope from normal inputs and converts such out-of-scope inputs back to in-scope inputs through program transformation. In particular, we propose a validity score metric to identify out-of-scope inputs and leverage genetics algorithms to apply semantic preserving program transformation to convert out-of-scope inputs to in-scope inputs. Our experimental results show CodeImprove can enhance upto 8.78% of accuracy, and 51.28% of relative improvements in three code models on two SE tasks. Additionally, our input validation is promising in detecting outof-scope inputs (AUC score of 0.924).","tags":null,"title":"CodeImprove: Program Adaptation for Deep Code Models","type":"publication"},{"authors":["Zihe Song","S M Hasan Mansur","Ravishka Rathnasuriya","Yumna Fatima","Wei Yang","Kevin Moran","Wing Lam"],"categories":null,"content":"","date":1736294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736294400,"objectID":"aad3bb40f57627ee0777d8a967113ff9","permalink":"http://youngwei.com/publication/mobilesoft/","publishdate":"2025-01-08T00:00:00Z","relpermalink":"/publication/mobilesoft/","section":"publication","summary":"Android User Interface (UI) testing has emerged as an important and prevalent research topic due to the ubiquity of apps and the unique challenges faced by developers in this software domain. One popular topic of research that aims to facilitate both manual and automated UI testing and debugging processes is record and replay (R\u0026R) tools. These tools allow for the recording of UI actions to facilitate the execution of test scenarios and the replay of various types of bugs. R\u0026R tools typically support three main settings: (i) UI regression testing via R\u0026R of feature-based execution scenarios, (ii) R\u0026R of non-crashing functional bugs (e.g., in crowdsourced settings), and (iii) R\u0026R of crashing bugs. Despite the progress made in research related to R\u0026R tools, past approaches and studies only examine the effectiveness of these tools in disparate or fragmented settings. As such, the research community currently lacks a comprehensive examination of the effectiveness of existing tools across their common use cases and the potential key limitations that emerge. We address this current gap in knowledge by conducting a thorough empirical study on using R\u0026R tools to manually record and replay non-crashing failures, crashing bugs, and feature-based user scenarios. Additionally, we explore the possibility of using R\u0026R tools in conjunction with AIG tools to automatically record and replay crashing bugs. Our study context includes one industrial and three academic R\u0026R tools, 34 common user scenarios from 17 apps, 90 non-crashing failures from 42 Android apps, and 31 crashing bugs from 17 Android apps. Our results illustrate that 17% of execution scenarios, 38% of non-crashing bugs, and 44% of crashing bugs are not able to be reliably recorded and replayed, with the most prevalent reasons for non-replayability being action interval resolution, incompatibility related to APIs, and limitations in Android tooling. Our findings reveal important future research directions related to R\u0026R tools that should facilitate their practical application and adoption..","tags":null,"title":"Can you mimic me? Exploring the Use of Android Record \u0026 Replay Tools in Debugging","type":"publication"},{"authors":["Dezhi Ran","Mengzhou Wu","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1736208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736208000,"objectID":"fbdbc5366be3286ec215d2f911a9b9e0","permalink":"http://youngwei.com/publication/se2030/","publishdate":"2025-01-07T00:00:00Z","relpermalink":"/publication/se2030/","section":"publication","summary":"By treating data and models as the source code, Foundation Models (FMs) become a new type of software. Mirroring the concept of software crisis, the increasing complexity of FMs making FM crisis a tangible concern in the coming decade, appealing for new theories and methodologies from the field of software engineering. In this paper, we outline our vision of introducing Foundation Model (FM) engineering, a strategic response to the anticipated FM crisis with principled engineering methodologies. FM engineering aims to mitigate potential issues in FM development and application through the introduction of declarative, automated, and unified programming interfaces for both data and model management, reducing the complexities involved in working with FMs by providing a more structured and intuitive process for developers. Through the establishment of FM engineering, we aim to provide a robust, automated, and extensible framework that addresses the imminent challenges, and discovering new research opportunities for the software engineering field..","tags":null,"title":"Foundation Model Engineering: Engineering Foundation Models Just as Engineering Software","type":"publication"},{"authors":["Jaeseong Lee","Simin Chen","Austin Mordahl","Cong Liu","Wei Yang","Shiyi Wei"],"categories":null,"content":"","date":1727395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727395200,"objectID":"152839796db34bf2d9ea3d5b05bdcd84","permalink":"http://youngwei.com/publication/alict/","publishdate":"2024-09-27T00:00:00Z","relpermalink":"/publication/alict/","section":"publication","summary":"Natural language processing (NLP) has gained widespread adoption in the development of real-world applications. However, the black-box nature of neural networks in NLP applications poses a challenge when evaluating their performance, let alone ensuring it. Recent research has proposed testing techniques to enhance the trustworthiness of NLP-based applications. However, most existing works use a single, aggregated metric (i.e., accuracy) which is difficult for users to assess NLP model performance on fine-grained aspects, such as LCs. To address this limitation, we present ALiCT, an automated testing technique for validating NLP applications based on their LCs. ALiCT takes user-specified LCs as inputs and produces diverse test suite with test oracles for each of given LC. We evaluate ALiCT on two widely adopted NLP tasks, sentiment analysis and hate speech detection, in terms of diversity, effectiveness, and consistency. Using Self-BLEU and syntactic diversity metrics, our findings reveal that ALiCT generates test cases that are 190% and 2213% more diverse in semantics and syntax, respectively, compared to those produced by state-of-the-art techniques. In addition, ALiCT is capable of producing a larger number of NLP model failures in 22 out of 25 LCs over the two NLP applications.","tags":null,"title":"Automated Testing Linguistic Capabilities of NLP Models","type":"publication"},{"authors":["Xiaoning Feng","Xiaohong Han","Simin Chen","Wei Yang"],"categories":null,"content":"","date":1727395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727395200,"objectID":"6a1c1d1035e97b76ae63b051948211ab","permalink":"http://youngwei.com/publication/llmeffichecker/","publishdate":"2024-09-27T00:00:00Z","relpermalink":"/publication/llmeffichecker/","section":"publication","summary":"Large Language Models (LLMs) have received much recent attention due to their human-level accuracy. While existing works mostly focus on either improving accuracy or testing accuracy robustness, the computation efficiency of LLMs, which is of paramount importance due to often vast generation demands and real-time requirements, has surprisingly received little attention. In this article, we make the first attempt to understand and test potential computation efficiency robustness in state-of-the-art LLMs. By analyzing the working mechanism and implementation of 20,543 public-accessible LLMs, we observe a fundamental property in LLMs that could be manipulated in an adversarial manner to reduce computation efficiency significantly. Our interesting observation is that the output length determines the computation efficiency of LLMs instead of the input, where the output length depends on two factors: an often sufficiently large yet pessimistic pre-configured threshold controlling the max number of iterations and a runtime-generated end of sentence (EOS) token. Our key motivation is to generate test inputs that could sufficiently delay the generation of EOS such that LLMs would have to go through enough iterations to satisfy the pre-configured threshold. We present LLMEffiChecker, which can work under both white-box setting and black-box setting. In the white-box scenario, LLMEffiChecker develops a gradient-guided technique that searches for a minimal and unnoticeable perturbation at character-level, token-level, and structure-level. In the black-box scenario, LLMEffiChecker employs a causal inference-based approach to find critical tokens and similarly applies three levels of imperceptible perturbation to them. Both the white-box and black-box settings effectively delay the appearance of EOS, compelling these inputs to reach the naturally unreachable threshold. To demonstrate the effectiveness of LLMEffiChecker, we conduct a systematic evaluation on nine publicly available LLMs: Google T5, AllenAI WMT14, Helsinki-NLP translator, Facebook FairSeq, UNICAMP-DL translator, MarianMT, Google FLAN-T5, MBZUAI LaMini-GPT, and Salesforce CodeGen. Experimental results show that LLMEffiChecker can increase on average LLMs’ response latency and energy consumption by 325% to 3,244% and 344% to 3,616%, respectively, by perturbing just one character or token in the input sentence. Our case study shows that inputs generated by LLMEffiChecker significantly affect the battery power in real-world mobile devices (i.e., drain more than 30 times battery power than normal inputs).","tags":null,"title":"LLMEffiChecker: Understanding and Testing Efficiency Degradation of Large Language Models","type":"publication"},{"authors":["Dezhi Ran","Hao Wang","Zihe Song","Mengzhou Wu","Yuan Cao","Ying Zhang","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1726790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726790400,"objectID":"32714ae99aaaeea7e76de342bb8802ff","permalink":"http://youngwei.com/publication/guardian/","publishdate":"2024-09-20T00:00:00Z","relpermalink":"/publication/guardian/","section":"publication","summary":"Tests for feature-based UI testing have been indispensable for ensuring the quality of mobile applications (apps for short). The high manual labor costs to create such tests have led to a strong interest in automated feature-based UI testing, where an approach automatically explores the App under Test (AUT) to find correct sequences of UI events achieving the target test objective, given only a highlevel test objective description. Given that the task of automated feature-based UI testing resembles conventional AI planning problems, large language models (LLMs), known for their effectiveness in AI planning, could be ideal for this task. However, our study reveals that LLMs struggle with following specific instructions for UI testing and replanning based on new information. This limitation results in reduced effectiveness of LLM-driven solutions for automated feature-based UI testing, despite the use of advanced prompting techniques. \n Toward addressing the preceding limitation,we propose Guardian, a runtime system framework to improve the effectiveness of automated feature-based UI testing by offloading computational tasks from LLMs with two major strategies. First, Guardian refines UI action space that the LLM can plan over, enforcing the instruction following of the LLM by construction. Second, Guardian deliberately checks whether the gradually enriched information invalidates previous planning by the LLM. Guardian removes the invalidated UI actions from the UI action space that the LLM can plan over, restores the state of the AUT to the state before the execution of the invalidated UI actions, and prompts the LLM to re-plan with the new UI action space. We instantiate Guardian with ChatGPT and construct a benchmark named FestiVal with 58 tasks from 23 highly popular apps. Evaluation results on FestiVal show that Guardian achieves 48.3% success rate and 64.0% average completion proportion, outperforming state-of-the-art approaches with 154% and 132% relative improvement with respect to the two metrics, respectively.","tags":null,"title":"Guardian: A Runtime Framework for LLM-based UI Exploration","type":"publication"},{"authors":["Jiangrui Zheng","Xueqing Liu","Guanqun Yang","Mirazul Haque","Xing Qian","Ravishka Rathnasuriya","Girish Budhrani","Wei Yang"],"categories":null,"content":"","date":1712707200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712707200,"objectID":"897a8a9709da6f2173af723eb03606a4","permalink":"http://youngwei.com/publication/hatemoderate/","publishdate":"2024-04-10T00:00:00Z","relpermalink":"/publication/hatemoderate/","section":"publication","summary":"To protect users from massive hateful content, existing works studied automated hate speech detection. Despite the existing efforts, one question remains: do automated hate speech detectors conform to social media content policies? A platform’s content policies are a checklist of content moderated by the social media platform. Because content moderation rules are often uniquely defined, existing hate speech datasets cannot directly answer this question. This work seeks to answer this question by creating HateModerate, a dataset for testing the behaviors of automated content moderators against content policies. First, we engage 28 annotators and GPT in a six-step annotation process, resulting in a list of hateful and non-hateful test suites matching each of Facebook’s 41 hate speech policies. Second, we test the performance of state-of-theart hate speech detectors against HateModerate, revealing substantial failures these models have in their conformity to the policies. Third, using HateModerate, we augment the training data of a top-downloaded hate detector on HuggingFace. We observe significant improvement in the models’ conformity to content policies while having comparable scores on the original test data. Our dataset and code can be found on https://github.com/stevens-textmining/HateModerate.","tags":null,"title":"HateModerate: Testing Hate Speech Detectors against Content Moderation Policies","type":"publication"},{"authors":["Dezhi Ran","Zihe Song","Wenhan Zhang","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1710028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710028800,"objectID":"7bd22a30c39549c400571d24ffaae1a4","permalink":"http://youngwei.com/publication/hawkeyes/","publishdate":"2024-03-10T00:00:00Z","relpermalink":"/publication/hawkeyes/","section":"publication","summary":"LLM agents have been demonstrated to be powerful in vision language planning (VLP) tasks. However, they often encounter challenges with sequential VLP tasks, particularly in adhering to instructions in prompts, which affects their overall efficacy. To unleash the efficacy of LLM agents against instruction disalignments, this paper proposes HawkEyes, an LLM-based approach to self-identify and self-avoid instruction disalignments of any given LLM agent. Instead of altering the intrinsic mechanism of LLM agents, HawkEyes operates externally on the input and output sequences of LLM agents. Specifically, HawkEyes uses LLMs to decompose the instructions in the LLM agent’s workflow into primitive constraints, creating oracles to detect any disalignments of these primitive constraints and synthesize avoiding actions to preempt potential disalignments. This paper also demonstrates the application of HawkEyes to enhance three state-of-the-art LLM agents, assessing HawkEyes’s effectiveness on two challenging VLP tasks:WebShop and MoTIF. Evaluation results show that HawkEyes significantly boosts the performance of LLM agents across various agents and tasks. Notably, HawkEyes doubles the success rate of LLM-planner, a state-of-the-art LLM agent dedicated to sequential VLP, from 17.2% to 34.5% on the MoTIF dataset, showcasing its capability to adapt LLM planning more flexibly and effectively in sequential VLP scenarios.","tags":null,"title":"HawkEyes: Spotting and Evading Instruction Disalignments of LLMs","type":"publication"},{"authors":["Wei Yang"],"categories":["Research Opportunities","Summer Programs"],"content":" Overview We are excited to invite students from across the globe to apply for our research internship program at the University of Texas at Dallas. This program is led by distinguished professors including Yapeng Tian, Xinya Du, Yunhui Guo, Zhiyu Chen, Yi Ding, Bingzhe Li, Xinda Wang and Wei Yang. Our research spans a wide array of topics such as large language models, multimodal machine learning, natural language processing, machine learning systems, high-performance computing, storage systems, software engineering, security, computer vision, mobile computing, and robotics.\nApplication Details  Deadline: Applications are open until April 1 (23:59:59 AoE time zone) but will remain open until all positions are filled. Project Collaboration: Selected students will collaborate remotely with professors on projects tailored to their mutual interests. Onsite internships may be arranged on a case-by-case basis. Benefits: Although the positions are unpaid, students gain invaluable research experience, potential publications, and support for graduate program applications. Past Success: Our alumni have been accepted into prestigious graduate programs worldwide. For more details, visit Professor Yang\u0026rsquo;s Students, Professor Tian\u0026rsquo;s Group, Professor Du\u0026rsquo;s Advising, and Professor Guo\u0026rsquo;s Team.  How to Apply Submit your application through our Online Form.\nRequirements: - A link to your CV (preferably on Google Drive). - Reference contacts, if available. - Evidence of English proficiency (TOEFL, IELTS, etc.) is appreciated but not mandatory.\nAbout UT Dallas UT Dallas is renowned for its youthful vigor and impressive accolades, including: - 1st in the U.S. among universities under 50 years old. - Top rankings in Software Engineering, AI, Natural Language Processing, and more according to CSrankings.org and US News.\nOur faculty have received numerous awards, such as NSF CAREER Award, ACM SIGSOFT Distinguished Paper Award, the Spotlight Rising Star in Data Science, Cyber-Physical Systems Rising Star, and many more, reflecting the high-impact research conducted here.\nJoin Us This summer, immerse yourself in a vibrant research environment at UT Dallas. Work alongside leading scholars, contribute to impactful projects, and take a significant step toward your academic and professional goals.\n","date":1709337600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709337600,"objectID":"c4aa80acf4650137c6c4af61c22abf5a","permalink":"http://youngwei.com/post/internproject2024/","publishdate":"2024-03-02T00:00:00Z","relpermalink":"/post/internproject2024/","section":"post","summary":"Join our research internship program at UT Dallas to work on groundbreaking projects in AI, machine learning, and more. Open to students worldwide, this is your chance to collaborate with leading professors and gain valuable research experience.","tags":["Machine Learning","Large Language Models","Computer Vision","Software Engineering","Security","Mobile Computing","High-Performance Computing"],"title":"Computer Science Research Internship Program at UT Dallas","type":"post"},{"authors":["Simin Chen","Xiaoning Feng","Xiaohong Han","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1708646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708646400,"objectID":"e7c30822ea0ae5899c5a55e01f8197ec","permalink":"http://youngwei.com/publication/ppm/","publishdate":"2024-02-23T00:00:00Z","relpermalink":"/publication/ppm/","section":"publication","summary":"In recent times, a plethora of Large Code Generation Models (LCGMs) have been proposed, showcasing significant potential in assisting developers with complex programming tasks. Within the surge of LCGM proposals, a critical aspect of code generation research involves effectively benchmarking the programming capabilities of each model. Benchmarking LCGMs necessitates the creation of a diverse programming problem set, comprising the prompt, canonical solution, and test inputs. The existing methods for constructing such a problem set can be categorized into two main types: manually-based and perturbation-based. However, both these methods exhibit major limitations. Firstly, manually-based methods require substantial human effort and are not easily scalable. Moreover, programming problem sets created manually struggle to maintain long-term data integrity due to the greedy training data collection mechanism in LCGMs. On the other hand, perturbation-based approaches primarily produce semantically homogeneous problems, resulting in generated programming problems with identical Canonical Solutions to the seed problem. These methods also tend to introduce typos to the prompt, easily detectable by IDEs, rendering them unrealistic. Addressing the aforementioned limitations presents several challenges: (1) How to automatically generate semantically diverse Canonical Solutions, (2) how to ensure long-term data integrity, and (3) how to generate grammatically correct programming problems. To tackle the first challenge, our key insight stems from viewing a program as a mapping from the input domain to the output domain. The output of one program can be utilized as the input for another. Building on this insight, we propose programming problem merging, which combines two existing programming problems to create semantically diverse ones. In addressing the second challenge, we introduce randomness to our programming problem generation process. By defining a large random search space, our tool can probabilistically guarantee no data repetition with two random trials with high confidence. To tackle the third challenge, we propose the concept of a Lambda Programming Problem, comprising a concise one-sentence task description in natural language accompanied by a corresponding program implementation. As the proposed task description is grammatically correct, our tool ensures the new program prompt is also grammatically correct. Additionally, the tool leverages return value type analysis to verify the correctness of newly created Canonical Solutions. In our empirical evaluation, we utilize our tool on two widely-used datasets and compare it against six baseline methods using eight code generation models. The results vividly demonstrate the effectiveness of our tool in generating challenging, diverse, and natural coding problems, surpassing the baselines.","tags":null,"title":"PPM: Automated Generation of Diverse Programming Problems for Benchmarking Code Generation Models","type":"publication"},{"authors":["Simin Chen","Zexin Li","Wei Yang","Cong Liu"],"categories":null,"content":"","date":1708387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708387200,"objectID":"316b62564d60ff3836d3fc8a21092e40","permalink":"http://youngwei.com/publication/decix/","publishdate":"2024-02-20T00:00:00Z","relpermalink":"/publication/decix/","section":"publication","summary":"Deep learning-based code generation (DL-CG) applications have shown great potential for assisting developers in programming with human-competitive accuracy. However, the lack of transparency in such applications due to the uninterpretable nature of deep learning models makes the automatically generated programs untrustworthy. In this paper, we develop DeciX, an explanation method dedicated to deep learning-based code models. DeciX is motivated by observing two unique properties of DL-CG applications: output-to-output dependencies and irrelevant value and semantic space. These properties violate the fundamental assumptions made in existing explainable DL techniques and thus cause applying existing techniques to DL-CG applications rather pessimistic and even incorrect. DeciX addresses these two limitations by constructing a causal inference dependency graph, containing a novel method leveraging causal inference that can accurately quantify the contribution of each dependency edge in the graph to the end prediction result. Proved by extensive experiments assessing popular, widely-used DL-CG applications and several baseline methods, DeciX is able to achieve significantly better performance compared to state-of-the-art in terms of several critical performance metrics, including correctness, succinctness, stability, and overhead. Furthermore, DeciX can be applied to practical scenarios since it does not require any knowledge of the DL-CG model under explanation. We have also conducted case studies that demonstrate the applicability of DeciX in practice.","tags":null,"title":"DeciX: Explain Deep Learning Based Code Generation Applications","type":"publication"},{"authors":["Xinyue Liu","Zihe Song","Weike Fang","Wei Yang","Weihang Wang"],"categories":null,"content":"","date":1705708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705708800,"objectID":"ae2de6b85af041dbeee5d52e2afe3b7e","permalink":"http://youngwei.com/publication/wefix/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/publication/wefix/","section":"publication","summary":"Web end-to-end (e2e) testing evaluates the workflow of a web application from beginning to end. It simulates real-world user scenarios to ensure the application flows behave as expected. Web e2e testing plays an indispensable role in the development of modern web applications. However, web e2e tests are notorious for being flaky, i.e., the tests can produce inconsistent results, passing or failing unpredictably, despite no changes to the code under test. One common type of flakiness in web e2e testing is caused by nondeterministic execution orders between the test code and the client-side code under test. In particular, UI-based flakiness emerges as a notably prevalent and challenging issue to mitigate. Such flaky tests are challenging to fix because the test code has limited knowledge about the client-side code execution. In this paper, we propose WEFix, a technique that can automatically generate fix code for UI-based flakiness in web e2e testing. The core of our approach is to leverage browser UI changes to predict the client-side code execution and generate proper wait oracles. We evaluate the effectiveness and efficiency of WEFix against 122 web e2e flaky tests from seven popular real-world projects. Our results show that (1) UI-based flakiness is prevalent; (2) implicit waits introduce significant runtime overhead; (3) WEFix dramatically reduces the overhead (from 3.7 to 1.25) while still achieving a high correctness (98%).","tags":null,"title":"WEFix: Intelligent Automatic Generation of Explicit Waits for Efficient Web End-to-End Flaky Tests","type":"publication"},{"authors":["Shamik Kundu\\*","Mirazul Haque\\*","Sanjay Das","Wei Yang","Kanad Basu"],"categories":null,"content":"","date":1704672000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704672000,"objectID":"20a22e04617d60ed0777ee3a3015a985","permalink":"http://youngwei.com/publication/mendnet/","publishdate":"2024-01-08T00:00:00Z","relpermalink":"/publication/mendnet/","section":"publication","summary":"Hardware faults in AI accelerators, particularly in accelerator memory, can alter pre-trained deep neural network parameters, leading to errors that compromise performance. To address this, just-intime (JIT) fault detection and mitigation are crucial. However, existing fault detection/mitigation approaches, either interrupt continuous execution or introduce significant latency, making them less ideal for JIT implementation. To circumvent this issue, this paper explores uncertainty quantification in deep neural networks as a means of facilitating an efficient and novel fault detection approach in AI accelerators. Furthermore, in order to mitigate the impact of such faults, we propose MENDNet, which leverages the properties of multi-exit neural networks, coupled with the proposed uncertainty quantification framework. By tuning the confidence threshold for inference in each exit and leveraging the energy-based uncertainty quantification metric, MENDNet can make accurate predictions even in the presence of faults in the accelerator. When evaluated on state-of-the-art network-dataset configurations and with multiple fault rate-fault position combinations, our proposed approach furnishes up to 80.42% improvement in accuracy over a traditional DNN implementation, thereby instilling the reliability of the AI accelerator in mission mode.\n\\* The first two authors contributed equally.","tags":null,"title":"MENDNet: Just-in-time Fault Detection and Mitigation in AI Systems with Uncertainty Quantification and Multi-Exit Networks","type":"publication"},{"authors":["Hanlin Chen","Simin Chen","Wenyu Li","Wei Yang","Yiheng Feng"],"categories":null,"content":"","date":1704412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704412800,"objectID":"a5f9845789e59443147937ed9143ed9f","permalink":"http://youngwei.com/publication/slothav/","publishdate":"2024-01-05T00:00:00Z","relpermalink":"/publication/slothav/","section":"publication","summary":"As a safety-critical cyber-physical system, cybersecurity and related safety issues for Autonomous Vehicles (AVs) have been important research topics for a while. Among all the modules on AVs, perception is one of the most accessible attack surfaces, as drivers and AVs have no control over the outside environment. Most current work targeting perception security for AVs focuses on perception correctness. In this work, we propose an impact analysis based on inference time attacks for autonomous vehicles. We demonstrate in a simulation system that such inference time attacks can also threaten the safety of both the ego vehicle and other traffic participants.","tags":null,"title":"IMPACT ANALYSIS OF INFERENCE TIME ATTACK OF PERCEPTION SENSORS ON AUTONOMOUS VEHICLES","type":"publication"},{"authors":["Yufei Li","Zexin Li","Wei Yang","Cong Liu"],"categories":null,"content":"","date":1702166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702166400,"objectID":"5e4338bc8d1d7f6498ab0726a1276e7e","permalink":"http://youngwei.com/publication/rt-lm/","publishdate":"2023-12-10T00:00:00Z","relpermalink":"/publication/rt-lm/","section":"publication","summary":"Recent advancements in language models (LMs) have gained substantial attentions on their capability to generate human-like responses. Though exhibiting a promising future for various applications such as conversation AI, these LMs face deployment challenges on various devices due to their extreme computational cost and unpredictable inference latency. Such varied inference latency, identified as a consequence of uncertainty intrinsic to the nature of language, can lead to computational inefficiency and degrade the overall performance of LMs, especially under high-traffic workloads. Unfortunately, the bandwidth of these uncertainty sources is extensive, complicating the prediction of latency and the effects emanating from such uncertainties. To understand and mitigate the impact of uncertainty on real-time response-demanding systems, we take the first step to comprehend, quantify and optimize these uncertainty-induced latency performance variations in LMs. Specifically, we present RT-LM, an uncertainty-aware resource management ecosystem for real-time inference of LMs. RT-LM innovatively quantifies how specific input uncertainties, adversely affect latency, often leading to an increased output length. Exploiting these insights, we devise a lightweight yet effective method to dynamically correlate input text uncertainties with output length at runtime. Utilizing this quantification as a latency heuristic, we integrate the uncertainty information into a system-level scheduler which explores several uncertainty-induced optimization opportunities, including uncertainty-aware prioritization, dynamic consolidation, and strategic CPU offloading. Quantitative experiments across five state-of-the-art LMs on two hardware platforms demonstrates that RT-LM can significantly reduce the average response time and improve throughput while incurring a rather small runtime overhead.","tags":null,"title":"RT-LM: Uncertainty-Aware Resource Management for Real-Time Inference of Language Models","type":"publication"},{"authors":["Simin Chen","Shiyi Wei","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1691452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691452800,"objectID":"609606e7e8fcb8e77515430d53d8ecd1","permalink":"http://youngwei.com/publication/dycl/","publishdate":"2023-08-08T00:00:00Z","relpermalink":"/publication/dycl/","section":"publication","summary":"The deep learning (DL) compiler is a fundamental piece of infrastructure that enables the deployment of deep neural networks on various hardware platforms (e.g, mobile devices and Raspberry Pi). A DL compiler translates DNN programs written with high-level DL frameworks (e.g, PyTorch and TensorFlow) into portable executables; deployed host programs can then flexibly run these executables. Existing DL compilers treat neural network programs as static data flow graphs, which presume a pre-determined DNN model architecture. However, this assumption does not hold in modern dynamic neural networks (DyNNs). As a result, existing DL compilers cannot compile DyNNs into correct executables. To bridge this gap, we propose DyCL, a flexible approach that enables existing DL compilers for compiling DyNNs. DyCL handles the dynamic nature of the DyNNs by introducing a compilation mechanism that redistributes the original programs' control and data flow during compilation. Specifically, DyCL applies program analysis and transformation techniques to transform an dynamic neural network into multiple sub-neural networks. Each sub-neural network does not contain conditional statements and is compiled separately. DyCL then synthesizes a host API to model the control flow of the DyNNs and invocations of the sub-neural networks. Our evaluation demonstrates that DyCL can 100% successfully compile all dynamic neural networks and the compiled executables run 1.12X to 20.21X faster than the original DyNNs runs on the general-purpose DL frameworks.","tags":null,"title":"DyCL: Dynamic Neural Network Compilation Via Program Rewriting and Graph Optimization","type":"publication"},{"authors":["Mirazul Haque","Rutvij Shah","Simin Chen","Berrak Sisman","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1691020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691020800,"objectID":"cc3265f0f50adf5a57cd9ba511ac9199","permalink":"http://youngwei.com/publication/slothspeech/","publishdate":"2023-08-03T00:00:00Z","relpermalink":"/publication/slothspeech/","section":"publication","summary":"Deep Learning (DL) models have been popular nowadays to execute different speech-related tasks, including automatic speech recognition (ASR). As ASR is being used in different real-time scenarios, it is important that the ASR model remains efficient against minor perturbations to the input. Hence, evaluating efficiency robustness of the ASR model is the need of the hour. We show that popular ASR models like Speech2Text model and Whisper model have dynamic computation based on different inputs, causing dynamic efficiency. In this work, we propose SlothSpeech, a denial-of-service attack against ASR models, which exploits the dynamic behavior of the model. SlothSpeech uses the probability distribution of the output text tokens to generate perturbations to the audio such that the efficiency of the ASR model is decreased. We find that SlothSpeech-generated inputs can increase the latency up to 40X times the latency induced by benign input.","tags":null,"title":"SlothSpeech: Denial-of-service Attack Against Speech Recognition Models","type":"publication"},{"authors":["Mirazul Haque","Simin Chen","Wasif Haque","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1680480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680480000,"objectID":"88c0ec4d9ff6ea1630f9f7271b2fb0f1","permalink":"http://youngwei.com/publication/nodeattack/","publishdate":"2023-04-03T00:00:00Z","relpermalink":"/publication/nodeattack/","section":"publication","summary":"Recently, Neural ODE (Ordinary Differential Equation) models have been proposed, which use ordinary differential equation solving to predict the output of neural networks. Due to Neural ODE models' noticeably lower parameter usage compared to traditional Deep Neural Networks (DNN) and higher robustness against gradient-based attacks, they are being adopted in many type of real-time applications. For real-time applications, response-time (latency) has paramount importance due to the convenience of the user. Through our observation, we find that the latency during Neural ODE inference can be highly dynamic and sometimes detrimental to the system due to the adaptive nature of the ODE solvers. Because of that reason, understanding and evaluating efficiency robustness of Neural ODE models is needed, which has not received much attention yet. However, evaluating efficiency robustness of any model is dependent on the relationship between input and latency, which has not been defined yet for Neural ODE models. In this work, we first formulate the relationship between input and dynamic latency consumption of Neural ODEs. Based on the formulation, we propose AntiNODE, which generates latency-surging adversarial inputs for Neural ODEs by increasing the computations in Neural ODEs. We evaluate AntiNODE on two popular datasets and three ODE solvers on both hardware dependent and independent metrics. Results show that the adversarial inputs generated by AntiNODE can decrease up to 335% efficiency during inference. Our evaluation also shows that the generated adversarial inputs are transferable across multiple solvers and multiple architectures, which indicates the feasibility of black-box attack.","tags":null,"title":"AntiNODE: Evaluating Efficiency Robustness of Neural ODEs","type":"publication"},{"authors":["Mirazul Haque","Wei Yang"],"categories":null,"content":"","date":1680480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680480000,"objectID":"7f7b42d8e652aab36e4bb9549f86905e","permalink":"http://youngwei.com/publication/earlyattack/","publishdate":"2023-04-03T00:00:00Z","relpermalink":"/publication/earlyattack/","section":"publication","summary":"Deep Neural Networks (DNNs) have been used to solve different day-to-day problems. Recently, DNNs have been deployed in real-time systems, and lowering the energy consumption and response time has become the need of the hour. To address this scenario, researchers have proposed incorporating dynamic mechanism to static DNNs (SDNN) to create Dynamic Neural Networks (DyNNs) performing dynamic amounts of computation based on the input complexity. Although incorporating dynamic mechanism into SDNNs would be preferable in real-time systems, it also becomes important to evaluate how the introduction of dynamic mechanism impacts the robustness of the models. However, there has not been a significant number of works focusing on the robustness trade-off between SDNNs and DyNNs. To address this issue, we propose to investigate the robustness of dynamic mechanism in DyNNs and how dynamic mechanism design impacts the robustness of DyNNs. For that purpose, we evaluate three research questions. These evaluations are performed on three models and two datasets. Through the studies, we find that attack transferability from DyNNs to SDNNs is higher than attack transferability from SDNNs to DyNNs. Also, we find that DyNNs can be used to generate adversarial samples more efficiently than SDNNs. Then, through research studies, we provide insight into the design choices that can increase robustness of DyNNs against the attack generated using static model. Finally, we propose a novel attack to understand the additional attack surface introduced by the dynamic mechanism and provide design choices to improve robustness against the attack.","tags":null,"title":"Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks","type":"publication"},{"authors":["Simin Chen","Hanlin Chen","Mirazul Haque","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1677715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677715200,"objectID":"8c74f6ca1c9816c286cf36c703e49bf8","permalink":"http://youngwei.com/publication/efficfrog/","publishdate":"2023-03-02T00:00:00Z","relpermalink":"/publication/efficfrog/","section":"publication","summary":"Recent increases in deploying deep neural networks (DNNs) on resource-constrained devices, combined with the observation that not all input samples require the same amount of computations, have sparked interest in input- adaptive dynamic neural networks (DyNNs). These DyNNs bring in more efficient inferences and enable deploying DNNs on resource-constrained devices e.g. mobile devices. In this work, we study a new vulnerability about DyNNs: can adversaries manipulate a DyNN to provide a false sense of efficiency? To answer this question, we design EfficFrog, an adversarial attack that injects univer- sal efficiency backdoors in DyNNs. EfficFrog poison only a minimal percentage of DyNNs training data to in- ject a backdoor trigger into DyNNs. During the infer- ence time, EfficFrog can slow down backdoored DyNNs and abuse the computational resources of systems running DyNNs by adding the trigger to any inputs - an availability threat analogous to the denial-of-service attacks. We eval- uate EfficFrog on three DNN backbone architectures (based on VGG16, MobileNet, and ResNet56) on two popu- lar datasets (CIFAR-10 and Tiny ImageNet) We show that a EfficFrog reduces the efficiency of DyNNs on triggered input samples while keeping almost the same efficiency on clean samples.","tags":null,"title":"The Dark Side of Dynamic Routing Neural Networks: Towards Efficiency Backdoor Injection","type":"publication"},{"authors":["Yiming Chen","Simin Chen","Zexin Li","Wei Yang","Cong Liu","Robby T. Tan","Haizhou Li"],"categories":null,"content":"","date":1675296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675296000,"objectID":"31134c6799cf695d24fd3654518fc2c2","permalink":"http://youngwei.com/publication/same/","publishdate":"2023-02-02T00:00:00Z","relpermalink":"/publication/same/","section":"publication","summary":"Despite much success in natural language processing (NLP), pre-trained language models typically lead to a high computational cost during inference. Multi-exit is a mainstream approach to address this issue by making a tradeoff between efficiency and accuracy, where the saving of computation comes from an early exit. However, whether such saving from earlyexiting is robust remains unknown. Motivated by this, we first show that directly adapting existing adversarial attack approaches targeting model accuracy cannot significantly reduce inference efficiency. To this end, we propose a simple yet effective attacking framework, SAME, a novel slowdown attack framework on multi-exit models, which is specially tailored to reduce the efficiency of the multi-exit models. By leveraging the multi-exit models' design characteristics, we utilize all internal predictions to guide the adversarial sample generation instead of merely considering the final prediction. Experiments on the GLUE benchmark show that SAME can effectively diminish the efficiency gain of various multi-exit models by 80% on average, convincingly validating its effectiveness and generalization ability.","tags":null,"title":"Dynamic Transformers Provide a False Sense of Efficiency","type":"publication"},{"authors":["Yueming Wu","Shihan Dou","Deqing Zou","Wei Yang","Weizhong Qiang","Hai Jin"],"categories":null,"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"f6e29d57fb088f4955a8dbf0ac1b70c7","permalink":"http://youngwei.com/publication/ifdroid/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/ifdroid/","section":"publication","summary":"Due to its open-source nature, Android operating system has been the main target of attackers to exploit. Malware creators always perform different code obfuscations on their apps to hide malicious activities. Features extracted from these obfuscated samples through program analysis contain many useless and disguised features, which leads to many false negatives. To address the issue, in this paper, we demonstrate that obfuscation-resilient malware family analysis can be achieved through contrastive learning. The key insight behind our analysis is that contrastive learning can be used to reduce the difference introduced by obfuscation while amplifying the difference between malware and other types of malware. Based on the proposed analysis, we design a system that can achieve robust and interpretable classification of Android malware. To achieve robust classification, we perform contrastive learning on malware samples to learn an encoder that can automatically extract robust features from malware samples. To achieve interpretable classification, we transform the function call graph of a sample into an image by centrality analysis. Then the corresponding heatmaps can be obtained by visualization techniques. These heatmaps can help users understand why the malware is classified as this family. Weimplement IFDroid and perform extensive evaluations on two datasets. Experimental results show that IFDroid is superior to state-of-the-art Android malware familial classification systems. Moreover, IFDroid is capable of maintaining a 98.4% F1 on classifying 69,421 obfuscated malware samples.","tags":null,"title":"Contrastive Learning for Robust Android Malware Familial Classification","type":"publication"},{"authors":["Zihe Song","Yingfeng Chen","Lei Ma","Shangjie Lu","Honglei Lin","Changjie Fan","Wei Yang"],"categories":null,"content":"","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"8091ddc735192121132106f6b230d320","permalink":"http://youngwei.com/publication/gamecompatstudy/","publishdate":"2022-08-28T00:00:00Z","relpermalink":"/publication/gamecompatstudy/","section":"publication","summary":"Detecting and fixing compatibility issues become increasingly important for mobile game development. The con- stant evolution of mobile operating systems and the severe fragmentation of mobile devices makes it challenging for game developers to detect and fix compatibility issues in time for various device models. The undetected compatibility issues can ruin the user experience, and cause financial loss to game companies and players. Unfortunately, up to the present, mobile game testing is still rather challenging in general. The pressing compatibility issue of mobile games is largely untouched in the research community so far. To bridge the gap, in this experience paper, we perform an empirical study on common compatibility issues of popular commercial mobile games. In particular, we select four active and representative mobile games with well-documented bug reports, containing over seven million lines of code and over 20,000 commits over the past several years. We successfully create a dataset with complete information about bugs and bug fixing details, to investigate the common compatibility issues and fixing strategies. We performed an in-depth manual inspection of the most common symptoms and root causes of these compatibility issues, and analyzed the common fixing strategies of issues under each root cause category. We believe our findings and implications are useful for developers in addressing compatibility hurdles during the developing process. Our results also provide insights for future research on compatibility issue testing and bug fixing for mobile games. ","tags":null,"title":"An Empirical Analysis of Compatibility Issues for Industrial Mobile Games","type":"publication"},{"authors":["Simin Chen","Mirazul Haque","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"2c8e854b9fe021ac1a80098f2cbd685d","permalink":"http://youngwei.com/publication/deepperform/","publishdate":"2022-08-28T00:00:00Z","relpermalink":"/publication/deepperform/","section":"publication","summary":"Today, an increasing number of Adaptive Deep Neural Networks (AdNNs) are being used to make decisions on resource-constrained embedded devices. We observe that, similar to traditional software, redundant computations exist in AdNNs, resulting in considerable performance degradation. The performance degradation in AdNNs is dependent on the input workloads, and is referred to as input-dependent performance bottlenecks (IDPBs). To ensure an AdNN satisfies the performance requirements of real-time applications, it is essential to conduct performance testing to detect IDPBs in the AdNN. Existing neural network testing methods are primarily concerned with correctness testing, which does not involve performance testing. To fill this gap, we propose DeepPerform, a scalable approach to generate test samples to detect the IDPB of AdNNs. We first demonstrate how the problem of generating performance test samples detecting IDPBs can be formulated as an optimization problem. Following that, we demonstrate how tool efficiently handles the optimization problem by learning and estimating the distribution of AdNNs’ computational consumption. We evaluate DeepPerform on three widely used datasets against five popular AdNN models. The results show that DeepPerform generates test samples that cause more severe performance degradation (FLOPs: increase up to 552%). Furthermore, DeepPerform is substantially more efficient than the baseline methods in terms of generating test inputs (runtime overhead: only 6–10 milliseconds). ","tags":null,"title":"DeepPerform: An Efficient Approach for Performance Testing of Resource-Constrained Neural Networks","type":"publication"},{"authors":["Guanqun Yang","Mirazul Haque","Qiaochu Song","Wei Yang","Xueqing Liu"],"categories":null,"content":"","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"7736ca05d2c72a3c40043258bf8ac2a0","permalink":"http://youngwei.com/publication/testaug/","publishdate":"2022-08-28T00:00:00Z","relpermalink":"/publication/testaug/","section":"publication","summary":"The recently proposed capability-based NLP testing allows model developers to test the functional capabilities of NLP models, revealing functional failures that cannot be detected by the traditional heldout mechanism. However, existing work on capability-based testing requires extensive manual efforts and domain expertise in creating the test cases. In this paper, we investigate a low-cost approach for the test case generation by leveraging the GPT-3 engine. We further propose to use a classifier to remove the invalid outputs from GPT-3 and expand the outputs into templates to generate more test cases. Our experiments show that TestAug has three advantages over the existing work on behavioral testing: (1) TestAug can find more bugs than existing work; (2) The test cases in TestAug are more diverse; and (3) TestAug largely saves the manual efforts in creating the test suites. The code and data for TestAug can be found at https://github.com/guanqun-yang/testaug. ","tags":null,"title":"TestAug: A Framework for Augmenting Capability-based NLP Tests","type":"publication"},{"authors":["Simin Chen","Cong Liu","Mirazul Haque","Zihe Song","Wei Yang"],"categories":null,"content":"","date":1655164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655164800,"objectID":"21ea0649b9c43530e2278ca8a05f6486","permalink":"http://youngwei.com/publication/nmtsloth/","publishdate":"2022-06-14T00:00:00Z","relpermalink":"/publication/nmtsloth/","section":"publication","summary":"Neural Machine Translation (NMT) systems have received much recent attention due to their human-level accuracy. While existing works mostly focus on either improving accuracy or testing accuracy robustness, the computation efficiency of NMT systems, which is of paramount importance due to often vast translation demands and real-time requirements, has surprisingly received little attention. In this paper, we make the first attempt in understanding and testing potential computation efficiency robustness in state-of-the-art NMT systems. By analyzing the working mechanism and implementation of 1455 publicly-accessible NMT systems, we observe a fundamental property that could be manipulated in an adversarial manner to significantly reduce computation efficiency. An interesting observation is that the computation efficiency of NMT systems is determined by the output length instead of the input, where the output length depends on two factors: an often sufficiently large yet pessimistic pre-configured threshold controlling the max number of iterations, and a runtime generated end of sentence (EOS) token. Our key motivation is to generate test inputs that could sufficiently delay the generation of EOS such that NMT systems would have to go through enough iterations to satisfy the pre-configured threshold. We present NMTSloth which develops a gradient-guided technique that searches for a minimal and unnoticeable perturbation at character-level, token-level, and structure-level, which sufficiently delay the appearance of EOS and force these inputs to reach the naturally-unreachable threshold. To demonstrate the effectiveness of NMTSloth, we conduct a systematic evaluation on three public-available NMT systems: Google T5, WallenAI WMT14, and Helsinki-NLP translators. Experimental results show that NMTSloth can increase NMT systems' response latency and energy consumption by 85% to 3153% and 86% to 3052%, respectively, by perturbing just one to three tokens in any input sentences. ","tags":null,"title":"NMTSloth: Understanding and Testing Efficiency Degradation of Neural Machine Translation Systems","type":"publication"},{"authors":["Simin Chen","Hamed Khanpour","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1650412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650412800,"objectID":"6620fdad31f0c8cf3babc7cec8da85c2","permalink":"http://youngwei.com/publication/reversednn/","publishdate":"2022-04-20T00:00:00Z","relpermalink":"/publication/reversednn/","section":"publication","summary":"With the privatization deployment of DNNs on edge devices, the security of on-device DNNs has raised great concern. To quantify model leakage risk of on-device DNNs automatically, we propose NNReverse, the first learning-based method which can reverse DNNs from AI programs without domain knowledge. NNReverse trains a representation model to represent the semantic of binary codes for DNN layers. By searching the most similar function in our database, NNReverse infers the layer type of a given functions’ binary codes. To represent assembly instructions semantic precisely, NNReverse propose a more finegrained embedding model to represent the textual and structural semantic of assembly functions. We evaluate NNReverse on ten different DNNs with different layers and parameter numbers, the results show NNReverse reverse the DNNs without accuracy loss.","tags":null,"title":"Learning to Reverse DNNs from AI Programs Automatically","type":"publication"},{"authors":["Simin Chen","Zihe Song","Mirazul Haque","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1646179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646179200,"objectID":"d4a50decfaccc750b969cd85c52b4f6b","permalink":"http://youngwei.com/publication/nicgslowdown/","publishdate":"2022-03-02T00:00:00Z","relpermalink":"/publication/nicgslowdown/","section":"publication","summary":"Neural image caption generation (NICG) models have received massive attention from the research community due to their excellent performance in visual understanding. Existing work focuses on improving NICG model accuracy while efficiency is less explored. However, many real-world applications require real-time feedback, which highly relies on the efficiency of the NICG models. Recent research observed that the efficiency of NICG models can vary for different inputs. This observation brings in a new attack surface of NICG models, i.e., an adversary might be able to slightly change inputs to cause the NICG models to consume more computational resources. To further understand such efficiency-oriented threats, in this paper, we propose a new attack approach NICGSlowDown, to evaluate the efficiency robustness of NICG models. Our experimental results show that NICGSlowDown can generate images with human-unnoticeable perturbations that will increase the NICG model latency up to 483%. We hope this research could raise the community’s concern about the efficiency robustness of NICG models.","tags":null,"title":"NICGSlowDown: Evaluating the Efficiency Robustness of Neural Image Caption Generation Models","type":"publication"},{"authors":["Mirazul Haque","Christof Budnik","Wei Yang"],"categories":null,"content":"","date":1642204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642204800,"objectID":"e30f3f723c3e77e711d33a6b97e7b4ad","permalink":"http://youngwei.com/publication/corrgan/","publishdate":"2022-01-15T00:00:00Z","relpermalink":"/publication/corrgan/","section":"publication","summary":"Because of the increasing accuracy of Deep Neural Networks (DNNs) on different tasks, a lot of real times systems are utilizing DNNs. These DNNs are vulnerable to adversarial perturbations and corruptions. Specifically, natural corruptions like fog, blur, contrast etc can affect the prediction of DNN in an autonomous vehicle. In real time, these corruptions are needed to be detected and also the corrupted inputs are needed to be de-noised to be predicted correctly. In this work, we propose CorrGAN approach, which can generate benign input when a corrupted input is provided. In this framework, we train Generative Adversarial Network (GAN) with novel intermediate output-based loss function. The GAN can denoise the corrupted input and generate benign input. Through experimentation, we show that up to 75.2% of the corrupted misclassified inputs can be classified correctly by DNN using CorrGAN","tags":null,"title":"CorrGAN:Input Transformation Technique Against Natural Corruptions. ","type":"publication"},{"authors":["Mirazul Haque","Yaswanth Yadlapalli","Wei Yang","Cong Liu"],"categories":null,"content":"","date":1641340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641340800,"objectID":"8e67b3b759787d969204e9ca586d066d","permalink":"http://youngwei.com/publication/ereba/","publishdate":"2022-01-05T00:00:00Z","relpermalink":"/publication/ereba/","section":"publication","summary":"Recently, various Deep Neural Network (DNN) models have been proposed for environments like embedded systems with stringent energy constraints. The fundamental problem of determining the robustness of a DNN with respect to its energy consumption (energy robustness) is relatively unexplored compared to accuracy-based robustness. This work investigates the energy robustness of Adaptive Neural Networks (AdNNs), a type of energy-saving DNNs proposed for many energy-sensitive domains and have recently gained traction. We propose EREBA, the first black-box testing method for determining the energy robustness of an AdNN. EREBA explores and infers the relationship between inputs and the energy consumption of AdNNs to generate energy surging samples. Extensive implementation and evaluation using three state-of-the-art AdNNs demonstrate that test inputs generated by EREBA could degrade the performance of the system substantially. The test inputs generated by EREBA can increase the energy consumption of AdNNs by 2,000% compared to the original inputs. Our results also show that test inputs generated via EREBA are valuable in detecting energy surging inputs. ","tags":null,"title":"EREBA: Black-box Energy Testing of Adaptive Neural Networks","type":"publication"},{"authors":["Senrong Xu","Yuan Yao","Liangyue Li","Wei Yang","Feng Xu","Hanghang Tong"],"categories":null,"content":"","date":1641168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641168000,"objectID":"12cc6d635c88f7a5da225123ac98b7a9","permalink":"http://youngwei.com/publication/gnnattack/","publishdate":"2022-01-03T00:00:00Z","relpermalink":"/publication/gnnattack/","section":"publication","summary":"Graph neural networks (GNNs) have been widely used in many real applications, and recent studies have revealed their vulnerabilities against topology attacks. To address this issue, existing efforts have mainly been dedicated to improving the robustness of GNNs, while little attention is paid to the detection of such attacks. In this work, we study the victim node detection problem under topology attacks against GNNs. Our approach is built upon the observation rooted in the intrinsic message passing nature of GNNs, and thus applicable to a variety of them. That is, the neighborhood of a victim node tends to have two competing group forces, pushing the node classification results towards the original label and the targeted label, respectively. Based on this observation, we propose to detect victim nodes by deliberately designing an effective measurement of the neighborhood variance for each node. Extensive experimental results on four real-world datasets and five existing topology attacks show the effectiveness and and efficiency of the proposed detection approach..","tags":null,"title":"Detecting Topology Attacks against Graph Neural Networks","type":"publication"},{"authors":["Yueming Wu","Deqing Zou","Shihan Dou","Wei Yang","Duo Xu","Hai Jin"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"8f17958931baa80d7fe89832e96defd5","permalink":"http://youngwei.com/publication/vulcnn/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/vulcnn/","section":"publication","summary":"Since deep learning (DL) can automatically learn features from source code, it has been widely used to detect source code vulnerability. To achieve scalable vulnerability scanning, some prior studies intent to process the source code directly by treating them as text.To achieve accurate vulnerability detection, other approaches consider distilling the program semantics into graph representations and use them to detect vulnerability. In practice, text-based techniques are scalable but not accurate due to the lack of program semantics. Graph-based methods are accurate but not scalable since graph analysis is typically time-consuming. In this paper, we aim to achieve both scalability and accuracy on scanning large-scale source code vulnerabilities. Inspired by existing DL-based image classification which has the ability to analyze millions of images accurately, we prefer to use these techniques to accomplish our purpose. Specifically, we propose a novel idea that can efficiently convert the source code of a function into an image while preserving the program details. We implement VulCNN and evaluate it on a dataset of 13,687 vulnerable functions and 26,970 non-vulnerable functions. Experimental results report that VulCNN performs better than eight state-of-the-art vulnerability detectors (i.e., Checkmarx, FlawFinder, RATS, TokenCNN, VulDeePecker, SySeVR, VulDeeLocator, and Devign). As for scalability, VulCNN is about four times faster than VulDeePecker and SySeVR, about 15 times faster than VulDeeLocator, and about six times faster than Devign. Furthermore, we conduct a case study on more than 25 million lines of code and the result indicates that VulCNN has the ability to detect large-scale vulnerability. Through the scanning reports, we finally discover 73 vulnerabilities that are not reported in NVD. ","tags":null,"title":"VulCNN: An Image-inspired Scalable Vulnerability Detection System","type":"publication"},{"authors":["Wenyu Wang","Wei Yang","Tianyin Xu","Tao Xie"],"categories":null,"content":"","date":1624924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624924800,"objectID":"c4c1faa269f5159ae53be8504a53a710","permalink":"http://youngwei.com/publication/vet/","publishdate":"2021-06-29T00:00:00Z","relpermalink":"/publication/vet/","section":"publication","summary":"Despite over a decade of research, it is still challenging for mobileUI testing tools to achieve satisfactory effectiveness, especially on industrial apps with rich features and large codebases. Our experiences suggest that existing mobile UI testing tools are prone to exploration tarpits, where the tools get stuck with a small fraction of app functionalities for an extensive amount of time. One ex-ample is that a tool logs out an app at early stages without being able to log back in, and since then gets stuck with exploring the app’s pre-login functionalities (i.e., exploration tarpits) instead of its main functionalities. While tool vendors/users can manually hardcode rules for the tools to avoid specific exploration tarpits, these rules can hardly generalize, being fragile in face of diverted testing environments, fast app iterations, and the demand of batch testing product lines. To identify and resolve exploration tarpits, we proposeVet, a general approach and its supporting system for the given specific Android UI testing tool on the given specific app under test (AUT). Vet runs the tool on the AUT for some time and records UI traces, based on which Vet identifies exploration tarpits by recognizing their patterns in the UI traces. Vet then pinpoints the actions (e.g., clicking logout) or the screens that lead to exploration tarpits. In subsequent test runs, Vet guides the testing tool to prevent or recover from exploration tarpits. From our evaluation with state-of-the-art Android UI testing tools on popular industrial apps, Vet identifies exploration tarpits that cost up to 98.6% testing time budget. These exploration tarpits reveal not only limitations inUI exploration strategies but also defects in tool implementations. Vet automatically addresses the identified exploration tarpits, enabling each evaluated tool to achieve higher code coverage and improved crash-triggering capabilities. **ACM SIGSOFT Distinguished Paper Award.**","tags":null,"title":"Vet: Identifying and Avoiding UI Exploration Tarpits","type":"publication"},{"authors":["Ke Chen\\*","Yufei Li\\*","Yingfeng Chen","Changjie Fan","Zhipeng Hu","Wei Yang"],"categories":null,"content":"","date":1621382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621382400,"objectID":"4a14ffe0de68809c9fa3ad5ba9082260","permalink":"http://youngwei.com/publication/glib/","publishdate":"2021-05-19T00:00:00Z","relpermalink":"/publication/glib/","section":"publication","summary":"Mobile games are ubiquitous with attractive visual effects of Graphical User Interface (GUI) that offers a bridge between software applications and end users. However, various types of graphical glitches may arise from such GUI complexity and have become the main composition of game compatibility issues. Our study of abundant of real-world bug reports indicates that graphical glitches frequently occur during the game GUI rendering on different devices and severely degrade the game app usability, leading to poor user experience. Different from other common GUI glitches that most existing GUI testing work has focused on, game GUIs composed of 3D models typically have different manifestation of glitch issues. To solve this gap in existing techniques, we propose GLIB, a novel deep learning (DL) approach for detecting game GUI glitches and develop a code-based data augmentation technique via bug understanding for enhancing the modeling ability of our GLIB. The evaluation on 201 real-world game test cases shows that GLIB can achieve 100% precision and 99.5% recall in detecting game GUI glitches and that our code-based augmentation approach can generate more real-like GUI glitches than the existing heuristic-based approach. Our case study on 14 real-world games further demonstrates that GLIB can effectively uncover GUI glitches with most of them having been confirmed and fixed by the app developers. \\* The first two authors contributed equally.","tags":null,"title":"GLIB: Towards Automated Test Oracle for Graphically-Rich Applications","type":"publication"},{"authors":["Yueming Wu","Deqing Zou","Wei Yang","Xiang Li","Hai Jin"],"categories":null,"content":"","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"c28ca6c926981cc5d9a17cf83a1d2dea","permalink":"http://youngwei.com/publication/homdroid/","publishdate":"2021-05-16T00:00:00Z","relpermalink":"/publication/homdroid/","section":"publication","summary":"Android has become the most popular mobile operating system. Correspondingly, an increasing number of Android malware has been developed and spread to steal users’ private information. There exists one type of malware whose benign behaviors are developed to camouflage malicious behaviors. The malicious component occupies a small part of the entire code of the application (app for short), and the malicious part is strongly coupled with the benign part. In this case, the malware may cause false negatives when malware detectors extract features from the entire apps to conduct classification because the malicious features of these apps may be hidden among benign features. Moreover, some previous work aims to divide the entire app into several parts to discover the malicious part. However, the premise of these methods to commence app partition is that the connections between the normal part and the malicious part are weak (e.g., repackaged apps). In this paper, we call this type of malware as Android covert malware and generate the first dataset of covert malware. To detect these malware samples,we first conduct static analysis to extract the function call graphs. Through the deep analysis from these graphs, we observe that although the correlations between the normal part and the malicious part in these graphs are high, the degree of these correlations has a unique range of distribution. By this, we design a novel system (i.e., HomDroid) to detect covert malware by analyzing the homophily of call graphs. Our evaluation results on a dataset of 4,840 benign apps and 3,385 covert malicious apps show that the ideal threshold of correlation to distinguish the normal part and the malicious part is 3. In this case, HomDroid is capable of detecting 96.8% of covert malware while the False Negative Rates of another three state-of-the-art systems (i.e., PerDroid, Drebin, and MaMaDroid) are 30.7%, 16.3%, and 15.2%, respectively.","tags":null,"title":"HomDroid: Detecting Android Covert Malware by Social-Network Homophily Analysis","type":"publication"},{"authors":["Fei Shao","Rui Xu","Wasif Haque","Jingwei Xu","Ying Zhang","Wei Yang","Yanfang Ye","Xusheng Xiao"],"categories":null,"content":"","date":1618704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618704000,"objectID":"755ad15748cd8bf549510d8e2207d547","permalink":"http://youngwei.com/publication/webevo/","publishdate":"2021-04-18T00:00:00Z","relpermalink":"/publication/webevo/","section":"publication","summary":"In order to prevent information retrieval (IR) and robotic process automation (RPA) tools from functioning improperly due to web- site evolution, it is important to develop web monitoring tools to monitor changes in a website and report them to the developers and testers. Existing monitoring tools commonly make use of DOM-tree based similarity and visual analysis between different versions of web pages. However, DOM-tree based similarity suffers are prone to false positives, since they cannot identify content-based changes (i.e., contents refreshed every time a web page is retrieved) and GUI widget evolution (e.g., moving a button). Such imprecision adversely affect IR tools or test scripts. To address this problem, we propose approach, WebEvo, that first performs DOM-based change detection, and then leverages historic pages to identify the regions that represent content-based changes, which can be safely ignored. Further, to identify refactoring changes that preserve semantics and appearances of GUI widgets, WebEvo adapts computer vision (CV) techniques to identify the mappings of the GUI widgets from the old web page to the new web page on an element-by-element basis. Empirical evaluations on 13 real-world websites from 9 popular cat- egories demonstrate the superiority of WebEvo over the existing work that relies on DOM-tree based detection or whole-page visual comparison, while also being faster in visual analysis.","tags":null,"title":"WebEvo: Taming Web Application Evolution via Detecting Semantic Structure Change","type":"publication"},{"authors":["Alan Romano","Zihe Song","Sampath Grandhi","Wei Yang","Weihang Wang"],"categories":null,"content":"","date":1609891200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609891200,"objectID":"fed1e61783c6b11f6087878bf33a1496","permalink":"http://youngwei.com/publication/uiflakystudy/","publishdate":"2021-01-06T00:00:00Z","relpermalink":"/publication/uiflakystudy/","section":"publication","summary":"Flaky tests have gained attention from the research community in recent years and with good reason. These tests lead to wasted time and resources and reduce the reliability of the test suites and build systems they affect. However, most of the existing works on flaky tests focus exclusively on traditional unit tests. This ignores UI tests that have larger input spaces and more diverse running conditions than traditional unit tests. In addition, UI tests tend to be more complex and resource-heavy, making them unsuited for detection techniques involving rerunning test suites multiple times.  \n\n In this paper, we perform a study on UI flaky tests. We analyze 235 flaky UI test samples found in 62 projects from both web and Android environments. We identify the common underlying root causes of flakiness in the UI tests, the strategies used to manifest the flaky behavior, and the fixing strategies used to remedy flaky UI tests. The findings made in this work can provide a foundation for the development of detection and prevention techniques for flakiness arising in UI tests.","tags":null,"title":" An Empirical Analysis of UI-based Flaky Tests","type":"publication"},{"authors":["Deqing Zou","Yueming Wu","Siru Yang","Anki Chauhan","Wei Yang","Jiangying Zhong","Shihan Dou","Hai Jin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4de9bb8970d8f1aed88b442176d18e83","permalink":"http://youngwei.com/publication/intdroid/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/intdroid/","section":"publication","summary":"Android, the most popular mobile operating system, has attracted millions of users around the world. Meanwhile, the number of new Android malware instances has grown exponentially in recent years. On the one hand, existing Android malware detection systems have shown that distilling the program semantics into a graph representation and detecting malicious programs by conducting graph matching are able to achieve high accuracy on detecting Android malware. However, these traditional graph-based approaches always perform expensive program analysis and suffer from low scalability on malware detection. On the other hand, because of the high scalability of social network analysis, it has been applied to complete large-scale malware detection. However, the socialnetwork-analysis-based method only considers simple semantic information (*i.e.,* centrality) for achieving market-wide mobile malware scanning, which may limit the detection effectiveness when benign apps show some similar behaviors as malware. \n\n   In this paper, we aim to combine the high accuracy of traditional graph-based method with the high scalability of social-networkanalysis-based method for Android malware detection. Instead of using traditional heavyweight static analysis, we treat function call graphs of apps as complex social networks and apply social-network-based centrality analysis to unearth the central nodes within call graphs. After obtaining the central nodes, the average intimacies between sensitive API calls and central nodes are computed to represent the semantic features of the graphs. We implement our approach in a tool called IntDroid and evaluate it on a dataset of 3,988 benign samples and 4,265 malicious samples. Experimental results show that IntDroid is capable of detecting Android malware with an F-measure of 97.1% while maintaining a True Positive Rate of 99.1%. Although the scalability is not as fast as social-network-analysis-based method (i.e., MalScan), however, compared to a traditional graph-based method, IntDroid is more than six times faster than MaMaDroid. Moreover, in a corpus of apps collected from GooglePlay market, IntDroid is able to identify 28 zero-day malware that can evade detection of existing tools, one of which has been downloaded and installed by more than ten million users. This app has also been flagged as malware by six anti-virus scanners in VirusTotal, one of which is Symantec Mobile Insight.","tags":null,"title":"IntDroid: Android Malware Detection Based on API Intimacy Analysis","type":"publication"},{"authors":["admin","吳恩達"],"categories":["Demo","教程"],"content":" import libr print('hello')  Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more  \nGet Started  👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Tutorial and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"947c2e8d76ea286f172e4fa2d0efae7d","permalink":"http://youngwei.com/post/internproject2023/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/internproject2023/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Shudi Shao","Zhengyi Qiu","Xiao Yu","Wei Yang","Guoliang Jin","Tao Xie","Xintao Wu"],"categories":null,"content":"","date":1596412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596412800,"objectID":"8a1801c33683eb022e41c18fd94e950c","permalink":"http://youngwei.com/publication/dbantipattern/","publishdate":"2020-08-03T00:00:00Z","relpermalink":"/publication/dbantipattern/","section":"publication","summary":"Database-backed web applications are prone to performance bugs related to database accesses. While much work has been conducted on database-access antipatterns with some recent work focusing on performance impact, there still lacks a comprehensive view of database-access performance antipatterns in database-backed web applications. To address this issue, we first summarize and report all known database-access performance antipatterns found through our literature survey. We further look at web applications that access databases through language-provided SQL interfaces, which have been largely ignored by recent work, to extract new antipatterns based on real-world performance bugs from such web applications. We also evaluate the effectiveness of rule-based antipattern detection on such web applications. Our study in total reports 24 known and 10 new database-access performance antipatterns. Our results can guide future work to develop effective tool support for different types of web applications.","tags":null,"title":"Database-Access Performance Antipatterns in Database-Backed Web Applications","type":"publication"},{"authors":["Yueming Wu","Deqing Zou","Shihan Dou","Siru Yang","Wei Yang","Feng Cheng","Hong Liang","Hai Jin"],"categories":null,"content":"","date":1595980800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595980800,"objectID":"18dc4fc694b821f641b13de145679d5c","permalink":"http://youngwei.com/publication/scdetector/","publishdate":"2020-07-29T00:00:00Z","relpermalink":"/publication/scdetector/","section":"publication","summary":"Code clone detection is to excavate code fragments with similar functionalities, which has been more and more important in software engineering. Many approaches have been proposed for detecting code clones, in which token-based methods are the most scalable but cannot handle semantic clones because of the lack of consideration of program semantics. To address the issue, researchers conduct program analysis to distill the program semantics into a graph representation and detect clones by matching the graphs. However, such approaches suffer from low scalability since graph matching is typically time-consuming. In this paper, we propose SCDetector to combine the scalability of token-based methods with the accuracy of graph-based methods for software functional clone detection. Given a function source code, we first extract the control flow graph by static analysis. Instead of traditional heavyweight graph matching, we treat the graph as a social network and apply social-network-centrality analysis to dig out the centrality of each basic block. Then we assign the centrality to each token in a basic block and sum the centrality of the same token in different basic blocks. By this a graph is turned into certain tokens with graph details (i.e., centrality), called semantic tokens. In final, these semantic tokens are fed into a Siamese architecture neural network to train a model, and use it to detect code clones. We evaluate SCDetector on two large datasets of functionally similar code. Experimental results indicate that our system is superior to state-of-the-art methods and the time cost of SCDetector is more than 14 times less than the state-of-the-art approach in detecting semantic clones","tags":null,"title":"SCDetector: Software Functional Clone Detection Based on Semantic Tokens Analysis","type":"publication"},{"authors":["Simin Chen","Soroush Bateni","Sampath Grandhi","Xiaodi Li","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1589846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589846400,"objectID":"56d0a63bbaf6ad517af7481f0a5e4524","permalink":"http://youngwei.com/publication/denas/","publishdate":"2020-05-19T00:00:00Z","relpermalink":"/publication/denas/","section":"publication","summary":"Deep neural networks (DNNs) have been widely applied in the software development process to automatically learn patterns and rules from massive data. However, many applications still make decisions based on rules that are manually crafted and verified by domain experts due to safety or security concerns. In this paper, we aim to close the gap between DNNs and rule-based systems by automating the rule generation process via extracting knowledge from well-trained DNNs. Existing techniques with similar purpose either rely on specific DNN input instances, or use inherently unstable random sampling of the input space. Therefore, these approaches either limit the exploration area to a local decision-space of the DNN or fail to converge to a consistent set of rules. The resulting rules thus lack representitiveness and stability.  \n \u0026nbsp;\u0026nbsp; In this paper, we address the two aforementioned shortcomings by discovering a global property of the DNN and use it to remodel the DNN decision-boundary. We name this property as the activation probability, and show that this property is stable. With this insight, we propose an approach named DENAS including a novel rule generation algorithm. Our proposed algorithm approximates the non-linear decision boundary of DNNs by iteratively superimposing a linearized optimization function.  \n \u0026nbsp;\u0026nbsp; We evaluate the representitiveness, stability and accuracy of DENASagainst five state-of-the-art techniques (LEMNA, Gradient, IG, DeepTaylor, and DTExtract) on three software engineering and security applications: Binary analysis, PDF malware detection, and Android malware detection. Our results show that DENAS can generate more representative rules consistently in a more stable manner over other approaches. We further offer case studies that demonstrate the applications of DENAS such as debugging faults in the DNN and generating zero-day malware signatures.","tags":null,"title":"DENAS: Automated Rule Generation by Knowledge Extraction from Neural Networks","type":"publication"},{"authors":["Mirazul Haque","Anki Chauhan","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1582502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582502400,"objectID":"a1e70172d28fde2a587ca1355168f91c","permalink":"http://youngwei.com/publication/ilfo/","publishdate":"2020-02-24T00:00:00Z","relpermalink":"/publication/ilfo/","section":"publication","summary":"With the increase in the number of layers and parameters in neural networks, the energy consumption of neural networks has become a great concern to society, especially to users of handheld or embedded devices. In this paper, we investigate the robustness of neural networks against energy-oriented attacks. Specifically, we propose ILFO (Intermediate Output Based Loss Function Optimization) at-tack against a type of energy-saving neural networks, Adaptive Neural Networks (AdNN). An AdNN can dynamically deactivate part of its model based on the need of the inputs to decrease energy consumption. ILFO leverage intermediate output as a proxy to infer the relation between input and its corresponding energy consumption. ILFO has shown an increase upto 100 % of the remaining FLOPs (floating-point operations per second) count of AdNNs with minimum noise added to input images. To our knowledge, this is the first attempt to attack the energy consumption of a DNN.","tags":null,"title":"ILFO: Adversarial Attack on Adaptive Neural Networks","type":"publication"},{"authors":["Yuyu He","Lei Zhang","Zhemin Yang","Yinzhi Cao","Keke Lian","Shuai Li","Wei Yang","Zhibo Zhang","Min Yang","Yuan Zhang","Haixin Duan"],"categories":null,"content":"","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578960000,"objectID":"8035a6e79bd1eecea26ab70d7c28ca07","permalink":"http://youngwei.com/publication/textexerciser/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/publication/textexerciser/","section":"publication","summary":"Dynamic analysis of Android apps is often used together with an exerciser to increase its code coverage. One big obstacle in designing such Android app exercisers comes from the existence of text-based inputs, which are often constrained by the nature of the input field, such as the length and character restrictions. \n In this paper, we propose TextExerciser, an iterative, feedback-driven text input exerciser, which generates text inputs for Android apps. Our key insight is that Android apps often provide feedback, called hints, for malformed inputs so that our system can utilize such hints to improve the input generation. \n We implemented a prototype of TextExerciser and evaluated it by comparing TextExerciser with state-of-the-art exercisers, such as The Monkey and DroidBot. Our evaluation shows that TextExerciser can achieve significantly higher code coverage and trigger more sensitive behaviors than these tools. We also combine TextExerciser with dynamic analysis tools and show they are able to detect more privacy leaks and vulnerabilities with TextExerciser than with existing exercisers. Particularly, existing tools, under the help of TextExerciser, find several new vulnerabilities, such as one user credential leak in a popular social app with more than 10,000,000 downloads.","tags":null,"title":"TextExerciser: Feedback-driven Text Input Exercising for Android Applications","type":"publication"},{"authors":["Yueming Wu","Xiaodi Li","Deqing Zou","Wei Yang","Xin Zhang","Hai Jin"],"categories":null,"content":"","date":1564963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564963200,"objectID":"a9577c2e67e0da90dfcda8eb92982491","permalink":"http://youngwei.com/publication/malscan/","publishdate":"2019-08-05T00:00:00Z","relpermalink":"/publication/malscan/","section":"publication","summary":"Malware scanning of an app market is expected to be scalable and effective. However, existing approaches use either syntax-based features which can be evaded by transformation attacks or semantic-based features which are usually extracted by performing expensive program analysis. Therefore, in this paper, we propose a lightweight graph-based approach to perform Android malware detection. Instead of traditional heavyweight static analysis, we treat function call graphs of apps as social networks and perform social-network-based centrality analysis to represent the semantic features of the graphs. Our key insight is that centrality provides a succinct and faulttolerant representation of graph semantics, especially for graphs with certain amount of inaccurate information (e.g., inaccurate call graphs). We implement a prototype system, MalScan, and evaluate it on datasets of 15285 benign samples and 15430 malware samples. Experimental results show that MalScan is capable of detecting Android malware with up to 98% accuracy under one second which is more than 100 times faster than two state-of-the-art approaches, namely MaMaDroid and Drebin. We also demonstrate the feasibility of MalScan on market-wide malware scanning by performing a statistical study on over 3 million apps. Finally, in a corpus of dataset collected from GooglePlay app market, MalScan is able to identify 18 zero-day malware including malware samples that can evade detection of existing tools.","tags":null,"title":"MalScan: Fast Market-Wide Mobile Malware Scanning by Social-Network Centrality Analysis","type":"publication"},{"authors":["Qi Wang","Pubali Datta","Wei Yang","Si Liu","Carl A. Gunter","Adam Bates"],"categories":null,"content":"","date":1563580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563580800,"objectID":"0f36eaf224e30bd9578e465e6ae989fe","permalink":"http://youngwei.com/publication/iruler/","publishdate":"2019-07-20T00:00:00Z","relpermalink":"/publication/iruler/","section":"publication","summary":"Internet of Things (IoT) deployments are becoming increasingly automated and vastly more complex. Facilitated by programming abstractions such as trigger-action rules, end-users can now easily create new functionalities by interconnecting their devices and other online services. However, when multiple rules are simultaneously enabled, complex system behaviors arise that are difficult to understand or diagnose. While history tells us that such conditions are ripe for exploitation, at present the security states of trigger-action IoT deployments are largely unknown. In this work, we conduct a comprehensive analysis of the interactions between trigger-action rules in order to identify their security risks. Using IFTTT as an exemplar platform, we first enumerate the space of inter-rule vulnerabilities that exist within trigger-action platforms. To aid users in the identification of these dangers, we go on to present iRuler, a system that performs Satisfiability Modulo Theories (SMT) solving and model checking to discover inter-rule vulnerabilities within IoT deployments. iRuler operates over an abstracted information flow model that represents the attack surface of an IoT deployment, but we discover in practice that such models are difficult to obtain given the closed nature of IoT platforms. To address this, we develop methods that assist in inferring triggeraction information flows based on Natural Language Processing. We develop a novel evaluative methodology for approximating plausible real-world IoT deployments based on the installation counts of 315,393 IFTTT applets, determining that 66% of the synthetic deployments in the IFTTT ecosystem exhibit the potential for interrule vulnerabilities. Combined, these efforts provide the insight into the real-world dangers of IoT deployment misconfigurations.","tags":null,"title":"Charting the Attack Surface of Trigger-Action IoT Platforms","type":"publication"},{"authors":["Zhengkai Wu","Evan N. Johnson","Wei Yang","Osbert Bastani","Dawn Song","Jian Peng","Tao Xie"],"categories":null,"content":"","date":1558742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558742400,"objectID":"136fd391cc4c5b8d2c4e48ecc8a48a36","permalink":"http://youngwei.com/publication/reinam/","publishdate":"2019-05-25T00:00:00Z","relpermalink":"/publication/reinam/","section":"publication","summary":"Program-input grammars (i.e., grammars encoding the language of valid program inputs) facilitate a wide range of applications in software engineering such as symbolic execution and delta debugging. Grammars synthesized by existing approaches can cover only a small part of the valid input space mainly due to unanalyzable code (e.g., native code) in programs and lacking high-quality, high-variety, and high-quantity seed inputs. To address these challenges, we present REINAM, a reinforcement-learning approach for synthesizing a probabilistic context-free program-input grammars without any seed input. REINAM includes an industrial symbolic execution engine to generate an initial set of inputs for the given target program, and includes an iterative process of grammar generalization to proactively generate additional inputs in order to infer grammars generalized from the initial seed inputs. To efficiently search for target generalizations in a huge search space of candidate generalization operators, REINAM includes a novel formulation of the search problem as the problem of reinforcement learning. Our evaluation results on five real-world subjects show that REINAM outperforms an existing state-of-the-art approach on precision and recall of synthesized grammars, and fuzz testing based on REINAM substantially increases the coverage of the valid input space. REINAM is able to synthesize a grammar covering the whole valid input space for some subjects without decreasing accuracy of the grammar.","tags":null,"title":"REINAM: Reinforcement Learning for Input-Grammar Inference","type":"publication"},{"authors":["Wenyu Wang","Wujie Zheng","Dian Liu","Changrong Zhang","Qinsong Zeng","Yuetang Deng","Wei Yang","Pinjia He","Tao Xie"],"categories":null,"content":"","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551744000,"objectID":"b642b632a7fa8f3484e7046a46d819a4","permalink":"http://youngwei.com/publication/dsn19_industry/","publishdate":"2019-03-05T00:00:00Z","relpermalink":"/publication/dsn19_industry/","section":"publication","summary":"Despite getting widely adopted recently, a Neural Machine Translation (NMT) system is often found to produce translation failures in the outputs. Developers have been relying on in-house system testing for quality assurance of NMT. This testing methodology requires human-constructed reference translations as the ground truth (test oracle) for example natural language inputs. The testing methodology has shown benefits of quickly enhancing an NMT system in early development stages. However, in industrial settings, it is desirable to detect translation failures without reliance on reference translations for enabling further improvements on translation quality in both industrial development and production environments. Aiming for a practical and scalable solution to such demand in the industrial settings, in this paper, we propose a new approach for automatically identifying translation failures without requiring reference translations for a translation task. Our approach focuses on a property of natural language translation that can be checked systematically by using information from both the test inputs (i.e., the texts to be translated) and the test outputs (i.e., the translations under inspection) of the NMT system. Our evaluation conducted on real-world datasets shows that our approach can effectively detect property violations as translation failures. By deploying our approach in the translation service of WeChat (a messenger app with more than one billion monthly active users), we show that our approach is both practical and scalable in the industrial settings.","tags":null,"title":"Detecting Failures of Neural Machine Translation in the Absence of Reference Translations","type":"publication"},{"authors":["Wujie Zheng","Wenyu Wang","Dian Liu","Changrong Zhang","Qinsong Zeng","Yuetang Deng","Wei Yang","Pinjia He","Tao Xie"],"categories":null,"content":"","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551744000,"objectID":"b29600850a3220dccd90b299a2abba86","permalink":"http://youngwei.com/publication/icse19_poster/","publishdate":"2019-03-05T00:00:00Z","relpermalink":"/publication/icse19_poster/","section":"publication","summary":"Neural Machine Translation (NMT) has shown great advantages and is becoming increasingly popular. However, in practice, NMT often produces unexpected translation failures in its translations. While reference-based black-box system testing has been a common practice for NMT quality assurance during development, an increasingly critical industrial practice, named in-vivo testing, exposes unseen types or instances of translation failures when real users are using a deployed industrial NMT system. To fill the gap of lacking test oracles for in-vivo testing of NMT systems, we propose a new methodology for automatically identifying translation failures without reference translations. Our evaluation conducted on real-world datasets shows that our methodology effectively detects several targeted types of translation failures. Our experiences on deploying our methodology in both production and development environments of WeChat (a messenger app with over one billion monthly active users) demonstrate high effectiveness of our methodology along with high industry impact.","tags":null,"title":"Testing Untestable Neural Machine Translation: An Industrial Case","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1545264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545264000,"objectID":"2387cefccfe6937de11eb6dfb2bcd639","permalink":"http://youngwei.com/talk/pku2018/","publishdate":"2018-12-20T00:00:00Z","relpermalink":"/talk/pku2018/","section":"talk","summary":"For too long, researchers have often tackled security in an attack-driven, ad hoc, and reactionary manner with large manual efforts devoted by security analysts. In order to make substantial progress in security, I advocate to shift such manner to be systematic, intelligent, and adversarial resilient. I have developed software engineering techniques to automate decision makings in security systems, and built defenses and testing methodologies to guard against emerging attacks specifically adversarial to these newly-proposed techniques. In this talk, I will first highlight one of these systems for mobile security: AppContext, a malware detection system extracting execution contexts of an app’s security-sensitive behaviors through program analysis. Then I will show how an adaptive adversary can attack these systems and how we can generate adversarial inputs ahead of time for testing and further strengthening these systems. I will conclude by discussing how future research efforts can leverage the interplay among software engineering, security, and AI techniques toward a defense-driven security ecosystem.","tags":null,"title":"Adversarial-Resilience Assurance for Mobile Security Systems.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1545004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545004800,"objectID":"c4fdbe13c4f766f21ed1d77ecb06f6c0","permalink":"http://youngwei.com/talk/fudan2018/","publishdate":"2018-12-17T00:00:00Z","relpermalink":"/talk/fudan2018/","section":"talk","summary":"For too long, researchers have often tackled security in an attack-driven, ad hoc, and reactionary manner with large manual efforts devoted by security analysts. In order to make substantial progress in security, I advocate to shift such manner to be systematic, intelligent, and adversarial resilient. I have developed software engineering techniques to automate decision makings in security systems, and built defenses and testing methodologies to guard against emerging attacks specifically adversarial to these newly-proposed techniques. In this talk, I will first highlight one of these systems for mobile security: AppContext, a malware detection system extracting execution contexts of an app’s security-sensitive behaviors through program analysis. Then I will show how an adaptive adversary can attack these systems and how we can generate adversarial inputs ahead of time for testing and further strengthening these systems. I will conclude by discussing how future research efforts can leverage the interplay among software engineering, security, and AI techniques toward a defense-driven security ecosystem.","tags":null,"title":"Adversarial Learning and Mobile Security System.","type":"talk"},{"authors":["Zexuan Zhong","Jiaqi Guo","Wei Yang","Jian Peng","Tao Xie","Jian-Guang Lou","Ting Liu","Dongmei Zhang"],"categories":null,"content":"","date":1532908800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532908800,"objectID":"f0db75ada8eb2e39c0e74197984bd4e7","permalink":"http://youngwei.com/publication/semregex/","publishdate":"2018-07-30T00:00:00Z","relpermalink":"/publication/semregex/","section":"publication","summary":"Recent research proposes syntax-based approaches to address the problem of generating programs from natural language specifications. These approaches typically train a sequence-to-sequence learning model using a syntax-based objective: maximum likelihood estimation (MLE). Such syntax-based approaches do not effectively address the goal of generating semantically correct programs, because these approaches fail to handle Program Aliasing, i.e., semantically equivalent programs may have many syntactically different forms. To address this issue, in this paper, we propose a semantics-based approach named SemRegex. SemRegex provides solutions for a subtask of the program-synthesis problem: generating regular expressions from natural language. Different from the existing syntax-based approaches, SemRegex trains the model by maximizing the expected semantic correctness of the generated regular expressions. The semantic correctness is measured using the DFA-equivalence oracle, random test cases, and distinguishing test cases. The experiments on three public datasets demonstrate the superiority of SemRegex over the existing state-of-the-art approaches.","tags":null,"title":"SemRegex: A Semantics-Based Approach for Generating Regular Expressions from Natural Language Specifications","type":"publication"},{"authors":["Karan Ganju","Qi Wang","Wei Yang","Carl A. Gunter","Nikita Borisov"],"categories":null,"content":"","date":1531612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531612800,"objectID":"252dac2a87782dad45b98f7856b34e53","permalink":"http://youngwei.com/publication/permuteinvariance/","publishdate":"2018-07-15T00:00:00Z","relpermalink":"/publication/permuteinvariance/","section":"publication","summary":"With the growing adoption of machine learning, sharing of learned models is becoming popular. However, in addition to the prediction properties the model producer aims to share, there is also a risk that the model consumer can infer other properties of the training data the model producer did not intend to share. In this paper, we focus on the inference of global properties of the training data, such as the environment in which the data was produced, or the fraction of the data that comes from a certain class, as applied to white-box Fully Connected Neural Networks (FCNNs).  Because of their complexity and inscrutability, FCNNs have a particularly high risk of leaking unexpected information about their training sets; at the same time, this complexity makes extracting this information challenging. We develop techniques that reduce this complexity by noting that FCNNs are invariant under permutation of nodes in each layer. We develop our techniques using representations that capture this invariance and simplify the information extraction task. We evaluate our techniques on several synthetic and standard benchmark datasets and show that they are very effective at inferring various data properties.  We also perform two case studies to demonstrate the impact of our attack. In the first case study we show that a classifier that recognizes smiling faces also leaks information about the relative attractiveness of the individuals in its training set. In the second case study we show that a classifier that recognizes Bitcoin mining from performance counters also leaks information about whether the classifier was trained on logs from machines that were patched for the Meltdown and Spectre attacks.","tags":null,"title":"Property Inference Attacks on Deep Neural Networks using Permutation Invariant Representations","type":"publication"},{"authors":["Xueqing Liu","Yue Leng","Wei Yang","Wenyu Wang","Chengxiang Zhai","Tao Xie"],"categories":null,"content":"","date":1529020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529020800,"objectID":"0e9de60cd8cb5d6e15445752320d0e9f","permalink":"http://youngwei.com/publication/clap_vlhcc/","publishdate":"2018-06-15T00:00:00Z","relpermalink":"/publication/clap_vlhcc/","section":"publication","summary":"After Android 6.0 introduces the runtimepermission system, many apps provide runtime-permissiongroup rationales for the users to better understand the permissions requested by the apps. To understand the patterns of rationales and to what extent the rationales can improve the users’ understanding of the purposes of requesting permission groups, we conduct a large-scale measurement study on five aspects of runtime rationales. We have five main findings: (1) less than 25% apps under study provide rationales; (2) for permission-group purposes that are difficult to understand, the proportions of apps that provide rationales are even lower; (3) the purposes stated in a significant proportion of rationales are incorrect; (4) a large proportion of customized rationales do not provide more information than the default permission-requesting message of Android; (5) apps that provide rationales are more likely to explain the same permission group’s purposes in their descriptions than apps that do not provide rationales. We further discuss important implications from these findings.","tags":null,"title":"A Large-Scale Empirical Study on Android Runtime Permission Rationale Messages","type":"publication"},{"authors":["Wenyu Wang","Dengfeng Li","Wei Yang","Yurui Cao","Zhenwen Zhang","Yuetang Deng","Tao Xie"],"categories":null,"content":"","date":1529020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529020800,"objectID":"0e51e5cffc7ed195e7fe0f2fe026fdab","permalink":"http://youngwei.com/publication/wctester/","publishdate":"2018-06-15T00:00:00Z","relpermalink":"/publication/wctester/","section":"publication","summary":"User Interface (UI) testing is a popular approach to ensure the quality of mobile apps. Numerous test generation tools have been developed to support UI testing on mobile apps, especially for Android apps. Previous work evaluates and compares different test generation tools using only relatively simple open-source apps, while real-world industrial apps tend to have more complex functionalities and implementations. There is no direct comparison among test generation tools with regard to effectiveness and easeof-use on these industrial apps. To address such limitation, we study existing state-of-the-art or state-of-the-practice test generation tools on 68 widely-used industrial apps. We directly compare the tools with regard to code coverage and fault-detection ability. According to our results, Monkey, a state-of-the-practice tool from Google, achieves the highest method coverage on 22 of 41 apps whose method coverage data can be obtained. Of all 68 apps under study, Monkey also achieves the highest activity coverage on 35 apps, while Stoat, a state-of-the-art tool, is able to trigger the highest number of unique crashes on 23 apps. By analyzing the experimental results, we provide suggestions for combining different test generation tools to achieve better performance. We also report our experience in applying these tools to industrial apps under study. Our study results give insights on how Android UI test generation tools could be improved to better handle complex industrial apps.","tags":null,"title":"An Empirical Study of Android Test Generation Tools in Industrial Cases","type":"publication"},{"authors":["Xueqing Liu","Yue Leng","Wei Yang","Chengxiang Zhai","Tao Xie"],"categories":null,"content":"","date":1527638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527638400,"objectID":"a6d3330a768a2044a7dfb70d6aa2c2b6","permalink":"http://youngwei.com/publication/clap_re/","publishdate":"2018-05-30T00:00:00Z","relpermalink":"/publication/clap_re/","section":"publication","summary":"During the development or maintenance of an Android app, the app developer needs to determine the app’s security and privacy requirements such as permission requirements. Permission requirements include two folds: (1) what permissions (i.e., access to sensitive resources, e.g., location or contact list) the app needs to request, and (2) how to explain the reason of permission usages to users. In this paper, we focus on the multiple challenges that developers face when creating the explanations for permission usages. We propose a novel framework, CLAP, that mines potential explanations from the descriptions of similar apps. CLAP leverages information retrieval and text summarization techniques to find frequent permission usages. We evaluate CLAP on a large dataset containing 1.4 million Android apps. The evaluation results show that CLAP outperforms existing stateof-the-art approaches, and has great promise to assist developers for permission requirements discovery.","tags":null,"title":"Mining Android App Description for Permission Requirements Recommendation","type":"publication"},{"authors":["Wei Yang","Mukul Prasad","Tao Xie"],"categories":null,"content":"","date":1526342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526342400,"objectID":"965a04034cf5b8ce30559ecc07b9a531","permalink":"http://youngwei.com/publication/enmobile/","publishdate":"2018-05-15T00:00:00Z","relpermalink":"/publication/enmobile/","section":"publication","summary":"Modern mobile malware tend to conduct their malicious exploits through sophisticated patterns of interactions that involve multiple entities, e.g., the mobile platform, human users, and network locations. Such malware often evade the detection by existing approaches due to their limited expressiveness and accuracy in characterizing and detecting these malware. To address these issues, in this paper, we recognize entities in the environment of an app, the app’s interactions with such entities, and the provenance of these interactions, i.e., the intent and ownership of each interaction, as the key to comprehensively characterizing modern mobile apps, and mobile malware in particular. With this insight, we propose a novel approach named EnMobile including a new entity-based characterization of mobile-app behaviors, and corresponding static analyses, to accurately characterize an app’s interactions with entities. We implement EnMobile and provide a practical application of EnMobile in a signature-based scheme for detecting mobile malware. We evaluate EnMobile on a set of 6614 apps consisting of malware from Genome and Drebin along with benign apps from Google Play. Our results show that EnMobile detects malware with substantially higher precision and recall than four state-of-the-art approaches, namely Apposcopy, Drebin, MUDFLOW, and AppContext.","tags":null,"title":"EnMobile: Entity-based Characterization and Analysis of Mobile Malware","type":"publication"},{"authors":["Zexuan Zhong","Jiaqi Guo","Wei Yang","Tao Xie","Jian-Guang Lou","Ting Liu","Dongmei Zhang"],"categories":null,"content":"","date":1517270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517270400,"objectID":"690ede48a5a96ba31024068dcf5d4f74","permalink":"http://youngwei.com/publication/semregex-aaai/","publishdate":"2018-01-30T00:00:00Z","relpermalink":"/publication/semregex-aaai/","section":"publication","summary":"Recent state-of-the-art approaches automatically generate regular expressions from natural language specifications. Given that these approaches use only synthetic data in both training datasets and validation/test datasets, a natural question arises: are these approaches effective to address various real-world situations? To explore this question, in this paper, we conduct a characteristic study on comparing two synthetic datasets used by the recent research and a real-world dataset collected from the Internet, and conduct an experimental study on applying a state-of-the-art approach on the real-world dataset. Our study results suggest the existence of distinct characteristics between the synthetic datasets and the real-world dataset, and the state-of-the-art approach (based on a model trained from a synthetic dataset) achieves extremely low effectiveness when evaluated on real-world data, much lower than the effectiveness when evaluated on the synthetic dataset. We also provide initial analysis on some of those challenging cases and discuss future directions.","tags":null,"title":"Generating Regular Expressions from Natural Language Specifications: Are We There Yet?","type":"publication"},{"authors":["Wei Yang","Tao Xie"],"categories":null,"content":"","date":1515974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515974400,"objectID":"026a1f8601da006d613493972298e057","permalink":"http://youngwei.com/publication/telemade/","publishdate":"2018-01-15T00:00:00Z","relpermalink":"/publication/telemade/","section":"publication","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads. To address the challenge, we propose Telemade, a testing framework for learning-based malware detectors.","tags":null,"title":"Telemade: A Testing Framework for Learning-Based Malware Detection Systems. ","type":"publication"},{"authors":["Wei Yang","Deguang Kong","Tao Xie","Carl A. Gunter"],"categories":null,"content":"","date":1513296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513296000,"objectID":"b02f5a89209816587da7bec0c2357f1b","permalink":"http://youngwei.com/publication/mrv/","publishdate":"2017-12-15T00:00:00Z","relpermalink":"/publication/mrv/","section":"publication","summary":"Existing techniques on adversarial malware generation employ feature mutations based on feature vectors extracted from malware. However, most (if not all) of these techniques suffer from a common limitation: feasibility of these attacks is unknown. The synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads. To address the limitation, we present Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and malware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we conduct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants. We evaluate our MRV approach on actual malware variants, and our empirical evaluation on 1,935 Android benign apps and 1,917 malware shows that MRV produces malware variants that can have high likelihood to evade detection while still retaining their malicious behaviors. We also propose and evaluate three defense mechanisms to counter MRV.","tags":null,"title":"Malware Detection in Adversarial Settings: Exploiting Feature Evolutions and Confusions in Android Apps","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"049b43a1b4527f76346e7294b31ba7b1","permalink":"http://youngwei.com/talk/mwpls-2017/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/talk/mwpls-2017/","section":"talk","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads.","tags":null,"title":"Generating Adversarial Examples with Program Transformations: Practical Attacks to Machine Learner.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508803200,"objectID":"a46e0186da8b4a4d7947e1348c865957","permalink":"http://youngwei.com/talk/sjtu2017/","publishdate":"2017-10-24T00:00:00Z","relpermalink":"/talk/sjtu2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection.In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of securitysensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and malware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we conduct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"a6ca05815811676883dc49141fcd871c","permalink":"http://youngwei.com/talk/fudan2017/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/talk/fudan2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection. In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. \n\n In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and mal- ware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we con- duct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508371200,"objectID":"651ea80d375835ecceb03376c5533af0","permalink":"http://youngwei.com/talk/ecnu2017/","publishdate":"2017-10-19T00:00:00Z","relpermalink":"/talk/ecnu2017/","section":"talk","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads.","tags":null,"title":"Testing Learning-Based Security System: Generating Adversarial Samples for Static Analysis and Machine Learning.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508284800,"objectID":"c0398c9b862fd31a05bc8daede6d8c28","permalink":"http://youngwei.com/talk/shanghaitech2017/","publishdate":"2017-10-18T00:00:00Z","relpermalink":"/talk/shanghaitech2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection. In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. \n\n In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and mal- ware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we con- duct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Haibing Zheng","Dengfeng Li","Beihai Liang","Xia Zeng","Wujie Zheng","Yuetang Deng","Wing Lam","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1494806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494806400,"objectID":"32c599bc2efc60bcfcd029ad6b3f6fb1","permalink":"http://youngwei.com/publication/wctester_icse17/","publishdate":"2017-05-15T00:00:00Z","relpermalink":"/publication/wctester_icse17/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Automated Test Input Generation for Android: Towards Getting There in an Industrial Case","type":"publication"},{"authors":["Dengfeng Li","Wing Lam","Wei Yang","Zhengkai Wu","Xusheng Xiao","Tao Xie"],"categories":null,"content":"","date":1492214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492214400,"objectID":"984c5506afd7c8063fee0efe55794de3","permalink":"http://youngwei.com/publication/hotsos17/","publishdate":"2017-04-15T00:00:00Z","relpermalink":"/publication/hotsos17/","section":"publication","summary":"As mobile apps are increasingly becoming data-driven, these apps tend to collect much app usage data to carry out their promised utilities and enhance user experiences. Unfortunately, some highly sensitive information in the data provides little or no benefit towards delivering the apps’ utilities. For instance, for an app whose purpose is to show video game trailers, it is unnecessary to request and send its users’ phone number and contact list to a remote server. There is a strong need for a framework to help protect users’ app usage data while retaining the app’s utility efficacy (e.g., the number of enabled features). \n \n  There are three main challenges in realizing such framework. First, it is difficult to correctly identify security-sensitive information in the app usage data. For instance, user input text (such as “My password is 12345”) can contain sensitive information, and such framework needs to understand the semantic meaning of such text in order to know whether sensitive information is present or not. Second, because utilities of apps vary dramatically, there is a need for generically applicable program analysis to measure the impact of information anonymization on the level of utility efficacy. Third, balancing privacy preservation and utility efficacy requires fine-grained analysis on privacy specification (such as a privacy policy declared by the app’s developers) and the app. To address these challenges, we propose a privacy framework that enables a mobile app’s developers to determine what sensitive information can be anonymized while maintaining a desirable level of utility efficacy.","tags":null,"title":"Towards Privacy-Preserving Mobile Apps: A Balancing Act. ","type":"publication"},{"authors":["Soteris Demetriou","Whitney Merrill","Wei Yang","Aston Zhang","Carl A. Gunter"],"categories":null,"content":"","date":1481760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481760000,"objectID":"30da4d9c443ecd193ca2d8e6a8f53b08","permalink":"http://youngwei.com/publication/pluto/","publishdate":"2016-12-15T00:00:00Z","relpermalink":"/publication/pluto/","section":"publication","summary":"In this work, we systematically explore the potential reach of advertising libraries through these channels. We design a framework called Pluto that can be leveraged to analyze an app and discover whether it exposes targeted user data—such as contact information, interests, demographics, medical conditions and so on—-to an opportunistic ad library. We present a prototype implementation of Pluto, that embodies novel strategies for using natural language processing to illustrate what targeted data can potentially be learned from an ad network using files and user inputs. Pluto also leverages machine learning and data mining models to reveal what advertising networks can learn from the list of installed apps. We validate Pluto with a collection of apps for which we have determined ground truth about targeted data they may reveal, together with a data set derived from a survey we conducted that gives ground truth for targeted data and corresponding lists of installed apps for about 300 users. We use these to show that Pluto, and hence also opportunistic ad networks, can achieve 75% recall and 80% precision for selected targeted data coming from app files and inputs, and even better results for certain targeted data based on the list of installed apps. Pluto is the first tool that estimates the risk associated with integrating advertising in apps based on the four available channels and arbitrary sets of targeted data.","tags":null,"title":"Free for All! Assessing User Data Exposure to Advertising Libraries on Android","type":"publication"},{"authors":["Xia Zeng","Dengfeng Li","Wujie Zheng","Fan Xia","Yuetang Deng","Wing Lam","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1476489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476489600,"objectID":"d69584865984ae27306f414c4348456d","permalink":"http://youngwei.com/publication/wctester_fse16/","publishdate":"2016-10-15T00:00:00Z","relpermalink":"/publication/wctester_fse16/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Automated Test Input Generation for Android: Are We Really There Yet in an Industrial Case?","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1470960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470960000,"objectID":"0b3a468e04a4e31bdef6adbf7f551054","permalink":"http://youngwei.com/talk/ibm2/","publishdate":"2016-08-12T00:00:00Z","relpermalink":"/talk/ibm2/","section":"talk","summary":"Identifying similar code in software systems can assist many software engineering tasks such as program understanding and software refactoring. While most approaches focus on identifying syntactically similar code (i.e., code that looks alike), Ideally, we would like to also include code that is behaviorally or functionally similar, even if it looks completely different. Detecting these functional clones — code that functions alike — in mobile applications remains an open question because of the difficulty in exposing and comparing programs’ functionality effectively. In this talk, I will present a novel technique that detects functional clones in complex mobile app codebases by identifying and comparing their user interface and key API method calls. The key insight is that user interface usually indicate the functionality to be implemented by a program which complements existing program analysis to detect functional clones.","tags":null,"title":"Searching Functionally Similar Code via UI Prototype.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1468195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1468195200,"objectID":"0ae2e6d056e0acb527f63fb9e16dfec5","permalink":"http://youngwei.com/talk/ibm1/","publishdate":"2016-07-11T00:00:00Z","relpermalink":"/talk/ibm1/","section":"talk","summary":"Numerous apps on the mobile-app market such as team management present opportunities beyond traditional mobile and email communications, greatly enhancing the productivity and mobility of employees in companies. However, these apps may contain unwanted behaviors, such as information leakage and root exploits, and thus violates enterprise security policies. Unwanted behaviors in mobile app can evade detection during app analysis by mimicking security-sensitive behaviors of benign behaviors that provide similar functionality (e.g., sending SMS messages), and suppressing their payload to reduce the chance of being observed (e.g., executing only its payload at night). Since current approaches focus their analyses on the types of security-sensitive resources being accessed (e.g., network), these evasive techniques make differentiating between unwanted and benign app behaviors a difficult task during app analysis. In this talk, I propose that unwanted and benign behaviors within apps can be differentiated based on the contexts that trigger security-sensitive behaviors, i.e., the events and conditions that cause the security-sensitive behaviors to occur. I will first introduce AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. Then, I will introduce WHYPER, a technique that explain why sensitive user information is used by the applications to help users make better decisions in permission granting. Next, I will briefly mention the malware recomposition variation (MRV) technique that can attack the proposed contextually-aware detection technique by systematically producing malware variants. Last, I will give an introduction on Smar (Systematic Mobile App Repair), that iteratively repairs unwanted behaviors at all four levels of granularity (“where”, “when”, “what”, and “how”).","tags":null,"title":"Contextually-Aware Mobile Security: Identification, Variation and Fixing of Mobile Threats.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Dengfeng Li","Huoran Li","Xuanzhe Liu","Haoyu Wang","Yao Guo","Tao Xie"],"categories":null,"content":"","date":1460678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1460678400,"objectID":"ae5d577411751f7d6799770a14d02b1c","permalink":"http://youngwei.com/publication/jcs_journal/","publishdate":"2016-04-15T00:00:00Z","relpermalink":"/publication/jcs_journal/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Security Analytics for Mobile Apps: Achievements and Challenges.","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1458000000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458000000,"objectID":"9b7b1b37f20546dc477b3c31d0d920a4","permalink":"http://youngwei.com/talk/qualcomm2016/","publishdate":"2016-03-15T00:00:00Z","relpermalink":"/talk/qualcomm2016/","section":"talk","summary":"What an application (or “app”) does is not always what a user expects. User expectations stem from user perceptions (information they can perceive about an application). User perceptions come from two sources: app descriptions form user perception before installation, and user interfaces enrich user perception after installation. Two types of inconsistencies, corresponding to each of these sources, contribute to the gap between app behavior and user perception. (1) Install-time inconsistency involves the functionalities described in app descriptions being inconsistent with the actual app behaviors. (2) Run-time inconsistency involves the behavior indicated through user interfaces (external behavior) being inconsistent with the behavior running in the background (internal behavior). In this proposal, we aim to bridge the gap between user perception and app behavior by developing a set of automated analyses to check these two inconsistencies and warn users about potential risks.","tags":null,"title":"Validating Application Behavior against User Expectations.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Benjamin Andow","Sihan Li","Tao Xie","William Enck"],"categories":null,"content":"","date":1450137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450137600,"objectID":"e5f00ebd10d5e66e87712c6477de2c76","permalink":"http://youngwei.com/publication/appcontext/","publishdate":"2015-12-15T00:00:00Z","relpermalink":"/publication/appcontext/","section":"publication","summary":"Mobile malware attempts to evade detection during app analysis by mimicking security-sensitive behaviors of benign apps that provide similar functionality (e.g., sending SMS messages), and suppressing their payload to reduce the chance of being observed (e.g., executing only its payload at night). Since current approaches focus their analyses on the types of securitysensitive resources being accessed (e.g., network), these evasive techniques in malware make differentiating between malicious and benign app behaviors a difficult task during app analysis. We propose that the malicious and benign behaviors within apps can be differentiated based on the contexts that trigger securitysensitive behaviors, i.e., the events and conditions that cause the security-sensitive behaviors to occur. In this work, we introduce AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. We implement a prototype of AppContext and evaluate AppContext on 202 malicious apps from various malware datasets, and 633 benign apps from the Google Play Store. AppContext correctly identifies 192 malicious apps with 87.7% precision and 95% recall. Our evaluation results suggest that the maliciousness of a security-sensitive behavior is more closely related to the intention of the behavior (reflected via contexts) than the type of the security-sensitive resources that the behavior accesses.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1450051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450051200,"objectID":"43931ad1e082b4ea06d1253a2ec361b9","permalink":"http://youngwei.com/talk/sjtu2015/","publishdate":"2015-12-14T00:00:00Z","relpermalink":"/talk/sjtu2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1437091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437091200,"objectID":"5a49ac11d3dc7acda35ec166c074502f","permalink":"http://youngwei.com/talk/sri2015/","publishdate":"2015-07-17T00:00:00Z","relpermalink":"/talk/sri2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1424995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1424995200,"objectID":"6af637e8f1bec9a513fc4d43ec746c00","permalink":"http://youngwei.com/talk/csl2015/","publishdate":"2015-02-27T00:00:00Z","relpermalink":"/talk/csl2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"Improving Mobile Application Security via Bridging User Expectations and Application Behaviors.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Rahul Pandita","William Enck","Tao Xie"],"categories":null,"content":"","date":1397520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1397520000,"objectID":"8d53210094fa198b5526ab40a6c4e515","permalink":"http://youngwei.com/publication/hotsos14/","publishdate":"2014-04-15T00:00:00Z","relpermalink":"/publication/hotsos14/","section":"publication","summary":"To keep malware out of mobile application markets, existing techniques analyze the security aspects of application behaviors and summarize patterns of these security aspects to determine what applications do. However, user expectations (reflected via user perception in combination with user judgment) are often not incorporated into such analysis to determine whether application behaviors are within user expectations. This poster presents our recent work on bridging the semantic gap between user perceptions of the application behaviors and the actual application behaviors.","tags":null,"title":"Improving Mobile Application Security via Bridging User Expectations and Application Behaviors.","type":"publication"},{"authors":["Rahul Pandita","Xusheng Xiao","Wei Yang","William Enck","Tao Xie"],"categories":null,"content":"","date":1387065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1387065600,"objectID":"60b7507c13c0822157cd22272f960284","permalink":"http://youngwei.com/publication/whyper/","publishdate":"2013-12-15T00:00:00Z","relpermalink":"/publication/whyper/","section":"publication","summary":"Application markets such as Apple’s App Store and Google’s Play Store have played an important role in the popularity of smartphones and mobile devices. However, keeping malware out of application markets is an ongoing challenge. While recent work has developed various techniques to determine what applications do, no work has provided a technical approach to answer, what do users expect? In this paper, we present the first step in addressing this challenge. Specifically, we focus on permissions for a given application and examine whether the application description provides any indication for why the application needs a permission. We present WHYPER, a framework using Natural Language Processing (NLP) techniques to identify sentences that describe the need for a given permission in an application description. WHYPER achieves an average precision of 82.8%, and an average recall of 81.5% for three permissions (address book, calendar, and record audio) that protect frequentlyused security and privacy sensitive resources. These results demonstrate great promise in using NLP techniques to bridge the semantic gap between user expectations and application functionality, further aiding the risk assessment of mobile applications.","tags":null,"title":"WHYPER: Towards Automating Risk Assessment of Mobile Applications","type":"publication"},{"authors":["Wei Yang","Mukul Prasad","Tao Xie"],"categories":null,"content":"","date":1360886400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1360886400,"objectID":"99fcd9071b7382bde04ce24d4bb208da","permalink":"http://youngwei.com/publication/orbit/","publishdate":"2013-02-15T00:00:00Z","relpermalink":"/publication/orbit/","section":"publication","summary":"As the mobile platform continues to pervade all aspects of human activity, and mobile apps on this platform tend to be faulty just like other types of software, there is a growing need for automated testing techniques for mobile applications. Model-based testing is a popular and important testing approach which operates on a model of an application’s behavior. However, such a model is often not available or of insufficient quality. To address this issue, we present a novel grey-box approach for automatically extracting a model of a given mobile application. In our approach, static analysis extracts the set of events supported by the Graphical User Interface (GUI) of the application. Then dynamic crawling reverse-engineers a model of the application, by systematically exercising these events on the running application. We also present a tool implementing this approach for the Android platform. Our empirical evaluation of this tool on several Android applications demonstrates that it can efficiently extract compact yet reasonably comprehensive models of high quality for such applications.","tags":null,"title":"A Grey-box Approach for Automated GUI-Model Generation of Mobile Applications","type":"publication"}]