[{"authors":["Yueming Wu","Shihan Dou","Deqing Zou","Wei Yang","Weizhong Qiang","Hai Jin"],"categories":null,"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"f6e29d57fb088f4955a8dbf0ac1b70c7","permalink":"http://youngwei.com/publication/ifdroid/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/ifdroid/","section":"publication","summary":"Due to its open-source nature, Android operating system has been the main target of attackers to exploit. Malware creators always perform different code obfuscations on their apps to hide malicious activities. Features extracted from these obfuscated samples through program analysis contain many useless and disguised features, which leads to many false negatives. To address the issue, in this paper, we demonstrate that obfuscation-resilient malware family analysis can be achieved through contrastive learning. The key insight behind our analysis is that contrastive learning can be used to reduce the difference introduced by obfuscation while amplifying the difference between malware and other types of malware. Based on the proposed analysis, we design a system that can achieve robust and interpretable classification of Android malware. To achieve robust classification, we perform contrastive learning on malware samples to learn an encoder that can automatically extract robust features from malware samples. To achieve interpretable classification, we transform the function call graph of a sample into an image by centrality analysis. Then the corresponding heatmaps can be obtained by visualization techniques. These heatmaps can help users understand why the malware is classified as this family. Weimplement IFDroid and perform extensive evaluations on two datasets. Experimental results show that IFDroid is superior to state-of-the-art Android malware familial classification systems. Moreover, IFDroid is capable of maintaining a 98.4% F1 on classifying 69,421 obfuscated malware samples.","tags":null,"title":"Contrastive Learning for Robust Android Malware Familial Classification","type":"publication"},{"authors":["Zihe Song","Yingfeng Chen","Lei Ma","Shangjie Lu","Honglei Lin","Changjie Fan","Wei Yang"],"categories":null,"content":"","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"8091ddc735192121132106f6b230d320","permalink":"http://youngwei.com/publication/gamecompatstudy/","publishdate":"2022-08-28T00:00:00Z","relpermalink":"/publication/gamecompatstudy/","section":"publication","summary":"Detecting and fixing compatibility issues become increasingly important for mobile game development. The con- stant evolution of mobile operating systems and the severe fragmentation of mobile devices makes it challenging for game developers to detect and fix compatibility issues in time for various device models. The undetected compatibility issues can ruin the user experience, and cause financial loss to game companies and players. Unfortunately, up to the present, mobile game testing is still rather challenging in general. The pressing compatibility issue of mobile games is largely untouched in the research community so far. To bridge the gap, in this experience paper, we perform an empirical study on common compatibility issues of popular commercial mobile games. In particular, we select four active and representative mobile games with well-documented bug reports, containing over seven million lines of code and over 20,000 commits over the past several years. We successfully create a dataset with complete information about bugs and bug fixing details, to investigate the common compatibility issues and fixing strategies. We performed an in-depth manual inspection of the most common symptoms and root causes of these compatibility issues, and analyzed the common fixing strategies of issues under each root cause category. We believe our findings and implications are useful for developers in addressing compatibility hurdles during the developing process. Our results also provide insights for future research on compatibility issue testing and bug fixing for mobile games. ","tags":null,"title":"An Empirical Analysis of Compatibility Issues for Industrial Mobile Games","type":"publication"},{"authors":["Simin Chen","Mirazul Haque","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"2c8e854b9fe021ac1a80098f2cbd685d","permalink":"http://youngwei.com/publication/deepperform/","publishdate":"2022-08-28T00:00:00Z","relpermalink":"/publication/deepperform/","section":"publication","summary":"Today, an increasing number of Adaptive Deep Neural Networks (AdNNs) are being used to make decisions on resource-constrained embedded devices. We observe that, similar to traditional software, redundant computations exist in AdNNs, resulting in considerable performance degradation. The performance degradation in AdNNs is dependent on the input workloads, and is referred to as input-dependent performance bottlenecks (IDPBs). To ensure an AdNN satisfies the performance requirements of real-time applications, it is essential to conduct performance testing to detect IDPBs in the AdNN. Existing neural network testing methods are primarily concerned with correctness testing, which does not involve performance testing. To fill this gap, we propose DeepPerform, a scalable approach to generate test samples to detect the IDPB of AdNNs. We first demonstrate how the problem of generating performance test samples detecting IDPBs can be formulated as an optimization problem. Following that, we demonstrate how tool efficiently handles the optimization problem by learning and estimating the distribution of AdNNs’ computational consumption. We evaluate DeepPerform on three widely used datasets against five popular AdNN models. The results show that DeepPerform generates test samples that cause more severe performance degradation (FLOPs: increase up to 552%). Furthermore, DeepPerform is substantially more efficient than the baseline methods in terms of generating test inputs (runtime overhead: only 6–10 milliseconds). ","tags":null,"title":"DeepPerform: An Efficient Approach for Performance Testing of Resource-Constrained Neural Networks","type":"publication"},{"authors":["Guanqun Yang","Mirazul Haque","Qiaochu Song","Wei Yang","Xueqing Liu"],"categories":null,"content":"","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"7736ca05d2c72a3c40043258bf8ac2a0","permalink":"http://youngwei.com/publication/testaug/","publishdate":"2022-08-28T00:00:00Z","relpermalink":"/publication/testaug/","section":"publication","summary":"The recently proposed capability-based NLP testing allows model developers to test the functional capabilities of NLP models, revealing functional failures that cannot be detected by the traditional heldout mechanism. However, existing work on capability-based testing requires extensive manual efforts and domain expertise in creating the test cases. In this paper, we investigate a low-cost approach for the test case generation by leveraging the GPT-3 engine. We further propose to use a classifier to remove the invalid outputs from GPT-3 and expand the outputs into templates to generate more test cases. Our experiments show that TestAug has three advantages over the existing work on behavioral testing: (1) TestAug can find more bugs than existing work; (2) The test cases in TestAug are more diverse; and (3) TestAug largely saves the manual efforts in creating the test suites. The code and data for TestAug can be found at https://github.com/guanqun-yang/testaug. ","tags":null,"title":"TestAug: A Framework for Augmenting Capability-based NLP Tests","type":"publication"},{"authors":["Simin Chen","Cong Liu","Mirazul Haque","Zihe Song","Wei Yang"],"categories":null,"content":"","date":1655164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655164800,"objectID":"21ea0649b9c43530e2278ca8a05f6486","permalink":"http://youngwei.com/publication/nmtsloth/","publishdate":"2022-06-14T00:00:00Z","relpermalink":"/publication/nmtsloth/","section":"publication","summary":"Neural Machine Translation (NMT) systems have received much recent attention due to their human-level accuracy. While existing works mostly focus on either improving accuracy or testing accuracy robustness, the computation efficiency of NMT systems, which is of paramount importance due to often vast translation demands and real-time requirements, has surprisingly received little attention. In this paper, we make the first attempt in understanding and testing potential computation efficiency robustness in state-of-the-art NMT systems. By analyzing the working mechanism and implementation of 1455 publicly-accessible NMT systems, we observe a fundamental property that could be manipulated in an adversarial manner to significantly reduce computation efficiency. An interesting observation is that the computation efficiency of NMT systems is determined by the output length instead of the input, where the output length depends on two factors: an often sufficiently large yet pessimistic pre-configured threshold controlling the max number of iterations, and a runtime generated end of sentence (EOS) token. Our key motivation is to generate test inputs that could sufficiently delay the generation of EOS such that NMT systems would have to go through enough iterations to satisfy the pre-configured threshold. We present NMTSloth which develops a gradient-guided technique that searches for a minimal and unnoticeable perturbation at character-level, token-level, and structure-level, which sufficiently delay the appearance of EOS and force these inputs to reach the naturally-unreachable threshold. To demonstrate the effectiveness of NMTSloth, we conduct a systematic evaluation on three public-available NMT systems: Google T5, WallenAI WMT14, and Helsinki-NLP translators. Experimental results show that NMTSloth can increase NMT systems' response latency and energy consumption by 85% to 3153% and 86% to 3052%, respectively, by perturbing just one to three tokens in any input sentences. ","tags":null,"title":"NMTSloth: Understanding and Testing Efficiency Degradation of Neural Machine Translation Systems","type":"publication"},{"authors":["Simin Chen","Hamed Khanpour","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1650412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650412800,"objectID":"6620fdad31f0c8cf3babc7cec8da85c2","permalink":"http://youngwei.com/publication/reversednn/","publishdate":"2022-04-20T00:00:00Z","relpermalink":"/publication/reversednn/","section":"publication","summary":"With the privatization deployment of DNNs on edge devices, the security of on-device DNNs has raised great concern. To quantify model leakage risk of on-device DNNs automatically, we propose NNReverse, the first learning-based method which can reverse DNNs from AI programs without domain knowledge. NNReverse trains a representation model to represent the semantic of binary codes for DNN layers. By searching the most similar function in our database, NNReverse infers the layer type of a given functions’ binary codes. To represent assembly instructions semantic precisely, NNReverse propose a more finegrained embedding model to represent the textual and structural semantic of assembly functions. We evaluate NNReverse on ten different DNNs with different layers and parameter numbers, the results show NNReverse reverse the DNNs without accuracy loss.","tags":null,"title":"Learning to Reverse DNNs from AI Programs Automatically","type":"publication"},{"authors":["Simin Chen","Zihe Song","Mirazul Haque","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1646179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646179200,"objectID":"d4a50decfaccc750b969cd85c52b4f6b","permalink":"http://youngwei.com/publication/nicgslowdown/","publishdate":"2022-03-02T00:00:00Z","relpermalink":"/publication/nicgslowdown/","section":"publication","summary":"Neural image caption generation (NICG) models have received massive attention from the research community due to their excellent performance in visual understanding. Existing work focuses on improving NICG model accuracy while efficiency is less explored. However, many real-world applications require real-time feedback, which highly relies on the efficiency of the NICG models. Recent research observed that the efficiency of NICG models can vary for different inputs. This observation brings in a new attack surface of NICG models, i.e., an adversary might be able to slightly change inputs to cause the NICG models to consume more computational resources. To further understand such efficiency-oriented threats, in this paper, we propose a new attack approach NICGSlowDown, to evaluate the efficiency robustness of NICG models. Our experimental results show that NICGSlowDown can generate images with human-unnoticeable perturbations that will increase the NICG model latency up to 483%. We hope this research could raise the community’s concern about the efficiency robustness of NICG models.","tags":null,"title":"NICGSlowDown: Evaluating the Efficiency Robustness of Neural Image Caption Generation Models","type":"publication"},{"authors":["Mirazul Haque","Christof Budnik","Wei Yang"],"categories":null,"content":"","date":1642204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642204800,"objectID":"e30f3f723c3e77e711d33a6b97e7b4ad","permalink":"http://youngwei.com/publication/corrgan/","publishdate":"2022-01-15T00:00:00Z","relpermalink":"/publication/corrgan/","section":"publication","summary":"Because of the increasing accuracy of Deep Neural Networks (DNNs) on different tasks, a lot of real times systems are utilizing DNNs. These DNNs are vulnerable to adversarial perturbations and corruptions. Specifically, natural corruptions like fog, blur, contrast etc can affect the prediction of DNN in an autonomous vehicle. In real time, these corruptions are needed to be detected and also the corrupted inputs are needed to be de-noised to be predicted correctly. In this work, we propose CorrGAN approach, which can generate benign input when a corrupted input is provided. In this framework, we train Generative Adversarial Network (GAN) with novel intermediate output-based loss function. The GAN can denoise the corrupted input and generate benign input. Through experimentation, we show that up to 75.2% of the corrupted misclassified inputs can be classified correctly by DNN using CorrGAN","tags":null,"title":"CorrGAN:Input Transformation Technique Against Natural Corruptions. ","type":"publication"},{"authors":["Mirazul Haque","Yaswanth Yadlapalli","Wei Yang","Cong Liu"],"categories":null,"content":"","date":1641340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641340800,"objectID":"8e67b3b759787d969204e9ca586d066d","permalink":"http://youngwei.com/publication/ereba/","publishdate":"2022-01-05T00:00:00Z","relpermalink":"/publication/ereba/","section":"publication","summary":"Recently, various Deep Neural Network (DNN) models have been proposed for environments like embedded systems with stringent energy constraints. The fundamental problem of determining the robustness of a DNN with respect to its energy consumption (energy robustness) is relatively unexplored compared to accuracy-based robustness. This work investigates the energy robustness of Adaptive Neural Networks (AdNNs), a type of energy-saving DNNs proposed for many energy-sensitive domains and have recently gained traction. We propose EREBA, the first black-box testing method for determining the energy robustness of an AdNN. EREBA explores and infers the relationship between inputs and the energy consumption of AdNNs to generate energy surging samples. Extensive implementation and evaluation using three state-of-the-art AdNNs demonstrate that test inputs generated by EREBA could degrade the performance of the system substantially. The test inputs generated by EREBA can increase the energy consumption of AdNNs by 2,000% compared to the original inputs. Our results also show that test inputs generated via EREBA are valuable in detecting energy surging inputs. ","tags":null,"title":"EREBA: Black-box Energy Testing of Adaptive Neural Networks","type":"publication"},{"authors":["Yueming Wu","Deqing Zou","Shihan Dou","Wei Yang","Duo Xu","Hai Jin"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"8f17958931baa80d7fe89832e96defd5","permalink":"http://youngwei.com/publication/vulcnn/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/vulcnn/","section":"publication","summary":"Since deep learning (DL) can automatically learn features from source code, it has been widely used to detect source code vulnerability. To achieve scalable vulnerability scanning, some prior studies intent to process the source code directly by treating them as text.To achieve accurate vulnerability detection, other approaches consider distilling the program semantics into graph representations and use them to detect vulnerability. In practice, text-based techniques are scalable but not accurate due to the lack of program semantics. Graph-based methods are accurate but not scalable since graph analysis is typically time-consuming. In this paper, we aim to achieve both scalability and accuracy on scanning large-scale source code vulnerabilities. Inspired by existing DL-based image classification which has the ability to analyze millions of images accurately, we prefer to use these techniques to accomplish our purpose. Specifically, we propose a novel idea that can efficiently convert the source code of a function into an image while preserving the program details. We implement VulCNN and evaluate it on a dataset of 13,687 vulnerable functions and 26,970 non-vulnerable functions. Experimental results report that VulCNN performs better than eight state-of-the-art vulnerability detectors (i.e., Checkmarx, FlawFinder, RATS, TokenCNN, VulDeePecker, SySeVR, VulDeeLocator, and Devign). As for scalability, VulCNN is about four times faster than VulDeePecker and SySeVR, about 15 times faster than VulDeeLocator, and about six times faster than Devign. Furthermore, we conduct a case study on more than 25 million lines of code and the result indicates that VulCNN has the ability to detect large-scale vulnerability. Through the scanning reports, we finally discover 73 vulnerabilities that are not reported in NVD. ","tags":null,"title":"VulCNN: An Image-inspired Scalable Vulnerability Detection System","type":"publication"},{"authors":["Wenyu Wang","Wei Yang","Tianyin Xu","Tao Xie"],"categories":null,"content":"","date":1624924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624924800,"objectID":"c4c1faa269f5159ae53be8504a53a710","permalink":"http://youngwei.com/publication/vet/","publishdate":"2021-06-29T00:00:00Z","relpermalink":"/publication/vet/","section":"publication","summary":"Despite over a decade of research, it is still challenging for mobileUI testing tools to achieve satisfactory effectiveness, especially on industrial apps with rich features and large codebases. Our experiences suggest that existing mobile UI testing tools are prone to exploration tarpits, where the tools get stuck with a small fraction of app functionalities for an extensive amount of time. One ex-ample is that a tool logs out an app at early stages without being able to log back in, and since then gets stuck with exploring the app’s pre-login functionalities (i.e., exploration tarpits) instead of its main functionalities. While tool vendors/users can manually hardcode rules for the tools to avoid specific exploration tarpits, these rules can hardly generalize, being fragile in face of diverted testing environments, fast app iterations, and the demand of batch testing product lines. To identify and resolve exploration tarpits, we proposeVet, a general approach and its supporting system for the given specific Android UI testing tool on the given specific app under test (AUT). Vet runs the tool on the AUT for some time and records UI traces, based on which Vet identifies exploration tarpits by recognizing their patterns in the UI traces. Vet then pinpoints the actions (e.g., clicking logout) or the screens that lead to exploration tarpits. In subsequent test runs, Vet guides the testing tool to prevent or recover from exploration tarpits. From our evaluation with state-of-the-art Android UI testing tools on popular industrial apps, Vet identifies exploration tarpits that cost up to 98.6% testing time budget. These exploration tarpits reveal not only limitations inUI exploration strategies but also defects in tool implementations. Vet automatically addresses the identified exploration tarpits, enabling each evaluated tool to achieve higher code coverage and improved crash-triggering capabilities. **ACM SIGSOFT Distinguished Paper Award.**","tags":null,"title":"Vet: Identifying and Avoiding UI Exploration Tarpits","type":"publication"},{"authors":["Ke Chen\\*","Yufei Li\\*","Yingfeng Chen","Changjie Fan","Zhipeng Hu","Wei Yang"],"categories":null,"content":"","date":1621382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621382400,"objectID":"4a14ffe0de68809c9fa3ad5ba9082260","permalink":"http://youngwei.com/publication/glib/","publishdate":"2021-05-19T00:00:00Z","relpermalink":"/publication/glib/","section":"publication","summary":"Mobile games are ubiquitous with attractive visual effects of Graphical User Interface (GUI) that offers a bridge between software applications and end users. However, various types of graphical glitches may arise from such GUI complexity and have become the main composition of game compatibility issues. Our study of abundant of real-world bug reports indicates that graphical glitches frequently occur during the game GUI rendering on different devices and severely degrade the game app usability, leading to poor user experience. Different from other common GUI glitches that most existing GUI testing work has focused on, game GUIs composed of 3D models typically have different manifestation of glitch issues. To solve this gap in existing techniques, we propose GLIB, a novel deep learning (DL) approach for detecting game GUI glitches and develop a code-based data augmentation technique via bug understanding for enhancing the modeling ability of our GLIB. The evaluation on 201 real-world game test cases shows that GLIB can achieve 100% precision and 99.5% recall in detecting game GUI glitches and that our code-based augmentation approach can generate more real-like GUI glitches than the existing heuristic-based approach. Our case study on 14 real-world games further demonstrates that GLIB can effectively uncover GUI glitches with most of them having been confirmed and fixed by the app developers. \\* The first two authors contributed equally.","tags":null,"title":"GLIB: Towards Automated Test Oracle for Graphically-Rich Applications","type":"publication"},{"authors":["Yueming Wu","Deqing Zou","Wei Yang","Xiang Li","Hai Jin"],"categories":null,"content":"","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"c28ca6c926981cc5d9a17cf83a1d2dea","permalink":"http://youngwei.com/publication/homdroid/","publishdate":"2021-05-16T00:00:00Z","relpermalink":"/publication/homdroid/","section":"publication","summary":"Android has become the most popular mobile operating system. Correspondingly, an increasing number of Android malware has been developed and spread to steal users’ private information. There exists one type of malware whose benign behaviors are developed to camouflage malicious behaviors. The malicious component occupies a small part of the entire code of the application (app for short), and the malicious part is strongly coupled with the benign part. In this case, the malware may cause false negatives when malware detectors extract features from the entire apps to conduct classification because the malicious features of these apps may be hidden among benign features. Moreover, some previous work aims to divide the entire app into several parts to discover the malicious part. However, the premise of these methods to commence app partition is that the connections between the normal part and the malicious part are weak (e.g., repackaged apps). In this paper, we call this type of malware as Android covert malware and generate the first dataset of covert malware. To detect these malware samples,we first conduct static analysis to extract the function call graphs. Through the deep analysis from these graphs, we observe that although the correlations between the normal part and the malicious part in these graphs are high, the degree of these correlations has a unique range of distribution. By this, we design a novel system (i.e., HomDroid) to detect covert malware by analyzing the homophily of call graphs. Our evaluation results on a dataset of 4,840 benign apps and 3,385 covert malicious apps show that the ideal threshold of correlation to distinguish the normal part and the malicious part is 3. In this case, HomDroid is capable of detecting 96.8% of covert malware while the False Negative Rates of another three state-of-the-art systems (i.e., PerDroid, Drebin, and MaMaDroid) are 30.7%, 16.3%, and 15.2%, respectively.","tags":null,"title":"HomDroid: Detecting Android Covert Malware by Social-Network Homophily Analysis","type":"publication"},{"authors":["Fei Shao","Rui Xu","Wasif Haque","Jingwei Xu","Ying Zhang","Wei Yang","Yanfang Ye","Xusheng Xiao"],"categories":null,"content":"","date":1618704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618704000,"objectID":"755ad15748cd8bf549510d8e2207d547","permalink":"http://youngwei.com/publication/webevo/","publishdate":"2021-04-18T00:00:00Z","relpermalink":"/publication/webevo/","section":"publication","summary":"In order to prevent information retrieval (IR) and robotic process automation (RPA) tools from functioning improperly due to web- site evolution, it is important to develop web monitoring tools to monitor changes in a website and report them to the developers and testers. Existing monitoring tools commonly make use of DOM-tree based similarity and visual analysis between different versions of web pages. However, DOM-tree based similarity suffers are prone to false positives, since they cannot identify content-based changes (i.e., contents refreshed every time a web page is retrieved) and GUI widget evolution (e.g., moving a button). Such imprecision adversely affect IR tools or test scripts. To address this problem, we propose approach, WebEvo, that first performs DOM-based change detection, and then leverages historic pages to identify the regions that represent content-based changes, which can be safely ignored. Further, to identify refactoring changes that preserve semantics and appearances of GUI widgets, WebEvo adapts computer vision (CV) techniques to identify the mappings of the GUI widgets from the old web page to the new web page on an element-by-element basis. Empirical evaluations on 13 real-world websites from 9 popular cat- egories demonstrate the superiority of WebEvo over the existing work that relies on DOM-tree based detection or whole-page visual comparison, while also being faster in visual analysis.","tags":null,"title":"WebEvo: Taming Web Application Evolution via Detecting Semantic Structure Change","type":"publication"},{"authors":["Alan Romano","Zihe Song","Sampath Grandhi","Wei Yang","Weihang Wang"],"categories":null,"content":"","date":1609891200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609891200,"objectID":"fed1e61783c6b11f6087878bf33a1496","permalink":"http://youngwei.com/publication/uiflakystudy/","publishdate":"2021-01-06T00:00:00Z","relpermalink":"/publication/uiflakystudy/","section":"publication","summary":"Flaky tests have gained attention from the research community in recent years and with good reason. These tests lead to wasted time and resources and reduce the reliability of the test suites and build systems they affect. However, most of the existing works on flaky tests focus exclusively on traditional unit tests. This ignores UI tests that have larger input spaces and more diverse running conditions than traditional unit tests. In addition, UI tests tend to be more complex and resource-heavy, making them unsuited for detection techniques involving rerunning test suites multiple times.  \n\n In this paper, we perform a study on UI flaky tests. We analyze 235 flaky UI test samples found in 62 projects from both web and Android environments. We identify the common underlying root causes of flakiness in the UI tests, the strategies used to manifest the flaky behavior, and the fixing strategies used to remedy flaky UI tests. The findings made in this work can provide a foundation for the development of detection and prevention techniques for flakiness arising in UI tests.","tags":null,"title":" An Empirical Analysis of UI-based Flaky Tests","type":"publication"},{"authors":["Deqing Zou","Yueming Wu","Siru Yang","Anki Chauhan","Wei Yang","Jiangying Zhong","Shihan Dou","Hai Jin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4de9bb8970d8f1aed88b442176d18e83","permalink":"http://youngwei.com/publication/intdroid/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/intdroid/","section":"publication","summary":"Android, the most popular mobile operating system, has attracted millions of users around the world. Meanwhile, the number of new Android malware instances has grown exponentially in recent years. On the one hand, existing Android malware detection systems have shown that distilling the program semantics into a graph representation and detecting malicious programs by conducting graph matching are able to achieve high accuracy on detecting Android malware. However, these traditional graph-based approaches always perform expensive program analysis and suffer from low scalability on malware detection. On the other hand, because of the high scalability of social network analysis, it has been applied to complete large-scale malware detection. However, the socialnetwork-analysis-based method only considers simple semantic information (*i.e.,* centrality) for achieving market-wide mobile malware scanning, which may limit the detection effectiveness when benign apps show some similar behaviors as malware. \n\n   In this paper, we aim to combine the high accuracy of traditional graph-based method with the high scalability of social-networkanalysis-based method for Android malware detection. Instead of using traditional heavyweight static analysis, we treat function call graphs of apps as complex social networks and apply social-network-based centrality analysis to unearth the central nodes within call graphs. After obtaining the central nodes, the average intimacies between sensitive API calls and central nodes are computed to represent the semantic features of the graphs. We implement our approach in a tool called IntDroid and evaluate it on a dataset of 3,988 benign samples and 4,265 malicious samples. Experimental results show that IntDroid is capable of detecting Android malware with an F-measure of 97.1% while maintaining a True Positive Rate of 99.1%. Although the scalability is not as fast as social-network-analysis-based method (i.e., MalScan), however, compared to a traditional graph-based method, IntDroid is more than six times faster than MaMaDroid. Moreover, in a corpus of apps collected from GooglePlay market, IntDroid is able to identify 28 zero-day malware that can evade detection of existing tools, one of which has been downloaded and installed by more than ten million users. This app has also been flagged as malware by six anti-virus scanners in VirusTotal, one of which is Symantec Mobile Insight.","tags":null,"title":"IntDroid: Android Malware Detection Based on API Intimacy Analysis","type":"publication"},{"authors":["Shudi Shao","Zhengyi Qiu","Xiao Yu","Wei Yang","Guoliang Jin","Tao Xie","Xintao Wu"],"categories":null,"content":"","date":1596412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596412800,"objectID":"8a1801c33683eb022e41c18fd94e950c","permalink":"http://youngwei.com/publication/dbantipattern/","publishdate":"2020-08-03T00:00:00Z","relpermalink":"/publication/dbantipattern/","section":"publication","summary":"Database-backed web applications are prone to performance bugs related to database accesses. While much work has been conducted on database-access antipatterns with some recent work focusing on performance impact, there still lacks a comprehensive view of database-access performance antipatterns in database-backed web applications. To address this issue, we first summarize and report all known database-access performance antipatterns found through our literature survey. We further look at web applications that access databases through language-provided SQL interfaces, which have been largely ignored by recent work, to extract new antipatterns based on real-world performance bugs from such web applications. We also evaluate the effectiveness of rule-based antipattern detection on such web applications. Our study in total reports 24 known and 10 new database-access performance antipatterns. Our results can guide future work to develop effective tool support for different types of web applications.","tags":null,"title":"Database-Access Performance Antipatterns in Database-Backed Web Applications","type":"publication"},{"authors":["Yueming Wu","Deqing Zou","Shihan Dou","Siru Yang","Wei Yang","Feng Cheng","Hong Liang","Hai Jin"],"categories":null,"content":"","date":1595980800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595980800,"objectID":"18dc4fc694b821f641b13de145679d5c","permalink":"http://youngwei.com/publication/scdetector/","publishdate":"2020-07-29T00:00:00Z","relpermalink":"/publication/scdetector/","section":"publication","summary":"Code clone detection is to excavate code fragments with similar functionalities, which has been more and more important in software engineering. Many approaches have been proposed for detecting code clones, in which token-based methods are the most scalable but cannot handle semantic clones because of the lack of consideration of program semantics. To address the issue, researchers conduct program analysis to distill the program semantics into a graph representation and detect clones by matching the graphs. However, such approaches suffer from low scalability since graph matching is typically time-consuming. In this paper, we propose SCDetector to combine the scalability of token-based methods with the accuracy of graph-based methods for software functional clone detection. Given a function source code, we first extract the control flow graph by static analysis. Instead of traditional heavyweight graph matching, we treat the graph as a social network and apply social-network-centrality analysis to dig out the centrality of each basic block. Then we assign the centrality to each token in a basic block and sum the centrality of the same token in different basic blocks. By this a graph is turned into certain tokens with graph details (i.e., centrality), called semantic tokens. In final, these semantic tokens are fed into a Siamese architecture neural network to train a model, and use it to detect code clones. We evaluate SCDetector on two large datasets of functionally similar code. Experimental results indicate that our system is superior to state-of-the-art methods and the time cost of SCDetector is more than 14 times less than the state-of-the-art approach in detecting semantic clones","tags":null,"title":"SCDetector: Software Functional Clone Detection Based on Semantic Tokens Analysis","type":"publication"},{"authors":["Simin Chen","Soroush Bateni","Sampath Grandhi","Xiaodi Li","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1589846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589846400,"objectID":"56d0a63bbaf6ad517af7481f0a5e4524","permalink":"http://youngwei.com/publication/denas/","publishdate":"2020-05-19T00:00:00Z","relpermalink":"/publication/denas/","section":"publication","summary":"Deep neural networks (DNNs) have been widely applied in the software development process to automatically learn patterns and rules from massive data. However, many applications still make decisions based on rules that are manually crafted and verified by domain experts due to safety or security concerns. In this paper, we aim to close the gap between DNNs and rule-based systems by automating the rule generation process via extracting knowledge from well-trained DNNs. Existing techniques with similar purpose either rely on specific DNN input instances, or use inherently unstable random sampling of the input space. Therefore, these approaches either limit the exploration area to a local decision-space of the DNN or fail to converge to a consistent set of rules. The resulting rules thus lack representitiveness and stability.  \n \u0026nbsp;\u0026nbsp; In this paper, we address the two aforementioned shortcomings by discovering a global property of the DNN and use it to remodel the DNN decision-boundary. We name this property as the activation probability, and show that this property is stable. With this insight, we propose an approach named DENAS including a novel rule generation algorithm. Our proposed algorithm approximates the non-linear decision boundary of DNNs by iteratively superimposing a linearized optimization function.  \n \u0026nbsp;\u0026nbsp; We evaluate the representitiveness, stability and accuracy of DENASagainst five state-of-the-art techniques (LEMNA, Gradient, IG, DeepTaylor, and DTExtract) on three software engineering and security applications: Binary analysis, PDF malware detection, and Android malware detection. Our results show that DENAS can generate more representative rules consistently in a more stable manner over other approaches. We further offer case studies that demonstrate the applications of DENAS such as debugging faults in the DNN and generating zero-day malware signatures.","tags":null,"title":"DENAS: Automated Rule Generation by Knowledge Extraction from Neural Networks","type":"publication"},{"authors":["Mirazul Haque","Anki Chauhan","Cong Liu","Wei Yang"],"categories":null,"content":"","date":1582502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582502400,"objectID":"a1e70172d28fde2a587ca1355168f91c","permalink":"http://youngwei.com/publication/ilfo/","publishdate":"2020-02-24T00:00:00Z","relpermalink":"/publication/ilfo/","section":"publication","summary":"With the increase in the number of layers and parameters in neural networks, the energy consumption of neural networks has become a great concern to society, especially to users of handheld or embedded devices. In this paper, we investigate the robustness of neural networks against energy-oriented attacks. Specifically, we propose ILFO (Intermediate Output Based Loss Function Optimization) at-tack against a type of energy-saving neural networks, Adaptive Neural Networks (AdNN). An AdNN can dynamically deactivate part of its model based on the need of the inputs to decrease energy consumption. ILFO leverage intermediate output as a proxy to infer the relation between input and its corresponding energy consumption. ILFO has shown an increase upto 100 % of the remaining FLOPs (floating-point operations per second) count of AdNNs with minimum noise added to input images. To our knowledge, this is the first attempt to attack the energy consumption of a DNN.","tags":null,"title":"ILFO: Adversarial Attack on Adaptive Neural Networks","type":"publication"},{"authors":["Yuyu He","Lei Zhang","Zhemin Yang","Yinzhi Cao","Keke Lian","Shuai Li","Wei Yang","Zhibo Zhang","Min Yang","Yuan Zhang","Haixin Duan"],"categories":null,"content":"","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578960000,"objectID":"8035a6e79bd1eecea26ab70d7c28ca07","permalink":"http://youngwei.com/publication/textexerciser/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/publication/textexerciser/","section":"publication","summary":"Dynamic analysis of Android apps is often used together with an exerciser to increase its code coverage. One big obstacle in designing such Android app exercisers comes from the existence of text-based inputs, which are often constrained by the nature of the input field, such as the length and character restrictions. \n In this paper, we propose TextExerciser, an iterative, feedback-driven text input exerciser, which generates text inputs for Android apps. Our key insight is that Android apps often provide feedback, called hints, for malformed inputs so that our system can utilize such hints to improve the input generation. \n We implemented a prototype of TextExerciser and evaluated it by comparing TextExerciser with state-of-the-art exercisers, such as The Monkey and DroidBot. Our evaluation shows that TextExerciser can achieve significantly higher code coverage and trigger more sensitive behaviors than these tools. We also combine TextExerciser with dynamic analysis tools and show they are able to detect more privacy leaks and vulnerabilities with TextExerciser than with existing exercisers. Particularly, existing tools, under the help of TextExerciser, find several new vulnerabilities, such as one user credential leak in a popular social app with more than 10,000,000 downloads.","tags":null,"title":"TextExerciser: Feedback-driven Text Input Exercising for Android Applications","type":"publication"},{"authors":["Yueming Wu","Xiaodi Li","Deqing Zou","Wei Yang","Xin Zhang","Hai Jin"],"categories":null,"content":"","date":1564963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564963200,"objectID":"a9577c2e67e0da90dfcda8eb92982491","permalink":"http://youngwei.com/publication/malscan/","publishdate":"2019-08-05T00:00:00Z","relpermalink":"/publication/malscan/","section":"publication","summary":"Malware scanning of an app market is expected to be scalable and effective. However, existing approaches use either syntax-based features which can be evaded by transformation attacks or semantic-based features which are usually extracted by performing expensive program analysis. Therefore, in this paper, we propose a lightweight graph-based approach to perform Android malware detection. Instead of traditional heavyweight static analysis, we treat function call graphs of apps as social networks and perform social-network-based centrality analysis to represent the semantic features of the graphs. Our key insight is that centrality provides a succinct and faulttolerant representation of graph semantics, especially for graphs with certain amount of inaccurate information (e.g., inaccurate call graphs). We implement a prototype system, MalScan, and evaluate it on datasets of 15285 benign samples and 15430 malware samples. Experimental results show that MalScan is capable of detecting Android malware with up to 98% accuracy under one second which is more than 100 times faster than two state-of-the-art approaches, namely MaMaDroid and Drebin. We also demonstrate the feasibility of MalScan on market-wide malware scanning by performing a statistical study on over 3 million apps. Finally, in a corpus of dataset collected from GooglePlay app market, MalScan is able to identify 18 zero-day malware including malware samples that can evade detection of existing tools.","tags":null,"title":"MalScan: Fast Market-Wide Mobile Malware Scanning by Social-Network Centrality Analysis","type":"publication"},{"authors":["Qi Wang","Pubali Datta","Wei Yang","Si Liu","Carl A. Gunter","Adam Bates"],"categories":null,"content":"","date":1563580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563580800,"objectID":"0f36eaf224e30bd9578e465e6ae989fe","permalink":"http://youngwei.com/publication/iruler/","publishdate":"2019-07-20T00:00:00Z","relpermalink":"/publication/iruler/","section":"publication","summary":"Internet of Things (IoT) deployments are becoming increasingly automated and vastly more complex. Facilitated by programming abstractions such as trigger-action rules, end-users can now easily create new functionalities by interconnecting their devices and other online services. However, when multiple rules are simultaneously enabled, complex system behaviors arise that are difficult to understand or diagnose. While history tells us that such conditions are ripe for exploitation, at present the security states of trigger-action IoT deployments are largely unknown. In this work, we conduct a comprehensive analysis of the interactions between trigger-action rules in order to identify their security risks. Using IFTTT as an exemplar platform, we first enumerate the space of inter-rule vulnerabilities that exist within trigger-action platforms. To aid users in the identification of these dangers, we go on to present iRuler, a system that performs Satisfiability Modulo Theories (SMT) solving and model checking to discover inter-rule vulnerabilities within IoT deployments. iRuler operates over an abstracted information flow model that represents the attack surface of an IoT deployment, but we discover in practice that such models are difficult to obtain given the closed nature of IoT platforms. To address this, we develop methods that assist in inferring triggeraction information flows based on Natural Language Processing. We develop a novel evaluative methodology for approximating plausible real-world IoT deployments based on the installation counts of 315,393 IFTTT applets, determining that 66% of the synthetic deployments in the IFTTT ecosystem exhibit the potential for interrule vulnerabilities. Combined, these efforts provide the insight into the real-world dangers of IoT deployment misconfigurations.","tags":null,"title":"Charting the Attack Surface of Trigger-Action IoT Platforms","type":"publication"},{"authors":["Zhengkai Wu","Evan N. Johnson","Wei Yang","Osbert Bastani","Dawn Song","Jian Peng","Tao Xie"],"categories":null,"content":"","date":1558742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558742400,"objectID":"136fd391cc4c5b8d2c4e48ecc8a48a36","permalink":"http://youngwei.com/publication/reinam/","publishdate":"2019-05-25T00:00:00Z","relpermalink":"/publication/reinam/","section":"publication","summary":"Program-input grammars (i.e., grammars encoding the language of valid program inputs) facilitate a wide range of applications in software engineering such as symbolic execution and delta debugging. Grammars synthesized by existing approaches can cover only a small part of the valid input space mainly due to unanalyzable code (e.g., native code) in programs and lacking high-quality, high-variety, and high-quantity seed inputs. To address these challenges, we present REINAM, a reinforcement-learning approach for synthesizing a probabilistic context-free program-input grammars without any seed input. REINAM includes an industrial symbolic execution engine to generate an initial set of inputs for the given target program, and includes an iterative process of grammar generalization to proactively generate additional inputs in order to infer grammars generalized from the initial seed inputs. To efficiently search for target generalizations in a huge search space of candidate generalization operators, REINAM includes a novel formulation of the search problem as the problem of reinforcement learning. Our evaluation results on five real-world subjects show that REINAM outperforms an existing state-of-the-art approach on precision and recall of synthesized grammars, and fuzz testing based on REINAM substantially increases the coverage of the valid input space. REINAM is able to synthesize a grammar covering the whole valid input space for some subjects without decreasing accuracy of the grammar.","tags":null,"title":"REINAM: Reinforcement Learning for Input-Grammar Inference","type":"publication"},{"authors":["Wenyu Wang","Wujie Zheng","Dian Liu","Changrong Zhang","Qinsong Zeng","Yuetang Deng","Wei Yang","Pinjia He","Tao Xie"],"categories":null,"content":"","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551744000,"objectID":"b642b632a7fa8f3484e7046a46d819a4","permalink":"http://youngwei.com/publication/dsn19_industry/","publishdate":"2019-03-05T00:00:00Z","relpermalink":"/publication/dsn19_industry/","section":"publication","summary":"Despite getting widely adopted recently, a Neural Machine Translation (NMT) system is often found to produce translation failures in the outputs. Developers have been relying on in-house system testing for quality assurance of NMT. This testing methodology requires human-constructed reference translations as the ground truth (test oracle) for example natural language inputs. The testing methodology has shown benefits of quickly enhancing an NMT system in early development stages. However, in industrial settings, it is desirable to detect translation failures without reliance on reference translations for enabling further improvements on translation quality in both industrial development and production environments. Aiming for a practical and scalable solution to such demand in the industrial settings, in this paper, we propose a new approach for automatically identifying translation failures without requiring reference translations for a translation task. Our approach focuses on a property of natural language translation that can be checked systematically by using information from both the test inputs (i.e., the texts to be translated) and the test outputs (i.e., the translations under inspection) of the NMT system. Our evaluation conducted on real-world datasets shows that our approach can effectively detect property violations as translation failures. By deploying our approach in the translation service of WeChat (a messenger app with more than one billion monthly active users), we show that our approach is both practical and scalable in the industrial settings.","tags":null,"title":"Detecting Failures of Neural Machine Translation in the Absence of Reference Translations","type":"publication"},{"authors":["Wujie Zheng","Wenyu Wang","Dian Liu","Changrong Zhang","Qinsong Zeng","Yuetang Deng","Wei Yang","Pinjia He","Tao Xie"],"categories":null,"content":"","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551744000,"objectID":"b29600850a3220dccd90b299a2abba86","permalink":"http://youngwei.com/publication/icse19_poster/","publishdate":"2019-03-05T00:00:00Z","relpermalink":"/publication/icse19_poster/","section":"publication","summary":"Neural Machine Translation (NMT) has shown great advantages and is becoming increasingly popular. However, in practice, NMT often produces unexpected translation failures in its translations. While reference-based black-box system testing has been a common practice for NMT quality assurance during development, an increasingly critical industrial practice, named in-vivo testing, exposes unseen types or instances of translation failures when real users are using a deployed industrial NMT system. To fill the gap of lacking test oracles for in-vivo testing of NMT systems, we propose a new methodology for automatically identifying translation failures without reference translations. Our evaluation conducted on real-world datasets shows that our methodology effectively detects several targeted types of translation failures. Our experiences on deploying our methodology in both production and development environments of WeChat (a messenger app with over one billion monthly active users) demonstrate high effectiveness of our methodology along with high industry impact.","tags":null,"title":"Testing Untestable Neural Machine Translation: An Industrial Case","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1545264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545264000,"objectID":"2387cefccfe6937de11eb6dfb2bcd639","permalink":"http://youngwei.com/talk/pku2018/","publishdate":"2018-12-20T00:00:00Z","relpermalink":"/talk/pku2018/","section":"talk","summary":"For too long, researchers have often tackled security in an attack-driven, ad hoc, and reactionary manner with large manual efforts devoted by security analysts. In order to make substantial progress in security, I advocate to shift such manner to be systematic, intelligent, and adversarial resilient. I have developed software engineering techniques to automate decision makings in security systems, and built defenses and testing methodologies to guard against emerging attacks specifically adversarial to these newly-proposed techniques. In this talk, I will first highlight one of these systems for mobile security: AppContext, a malware detection system extracting execution contexts of an app’s security-sensitive behaviors through program analysis. Then I will show how an adaptive adversary can attack these systems and how we can generate adversarial inputs ahead of time for testing and further strengthening these systems. I will conclude by discussing how future research efforts can leverage the interplay among software engineering, security, and AI techniques toward a defense-driven security ecosystem.","tags":null,"title":"Adversarial-Resilience Assurance for Mobile Security Systems.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1545004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545004800,"objectID":"c4fdbe13c4f766f21ed1d77ecb06f6c0","permalink":"http://youngwei.com/talk/fudan2018/","publishdate":"2018-12-17T00:00:00Z","relpermalink":"/talk/fudan2018/","section":"talk","summary":"For too long, researchers have often tackled security in an attack-driven, ad hoc, and reactionary manner with large manual efforts devoted by security analysts. In order to make substantial progress in security, I advocate to shift such manner to be systematic, intelligent, and adversarial resilient. I have developed software engineering techniques to automate decision makings in security systems, and built defenses and testing methodologies to guard against emerging attacks specifically adversarial to these newly-proposed techniques. In this talk, I will first highlight one of these systems for mobile security: AppContext, a malware detection system extracting execution contexts of an app’s security-sensitive behaviors through program analysis. Then I will show how an adaptive adversary can attack these systems and how we can generate adversarial inputs ahead of time for testing and further strengthening these systems. I will conclude by discussing how future research efforts can leverage the interplay among software engineering, security, and AI techniques toward a defense-driven security ecosystem.","tags":null,"title":"Adversarial Learning and Mobile Security System.","type":"talk"},{"authors":["Zexuan Zhong","Jiaqi Guo","Wei Yang","Jian Peng","Tao Xie","Jian-Guang Lou","Ting Liu","Dongmei Zhang"],"categories":null,"content":"","date":1532908800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532908800,"objectID":"f0db75ada8eb2e39c0e74197984bd4e7","permalink":"http://youngwei.com/publication/semregex/","publishdate":"2018-07-30T00:00:00Z","relpermalink":"/publication/semregex/","section":"publication","summary":"Recent research proposes syntax-based approaches to address the problem of generating programs from natural language specifications. These approaches typically train a sequence-to-sequence learning model using a syntax-based objective: maximum likelihood estimation (MLE). Such syntax-based approaches do not effectively address the goal of generating semantically correct programs, because these approaches fail to handle Program Aliasing, i.e., semantically equivalent programs may have many syntactically different forms. To address this issue, in this paper, we propose a semantics-based approach named SemRegex. SemRegex provides solutions for a subtask of the program-synthesis problem: generating regular expressions from natural language. Different from the existing syntax-based approaches, SemRegex trains the model by maximizing the expected semantic correctness of the generated regular expressions. The semantic correctness is measured using the DFA-equivalence oracle, random test cases, and distinguishing test cases. The experiments on three public datasets demonstrate the superiority of SemRegex over the existing state-of-the-art approaches.","tags":null,"title":"SemRegex: A Semantics-Based Approach for Generating Regular Expressions from Natural Language Specifications","type":"publication"},{"authors":["Karan Ganju","Qi Wang","Wei Yang","Carl A. Gunter","Nikita Borisov"],"categories":null,"content":"","date":1531612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531612800,"objectID":"252dac2a87782dad45b98f7856b34e53","permalink":"http://youngwei.com/publication/permuteinvariance/","publishdate":"2018-07-15T00:00:00Z","relpermalink":"/publication/permuteinvariance/","section":"publication","summary":"With the growing adoption of machine learning, sharing of learned models is becoming popular. However, in addition to the prediction properties the model producer aims to share, there is also a risk that the model consumer can infer other properties of the training data the model producer did not intend to share. In this paper, we focus on the inference of global properties of the training data, such as the environment in which the data was produced, or the fraction of the data that comes from a certain class, as applied to white-box Fully Connected Neural Networks (FCNNs).  Because of their complexity and inscrutability, FCNNs have a particularly high risk of leaking unexpected information about their training sets; at the same time, this complexity makes extracting this information challenging. We develop techniques that reduce this complexity by noting that FCNNs are invariant under permutation of nodes in each layer. We develop our techniques using representations that capture this invariance and simplify the information extraction task. We evaluate our techniques on several synthetic and standard benchmark datasets and show that they are very effective at inferring various data properties.  We also perform two case studies to demonstrate the impact of our attack. In the first case study we show that a classifier that recognizes smiling faces also leaks information about the relative attractiveness of the individuals in its training set. In the second case study we show that a classifier that recognizes Bitcoin mining from performance counters also leaks information about whether the classifier was trained on logs from machines that were patched for the Meltdown and Spectre attacks.","tags":null,"title":"Property Inference Attacks on Deep Neural Networks using Permutation Invariant Representations","type":"publication"},{"authors":["Xueqing Liu","Yue Leng","Wei Yang","Wenyu Wang","Chengxiang Zhai","Tao Xie"],"categories":null,"content":"","date":1529020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529020800,"objectID":"0e9de60cd8cb5d6e15445752320d0e9f","permalink":"http://youngwei.com/publication/clap_vlhcc/","publishdate":"2018-06-15T00:00:00Z","relpermalink":"/publication/clap_vlhcc/","section":"publication","summary":"After Android 6.0 introduces the runtimepermission system, many apps provide runtime-permissiongroup rationales for the users to better understand the permissions requested by the apps. To understand the patterns of rationales and to what extent the rationales can improve the users’ understanding of the purposes of requesting permission groups, we conduct a large-scale measurement study on five aspects of runtime rationales. We have five main findings: (1) less than 25% apps under study provide rationales; (2) for permission-group purposes that are difficult to understand, the proportions of apps that provide rationales are even lower; (3) the purposes stated in a significant proportion of rationales are incorrect; (4) a large proportion of customized rationales do not provide more information than the default permission-requesting message of Android; (5) apps that provide rationales are more likely to explain the same permission group’s purposes in their descriptions than apps that do not provide rationales. We further discuss important implications from these findings.","tags":null,"title":"A Large-Scale Empirical Study on Android Runtime Permission Rationale Messages","type":"publication"},{"authors":["Wenyu Wang","Dengfeng Li","Wei Yang","Yurui Cao","Zhenwen Zhang","Yuetang Deng","Tao Xie"],"categories":null,"content":"","date":1529020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529020800,"objectID":"0e51e5cffc7ed195e7fe0f2fe026fdab","permalink":"http://youngwei.com/publication/wctester/","publishdate":"2018-06-15T00:00:00Z","relpermalink":"/publication/wctester/","section":"publication","summary":"User Interface (UI) testing is a popular approach to ensure the quality of mobile apps. Numerous test generation tools have been developed to support UI testing on mobile apps, especially for Android apps. Previous work evaluates and compares different test generation tools using only relatively simple open-source apps, while real-world industrial apps tend to have more complex functionalities and implementations. There is no direct comparison among test generation tools with regard to effectiveness and easeof-use on these industrial apps. To address such limitation, we study existing state-of-the-art or state-of-the-practice test generation tools on 68 widely-used industrial apps. We directly compare the tools with regard to code coverage and fault-detection ability. According to our results, Monkey, a state-of-the-practice tool from Google, achieves the highest method coverage on 22 of 41 apps whose method coverage data can be obtained. Of all 68 apps under study, Monkey also achieves the highest activity coverage on 35 apps, while Stoat, a state-of-the-art tool, is able to trigger the highest number of unique crashes on 23 apps. By analyzing the experimental results, we provide suggestions for combining different test generation tools to achieve better performance. We also report our experience in applying these tools to industrial apps under study. Our study results give insights on how Android UI test generation tools could be improved to better handle complex industrial apps.","tags":null,"title":"An Empirical Study of Android Test Generation Tools in Industrial Cases","type":"publication"},{"authors":["Xueqing Liu","Yue Leng","Wei Yang","Chengxiang Zhai","Tao Xie"],"categories":null,"content":"","date":1527638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527638400,"objectID":"a6d3330a768a2044a7dfb70d6aa2c2b6","permalink":"http://youngwei.com/publication/clap_re/","publishdate":"2018-05-30T00:00:00Z","relpermalink":"/publication/clap_re/","section":"publication","summary":"During the development or maintenance of an Android app, the app developer needs to determine the app’s security and privacy requirements such as permission requirements. Permission requirements include two folds: (1) what permissions (i.e., access to sensitive resources, e.g., location or contact list) the app needs to request, and (2) how to explain the reason of permission usages to users. In this paper, we focus on the multiple challenges that developers face when creating the explanations for permission usages. We propose a novel framework, CLAP, that mines potential explanations from the descriptions of similar apps. CLAP leverages information retrieval and text summarization techniques to find frequent permission usages. We evaluate CLAP on a large dataset containing 1.4 million Android apps. The evaluation results show that CLAP outperforms existing stateof-the-art approaches, and has great promise to assist developers for permission requirements discovery.","tags":null,"title":"Mining Android App Description for Permission Requirements Recommendation","type":"publication"},{"authors":["Wei Yang","Mukul Prasad","Tao Xie"],"categories":null,"content":"","date":1526342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526342400,"objectID":"965a04034cf5b8ce30559ecc07b9a531","permalink":"http://youngwei.com/publication/enmobile/","publishdate":"2018-05-15T00:00:00Z","relpermalink":"/publication/enmobile/","section":"publication","summary":"Modern mobile malware tend to conduct their malicious exploits through sophisticated patterns of interactions that involve multiple entities, e.g., the mobile platform, human users, and network locations. Such malware often evade the detection by existing approaches due to their limited expressiveness and accuracy in characterizing and detecting these malware. To address these issues, in this paper, we recognize entities in the environment of an app, the app’s interactions with such entities, and the provenance of these interactions, i.e., the intent and ownership of each interaction, as the key to comprehensively characterizing modern mobile apps, and mobile malware in particular. With this insight, we propose a novel approach named EnMobile including a new entity-based characterization of mobile-app behaviors, and corresponding static analyses, to accurately characterize an app’s interactions with entities. We implement EnMobile and provide a practical application of EnMobile in a signature-based scheme for detecting mobile malware. We evaluate EnMobile on a set of 6614 apps consisting of malware from Genome and Drebin along with benign apps from Google Play. Our results show that EnMobile detects malware with substantially higher precision and recall than four state-of-the-art approaches, namely Apposcopy, Drebin, MUDFLOW, and AppContext.","tags":null,"title":"EnMobile: Entity-based Characterization and Analysis of Mobile Malware","type":"publication"},{"authors":["Zexuan Zhong","Jiaqi Guo","Wei Yang","Tao Xie","Jian-Guang Lou","Ting Liu","Dongmei Zhang"],"categories":null,"content":"","date":1517270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517270400,"objectID":"690ede48a5a96ba31024068dcf5d4f74","permalink":"http://youngwei.com/publication/semregex-aaai/","publishdate":"2018-01-30T00:00:00Z","relpermalink":"/publication/semregex-aaai/","section":"publication","summary":"Recent state-of-the-art approaches automatically generate regular expressions from natural language specifications. Given that these approaches use only synthetic data in both training datasets and validation/test datasets, a natural question arises: are these approaches effective to address various real-world situations? To explore this question, in this paper, we conduct a characteristic study on comparing two synthetic datasets used by the recent research and a real-world dataset collected from the Internet, and conduct an experimental study on applying a state-of-the-art approach on the real-world dataset. Our study results suggest the existence of distinct characteristics between the synthetic datasets and the real-world dataset, and the state-of-the-art approach (based on a model trained from a synthetic dataset) achieves extremely low effectiveness when evaluated on real-world data, much lower than the effectiveness when evaluated on the synthetic dataset. We also provide initial analysis on some of those challenging cases and discuss future directions.","tags":null,"title":"Generating Regular Expressions from Natural Language Specifications: Are We There Yet?","type":"publication"},{"authors":["Wei Yang","Tao Xie"],"categories":null,"content":"","date":1515974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515974400,"objectID":"026a1f8601da006d613493972298e057","permalink":"http://youngwei.com/publication/telemade/","publishdate":"2018-01-15T00:00:00Z","relpermalink":"/publication/telemade/","section":"publication","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads. To address the challenge, we propose Telemade, a testing framework for learning-based malware detectors.","tags":null,"title":"Telemade: A Testing Framework for Learning-Based Malware Detection Systems. ","type":"publication"},{"authors":["Wei Yang","Deguang Kong","Tao Xie","Carl A. Gunter"],"categories":null,"content":"","date":1513296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513296000,"objectID":"b02f5a89209816587da7bec0c2357f1b","permalink":"http://youngwei.com/publication/mrv/","publishdate":"2017-12-15T00:00:00Z","relpermalink":"/publication/mrv/","section":"publication","summary":"Existing techniques on adversarial malware generation employ feature mutations based on feature vectors extracted from malware. However, most (if not all) of these techniques suffer from a common limitation: feasibility of these attacks is unknown. The synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads. To address the limitation, we present Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and malware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we conduct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants. We evaluate our MRV approach on actual malware variants, and our empirical evaluation on 1,935 Android benign apps and 1,917 malware shows that MRV produces malware variants that can have high likelihood to evade detection while still retaining their malicious behaviors. We also propose and evaluate three defense mechanisms to counter MRV.","tags":null,"title":"Malware Detection in Adversarial Settings: Exploiting Feature Evolutions and Confusions in Android Apps","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"049b43a1b4527f76346e7294b31ba7b1","permalink":"http://youngwei.com/talk/mwpls-2017/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/talk/mwpls-2017/","section":"talk","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads.","tags":null,"title":"Generating Adversarial Examples with Program Transformations: Practical Attacks to Machine Learner.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508803200,"objectID":"a46e0186da8b4a4d7947e1348c865957","permalink":"http://youngwei.com/talk/sjtu2017/","publishdate":"2017-10-24T00:00:00Z","relpermalink":"/talk/sjtu2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection.In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of securitysensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and malware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we conduct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"a6ca05815811676883dc49141fcd871c","permalink":"http://youngwei.com/talk/fudan2017/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/talk/fudan2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection. In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. \n\n In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and mal- ware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we con- duct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508371200,"objectID":"651ea80d375835ecceb03376c5533af0","permalink":"http://youngwei.com/talk/ecnu2017/","publishdate":"2017-10-19T00:00:00Z","relpermalink":"/talk/ecnu2017/","section":"talk","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads.","tags":null,"title":"Testing Learning-Based Security System: Generating Adversarial Samples for Static Analysis and Machine Learning.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508284800,"objectID":"c0398c9b862fd31a05bc8daede6d8c28","permalink":"http://youngwei.com/talk/shanghaitech2017/","publishdate":"2017-10-18T00:00:00Z","relpermalink":"/talk/shanghaitech2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection. In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. \n\n In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and mal- ware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we con- duct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Haibing Zheng","Dengfeng Li","Beihai Liang","Xia Zeng","Wujie Zheng","Yuetang Deng","Wing Lam","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1494806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494806400,"objectID":"32c599bc2efc60bcfcd029ad6b3f6fb1","permalink":"http://youngwei.com/publication/wctester_icse17/","publishdate":"2017-05-15T00:00:00Z","relpermalink":"/publication/wctester_icse17/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Automated Test Input Generation for Android: Towards Getting There in an Industrial Case","type":"publication"},{"authors":["Dengfeng Li","Wing Lam","Wei Yang","Zhengkai Wu","Xusheng Xiao","Tao Xie"],"categories":null,"content":"","date":1492214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492214400,"objectID":"984c5506afd7c8063fee0efe55794de3","permalink":"http://youngwei.com/publication/hotsos17/","publishdate":"2017-04-15T00:00:00Z","relpermalink":"/publication/hotsos17/","section":"publication","summary":"As mobile apps are increasingly becoming data-driven, these apps tend to collect much app usage data to carry out their promised utilities and enhance user experiences. Unfortunately, some highly sensitive information in the data provides little or no benefit towards delivering the apps’ utilities. For instance, for an app whose purpose is to show video game trailers, it is unnecessary to request and send its users’ phone number and contact list to a remote server. There is a strong need for a framework to help protect users’ app usage data while retaining the app’s utility efficacy (e.g., the number of enabled features). \n \n  There are three main challenges in realizing such framework. First, it is difficult to correctly identify security-sensitive information in the app usage data. For instance, user input text (such as “My password is 12345”) can contain sensitive information, and such framework needs to understand the semantic meaning of such text in order to know whether sensitive information is present or not. Second, because utilities of apps vary dramatically, there is a need for generically applicable program analysis to measure the impact of information anonymization on the level of utility efficacy. Third, balancing privacy preservation and utility efficacy requires fine-grained analysis on privacy specification (such as a privacy policy declared by the app’s developers) and the app. To address these challenges, we propose a privacy framework that enables a mobile app’s developers to determine what sensitive information can be anonymized while maintaining a desirable level of utility efficacy.","tags":null,"title":"Towards Privacy-Preserving Mobile Apps: A Balancing Act. ","type":"publication"},{"authors":["Soteris Demetriou","Whitney Merrill","Wei Yang","Aston Zhang","Carl A. Gunter"],"categories":null,"content":"","date":1481760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481760000,"objectID":"30da4d9c443ecd193ca2d8e6a8f53b08","permalink":"http://youngwei.com/publication/pluto/","publishdate":"2016-12-15T00:00:00Z","relpermalink":"/publication/pluto/","section":"publication","summary":"In this work, we systematically explore the potential reach of advertising libraries through these channels. We design a framework called Pluto that can be leveraged to analyze an app and discover whether it exposes targeted user data—such as contact information, interests, demographics, medical conditions and so on—-to an opportunistic ad library. We present a prototype implementation of Pluto, that embodies novel strategies for using natural language processing to illustrate what targeted data can potentially be learned from an ad network using files and user inputs. Pluto also leverages machine learning and data mining models to reveal what advertising networks can learn from the list of installed apps. We validate Pluto with a collection of apps for which we have determined ground truth about targeted data they may reveal, together with a data set derived from a survey we conducted that gives ground truth for targeted data and corresponding lists of installed apps for about 300 users. We use these to show that Pluto, and hence also opportunistic ad networks, can achieve 75% recall and 80% precision for selected targeted data coming from app files and inputs, and even better results for certain targeted data based on the list of installed apps. Pluto is the first tool that estimates the risk associated with integrating advertising in apps based on the four available channels and arbitrary sets of targeted data.","tags":null,"title":"Free for All! Assessing User Data Exposure to Advertising Libraries on Android","type":"publication"},{"authors":["Xia Zeng","Dengfeng Li","Wujie Zheng","Fan Xia","Yuetang Deng","Wing Lam","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1476489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476489600,"objectID":"d69584865984ae27306f414c4348456d","permalink":"http://youngwei.com/publication/wctester_fse16/","publishdate":"2016-10-15T00:00:00Z","relpermalink":"/publication/wctester_fse16/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Automated Test Input Generation for Android: Are We Really There Yet in an Industrial Case?","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1470960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470960000,"objectID":"0b3a468e04a4e31bdef6adbf7f551054","permalink":"http://youngwei.com/talk/ibm2/","publishdate":"2016-08-12T00:00:00Z","relpermalink":"/talk/ibm2/","section":"talk","summary":"Identifying similar code in software systems can assist many software engineering tasks such as program understanding and software refactoring. While most approaches focus on identifying syntactically similar code (i.e., code that looks alike), Ideally, we would like to also include code that is behaviorally or functionally similar, even if it looks completely different. Detecting these functional clones — code that functions alike — in mobile applications remains an open question because of the difficulty in exposing and comparing programs’ functionality effectively. In this talk, I will present a novel technique that detects functional clones in complex mobile app codebases by identifying and comparing their user interface and key API method calls. The key insight is that user interface usually indicate the functionality to be implemented by a program which complements existing program analysis to detect functional clones.","tags":null,"title":"Searching Functionally Similar Code via UI Prototype.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1468195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1468195200,"objectID":"0ae2e6d056e0acb527f63fb9e16dfec5","permalink":"http://youngwei.com/talk/ibm1/","publishdate":"2016-07-11T00:00:00Z","relpermalink":"/talk/ibm1/","section":"talk","summary":"Numerous apps on the mobile-app market such as team management present opportunities beyond traditional mobile and email communications, greatly enhancing the productivity and mobility of employees in companies. However, these apps may contain unwanted behaviors, such as information leakage and root exploits, and thus violates enterprise security policies. Unwanted behaviors in mobile app can evade detection during app analysis by mimicking security-sensitive behaviors of benign behaviors that provide similar functionality (e.g., sending SMS messages), and suppressing their payload to reduce the chance of being observed (e.g., executing only its payload at night). Since current approaches focus their analyses on the types of security-sensitive resources being accessed (e.g., network), these evasive techniques make differentiating between unwanted and benign app behaviors a difficult task during app analysis. In this talk, I propose that unwanted and benign behaviors within apps can be differentiated based on the contexts that trigger security-sensitive behaviors, i.e., the events and conditions that cause the security-sensitive behaviors to occur. I will first introduce AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. Then, I will introduce WHYPER, a technique that explain why sensitive user information is used by the applications to help users make better decisions in permission granting. Next, I will briefly mention the malware recomposition variation (MRV) technique that can attack the proposed contextually-aware detection technique by systematically producing malware variants. Last, I will give an introduction on Smar (Systematic Mobile App Repair), that iteratively repairs unwanted behaviors at all four levels of granularity (“where”, “when”, “what”, and “how”).","tags":null,"title":"Contextually-Aware Mobile Security: Identification, Variation and Fixing of Mobile Threats.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Dengfeng Li","Huoran Li","Xuanzhe Liu","Haoyu Wang","Yao Guo","Tao Xie"],"categories":null,"content":"","date":1460678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1460678400,"objectID":"ae5d577411751f7d6799770a14d02b1c","permalink":"http://youngwei.com/publication/jcs_journal/","publishdate":"2016-04-15T00:00:00Z","relpermalink":"/publication/jcs_journal/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Security Analytics for Mobile Apps: Achievements and Challenges.","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1458000000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458000000,"objectID":"9b7b1b37f20546dc477b3c31d0d920a4","permalink":"http://youngwei.com/talk/qualcomm2016/","publishdate":"2016-03-15T00:00:00Z","relpermalink":"/talk/qualcomm2016/","section":"talk","summary":"What an application (or “app”) does is not always what a user expects. User expectations stem from user perceptions (information they can perceive about an application). User perceptions come from two sources: app descriptions form user perception before installation, and user interfaces enrich user perception after installation. Two types of inconsistencies, corresponding to each of these sources, contribute to the gap between app behavior and user perception. (1) Install-time inconsistency involves the functionalities described in app descriptions being inconsistent with the actual app behaviors. (2) Run-time inconsistency involves the behavior indicated through user interfaces (external behavior) being inconsistent with the behavior running in the background (internal behavior). In this proposal, we aim to bridge the gap between user perception and app behavior by developing a set of automated analyses to check these two inconsistencies and warn users about potential risks.","tags":null,"title":"Validating Application Behavior against User Expectations.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Benjamin Andow","Sihan Li","Tao Xie","William Enck"],"categories":null,"content":"","date":1450137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450137600,"objectID":"e5f00ebd10d5e66e87712c6477de2c76","permalink":"http://youngwei.com/publication/appcontext/","publishdate":"2015-12-15T00:00:00Z","relpermalink":"/publication/appcontext/","section":"publication","summary":"Mobile malware attempts to evade detection during app analysis by mimicking security-sensitive behaviors of benign apps that provide similar functionality (e.g., sending SMS messages), and suppressing their payload to reduce the chance of being observed (e.g., executing only its payload at night). Since current approaches focus their analyses on the types of securitysensitive resources being accessed (e.g., network), these evasive techniques in malware make differentiating between malicious and benign app behaviors a difficult task during app analysis. We propose that the malicious and benign behaviors within apps can be differentiated based on the contexts that trigger securitysensitive behaviors, i.e., the events and conditions that cause the security-sensitive behaviors to occur. In this work, we introduce AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. We implement a prototype of AppContext and evaluate AppContext on 202 malicious apps from various malware datasets, and 633 benign apps from the Google Play Store. AppContext correctly identifies 192 malicious apps with 87.7% precision and 95% recall. Our evaluation results suggest that the maliciousness of a security-sensitive behavior is more closely related to the intention of the behavior (reflected via contexts) than the type of the security-sensitive resources that the behavior accesses.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1450051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450051200,"objectID":"43931ad1e082b4ea06d1253a2ec361b9","permalink":"http://youngwei.com/talk/sjtu2015/","publishdate":"2015-12-14T00:00:00Z","relpermalink":"/talk/sjtu2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1437091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437091200,"objectID":"5a49ac11d3dc7acda35ec166c074502f","permalink":"http://youngwei.com/talk/sri2015/","publishdate":"2015-07-17T00:00:00Z","relpermalink":"/talk/sri2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1424995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1424995200,"objectID":"6af637e8f1bec9a513fc4d43ec746c00","permalink":"http://youngwei.com/talk/csl2015/","publishdate":"2015-02-27T00:00:00Z","relpermalink":"/talk/csl2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"Improving Mobile Application Security via Bridging User Expectations and Application Behaviors.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Rahul Pandita","William Enck","Tao Xie"],"categories":null,"content":"","date":1397520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1397520000,"objectID":"8d53210094fa198b5526ab40a6c4e515","permalink":"http://youngwei.com/publication/hotsos14/","publishdate":"2014-04-15T00:00:00Z","relpermalink":"/publication/hotsos14/","section":"publication","summary":"To keep malware out of mobile application markets, existing techniques analyze the security aspects of application behaviors and summarize patterns of these security aspects to determine what applications do. However, user expectations (reflected via user perception in combination with user judgment) are often not incorporated into such analysis to determine whether application behaviors are within user expectations. This poster presents our recent work on bridging the semantic gap between user perceptions of the application behaviors and the actual application behaviors.","tags":null,"title":"Improving Mobile Application Security via Bridging User Expectations and Application Behaviors.","type":"publication"},{"authors":["Rahul Pandita","Xusheng Xiao","Wei Yang","William Enck","Tao Xie"],"categories":null,"content":"","date":1387065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1387065600,"objectID":"60b7507c13c0822157cd22272f960284","permalink":"http://youngwei.com/publication/whyper/","publishdate":"2013-12-15T00:00:00Z","relpermalink":"/publication/whyper/","section":"publication","summary":"Application markets such as Apple’s App Store and Google’s Play Store have played an important role in the popularity of smartphones and mobile devices. However, keeping malware out of application markets is an ongoing challenge. While recent work has developed various techniques to determine what applications do, no work has provided a technical approach to answer, what do users expect? In this paper, we present the first step in addressing this challenge. Specifically, we focus on permissions for a given application and examine whether the application description provides any indication for why the application needs a permission. We present WHYPER, a framework using Natural Language Processing (NLP) techniques to identify sentences that describe the need for a given permission in an application description. WHYPER achieves an average precision of 82.8%, and an average recall of 81.5% for three permissions (address book, calendar, and record audio) that protect frequentlyused security and privacy sensitive resources. These results demonstrate great promise in using NLP techniques to bridge the semantic gap between user expectations and application functionality, further aiding the risk assessment of mobile applications.","tags":null,"title":"WHYPER: Towards Automating Risk Assessment of Mobile Applications","type":"publication"},{"authors":["Wei Yang","Mukul Prasad","Tao Xie"],"categories":null,"content":"","date":1360886400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1360886400,"objectID":"99fcd9071b7382bde04ce24d4bb208da","permalink":"http://youngwei.com/publication/orbit/","publishdate":"2013-02-15T00:00:00Z","relpermalink":"/publication/orbit/","section":"publication","summary":"As the mobile platform continues to pervade all aspects of human activity, and mobile apps on this platform tend to be faulty just like other types of software, there is a growing need for automated testing techniques for mobile applications. Model-based testing is a popular and important testing approach which operates on a model of an application’s behavior. However, such a model is often not available or of insufficient quality. To address this issue, we present a novel grey-box approach for automatically extracting a model of a given mobile application. In our approach, static analysis extracts the set of events supported by the Graphical User Interface (GUI) of the application. Then dynamic crawling reverse-engineers a model of the application, by systematically exercising these events on the running application. We also present a tool implementing this approach for the Android platform. Our empirical evaluation of this tool on several Android applications demonstrates that it can efficiently extract compact yet reasonably comprehensive models of high quality for such applications.","tags":null,"title":"A Grey-box Approach for Automated GUI-Model Generation of Mobile Applications","type":"publication"}]