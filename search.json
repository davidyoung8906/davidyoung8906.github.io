[{"authors":["Qi Wang","Pubali Datta","Wei Yang","Si Liu","Carl Gunter","Adam Bates"],"categories":null,"content":"","date":1563580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563580800,"objectID":"0f36eaf224e30bd9578e465e6ae989fe","permalink":"http://youngwei.com/publication/iruler/","publishdate":"2019-07-20T00:00:00Z","relpermalink":"/publication/iruler/","section":"publication","summary":"Internet of Things (IoT) deployments are becoming increasingly automated and vastly more complex. Facilitated by programming abstractions such as trigger-action rules, end-users can now easily create new functionalities by interconnecting their devices and other online services. However, when multiple rules are simultaneously enabled, complex system behaviors arise that are difficult to understand or diagnose. While history tells us that such conditions are ripe for exploitation, at present the security states of trigger-action IoT deployments are largely unknown. In this work, we conduct a comprehensive analysis of the interactions between trigger-action rules in order to identify their security risks. Using IFTTT as an exemplar platform, we first enumerate the space of inter-rule vulnerabilities that exist within trigger-action platforms. To aid users in the identification of these dangers, we go on to present iRuler, a system that performs Satisfiability Modulo Theories (SMT) solving and model checking to discover inter-rule vulnerabilities within IoT deployments. iRuler operates over an abstracted information flow model that represents the attack surface of an IoT deployment, but we discover in practice that such models are difficult to obtain given the closed nature of IoT platforms. To address this, we develop methods that assist in inferring triggeraction information flows based on Natural Language Processing. We develop a novel evaluative methodology for approximating plausible real-world IoT deployments based on the installation counts of 315,393 IFTTT applets, determining that 66% of the synthetic deployments in the IFTTT ecosystem exhibit the potential for interrule vulnerabilities. Combined, these efforts provide the insight into the real-world dangers of IoT deployment misconfigurations.","tags":null,"title":"Charting the Attack Surface of Trigger-Action IoT Platforms","type":"publication"},{"authors":["Zhengkai Wu","Evan N. Johnson","Wei Yang","Osbert Bastani","Dawn Song","Jian Peng","Tao Xie"],"categories":null,"content":"","date":1558742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558742400,"objectID":"136fd391cc4c5b8d2c4e48ecc8a48a36","permalink":"http://youngwei.com/publication/reinam/","publishdate":"2019-05-25T00:00:00Z","relpermalink":"/publication/reinam/","section":"publication","summary":"Program-input grammars (i.e., grammars encoding the language of valid program inputs) facilitate a wide range of applications in software engineering such as symbolic execution and delta debugging. Grammars synthesized by existing approaches can cover only a small part of the valid input space mainly due to unanalyzable code (e.g., native code) in programs and lacking high-quality, high-variety, and high-quantity seed inputs. To address these challenges, we present REINAM, a reinforcement-learning approach for synthesizing a probabilistic context-free program-input grammars without any seed input. REINAM includes an industrial symbolic execution engine to generate an initial set of inputs for the given target program, and includes an iterative process of grammar generalization to proactively generate additional inputs in order to infer grammars generalized from the initial seed inputs. To efficiently search for target generalizations in a huge search space of candidate generalization operators, REINAM includes a novel formulation of the search problem as the problem of reinforcement learning. Our evaluation results on five real-world subjects show that REINAM outperforms an existing state-of-the-art approach on precision and recall of synthesized grammars, and fuzz testing based on REINAM substantially increases the coverage of the valid input space. REINAM is able to synthesize a grammar covering the whole valid input space for some subjects without decreasing accuracy of the grammar.","tags":null,"title":"REINAM: Reinforcement Learning for Input-Grammar Inference","type":"publication"},{"authors":["Wenyu Wang","Wujie Zheng","Dian Liu","Changrong Zhang","Qinsong Zeng","Yuetang Deng","Wei Yang","Pinjia He","Tao Xie"],"categories":null,"content":"","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551744000,"objectID":"b642b632a7fa8f3484e7046a46d819a4","permalink":"http://youngwei.com/publication/dsn19_industry/","publishdate":"2019-03-05T00:00:00Z","relpermalink":"/publication/dsn19_industry/","section":"publication","summary":"Despite getting widely adopted recently, a Neural Machine Translation (NMT) system is often found to produce translation failures in the outputs. Developers have been relying on in-house system testing for quality assurance of NMT. This testing methodology requires human-constructed reference translations as the ground truth (test oracle) for example natural language inputs. The testing methodology has shown benefits of quickly enhancing an NMT system in early development stages. However, in industrial settings, it is desirable to detect translation failures without reliance on reference translations for enabling further improvements on translation quality in both industrial development and production environments. Aiming for a practical and scalable solution to such demand in the industrial settings, in this paper, we propose a new approach for automatically identifying translation failures without requiring reference translations for a translation task. Our approach focuses on a property of natural language translation that can be checked systematically by using information from both the test inputs (i.e., the texts to be translated) and the test outputs (i.e., the translations under inspection) of the NMT system. Our evaluation conducted on real-world datasets shows that our approach can effectively detect property violations as translation failures. By deploying our approach in the translation service of WeChat (a messenger app with more than one billion monthly active users), we show that our approach is both practical and scalable in the industrial settings.","tags":null,"title":"Detecting Failures of Neural Machine Translation in the Absence of Reference Translations","type":"publication"},{"authors":["Wujie Zheng","Wenyu Wang","Dian Liu","Changrong Zhang","Qinsong Zeng","Yuetang Deng","Wei Yang","Pinjia He","Tao Xie"],"categories":null,"content":"","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551744000,"objectID":"b29600850a3220dccd90b299a2abba86","permalink":"http://youngwei.com/publication/icse19_poster/","publishdate":"2019-03-05T00:00:00Z","relpermalink":"/publication/icse19_poster/","section":"publication","summary":"Neural Machine Translation (NMT) has shown great advantages and is becoming increasingly popular. However, in practice, NMT often produces unexpected translation failures in its translations. While reference-based black-box system testing has been a common practice for NMT quality assurance during development, an increasingly critical industrial practice, named in-vivo testing, exposes unseen types or instances of translation failures when real users are using a deployed industrial NMT system. To fill the gap of lacking test oracles for in-vivo testing of NMT systems, we propose a new methodology for automatically identifying translation failures without reference translations. Our evaluation conducted on real-world datasets shows that our methodology effectively detects several targeted types of translation failures. Our experiences on deploying our methodology in both production and development environments of WeChat (a messenger app with over one billion monthly active users) demonstrate high effectiveness of our methodology along with high industry impact.","tags":null,"title":"Testing Untestable Neural Machine Translation: An Industrial Case","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1545264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545264000,"objectID":"2387cefccfe6937de11eb6dfb2bcd639","permalink":"http://youngwei.com/talk/pku2018/","publishdate":"2018-12-20T00:00:00Z","relpermalink":"/talk/pku2018/","section":"talk","summary":"For too long, researchers have often tackled security in an attack-driven, ad hoc, and reactionary manner with large manual efforts devoted by security analysts. In order to make substantial progress in security, I advocate to shift such manner to be systematic, intelligent, and adversarial resilient. I have developed software engineering techniques to automate decision makings in security systems, and built defenses and testing methodologies to guard against emerging attacks specifically adversarial to these newly-proposed techniques. In this talk, I will first highlight one of these systems for mobile security: AppContext, a malware detection system extracting execution contexts of an app’s security-sensitive behaviors through program analysis. Then I will show how an adaptive adversary can attack these systems and how we can generate adversarial inputs ahead of time for testing and further strengthening these systems. I will conclude by discussing how future research efforts can leverage the interplay among software engineering, security, and AI techniques toward a defense-driven security ecosystem.","tags":null,"title":"Adversarial-Resilience Assurance for Mobile Security Systems.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1545004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545004800,"objectID":"c4fdbe13c4f766f21ed1d77ecb06f6c0","permalink":"http://youngwei.com/talk/fudan2018/","publishdate":"2018-12-17T00:00:00Z","relpermalink":"/talk/fudan2018/","section":"talk","summary":"For too long, researchers have often tackled security in an attack-driven, ad hoc, and reactionary manner with large manual efforts devoted by security analysts. In order to make substantial progress in security, I advocate to shift such manner to be systematic, intelligent, and adversarial resilient. I have developed software engineering techniques to automate decision makings in security systems, and built defenses and testing methodologies to guard against emerging attacks specifically adversarial to these newly-proposed techniques. In this talk, I will first highlight one of these systems for mobile security: AppContext, a malware detection system extracting execution contexts of an app’s security-sensitive behaviors through program analysis. Then I will show how an adaptive adversary can attack these systems and how we can generate adversarial inputs ahead of time for testing and further strengthening these systems. I will conclude by discussing how future research efforts can leverage the interplay among software engineering, security, and AI techniques toward a defense-driven security ecosystem.","tags":null,"title":"Adversarial Learning and Mobile Security System.","type":"talk"},{"authors":["Zexuan Zhong","Jiaqi Guo","Wei Yang","Jian Peng","Tao Xie","Jian-Guang Lou","Ting Liu","Dongmei Zhang"],"categories":null,"content":"","date":1532908800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532908800,"objectID":"f0db75ada8eb2e39c0e74197984bd4e7","permalink":"http://youngwei.com/publication/semregex/","publishdate":"2018-07-30T00:00:00Z","relpermalink":"/publication/semregex/","section":"publication","summary":"Recent research proposes syntax-based approaches to address the problem of generating programs from natural language specifications. These approaches typically train a sequence-to-sequence learning model using a syntax-based objective: maximum likelihood estimation (MLE). Such syntax-based approaches do not effectively address the goal of generating semantically correct programs, because these approaches fail to handle Program Aliasing, i.e., semantically equivalent programs may have many syntactically different forms. To address this issue, in this paper, we propose a semantics-based approach named SemRegex. SemRegex provides solutions for a subtask of the program-synthesis problem: generating regular expressions from natural language. Different from the existing syntax-based approaches, SemRegex trains the model by maximizing the expected semantic correctness of the generated regular expressions. The semantic correctness is measured using the DFA-equivalence oracle, random test cases, and distinguishing test cases. The experiments on three public datasets demonstrate the superiority of SemRegex over the existing state-of-the-art approaches.","tags":null,"title":"SemRegex: A Semantics-Based Approach for Generating Regular Expressions from Natural Language Specifications","type":"publication"},{"authors":["Karan Ganju","Qi Wang","Wei Yang","Carl A. Gunter","Nikita Borisov"],"categories":null,"content":"","date":1531612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531612800,"objectID":"252dac2a87782dad45b98f7856b34e53","permalink":"http://youngwei.com/publication/permuteinvariance/","publishdate":"2018-07-15T00:00:00Z","relpermalink":"/publication/permuteinvariance/","section":"publication","summary":"With the growing adoption of machine learning, sharing of learned models is becoming popular. However, in addition to the prediction properties the model producer aims to share, there is also a risk that the model consumer can infer other properties of the training data the model producer did not intend to share. In this paper, we focus on the inference of global properties of the training data, such as the environment in which the data was produced, or the fraction of the data that comes from a certain class, as applied to white-box Fully Connected Neural Networks (FCNNs).","tags":null,"title":"Property Inference Attacks on Deep Neural Networks using Permutation Invariant Representations","type":"publication"},{"authors":["Xueqing Liu","Yue Leng","Wei Yang","Wenyu Wang","Chengxiang Zhai","Tao Xie"],"categories":null,"content":"","date":1529020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529020800,"objectID":"0e9de60cd8cb5d6e15445752320d0e9f","permalink":"http://youngwei.com/publication/clap_vlhcc/","publishdate":"2018-06-15T00:00:00Z","relpermalink":"/publication/clap_vlhcc/","section":"publication","summary":"After Android 6.0 introduces the runtimepermission system, many apps provide runtime-permissiongroup rationales for the users to better understand the permissions requested by the apps. To understand the patterns of rationales and to what extent the rationales can improve the users’ understanding of the purposes of requesting permission groups, we conduct a large-scale measurement study on five aspects of runtime rationales. We have five main findings: (1) less than 25% apps under study provide rationales; (2) for permission-group purposes that are difficult to understand, the proportions of apps that provide rationales are even lower; (3) the purposes stated in a significant proportion of rationales are incorrect; (4) a large proportion of customized rationales do not provide more information than the default permission-requesting message of Android; (5) apps that provide rationales are more likely to explain the same permission group’s purposes in their descriptions than apps that do not provide rationales. We further discuss important implications from these findings.","tags":null,"title":"A Large-Scale Empirical Study on Android Runtime Permission Rationale Messages","type":"publication"},{"authors":["Wenyu Wang","Dengfeng Li","Wei Yang","Yurui Cao","Zhenwen Zhang","Yuetang Deng","Tao Xie"],"categories":null,"content":"","date":1529020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529020800,"objectID":"0e51e5cffc7ed195e7fe0f2fe026fdab","permalink":"http://youngwei.com/publication/wctester/","publishdate":"2018-06-15T00:00:00Z","relpermalink":"/publication/wctester/","section":"publication","summary":"User Interface (UI) testing is a popular approach to ensure the quality of mobile apps. Numerous test generation tools have been developed to support UI testing on mobile apps, especially for Android apps. Previous work evaluates and compares different test generation tools using only relatively simple open-source apps, while real-world industrial apps tend to have more complex functionalities and implementations. There is no direct comparison among test generation tools with regard to effectiveness and easeof-use on these industrial apps. To address such limitation, we study existing state-of-the-art or state-of-the-practice test generation tools on 68 widely-used industrial apps. We directly compare the tools with regard to code coverage and fault-detection ability. According to our results, Monkey, a state-of-the-practice tool from Google, achieves the highest method coverage on 22 of 41 apps whose method coverage data can be obtained. Of all 68 apps under study, Monkey also achieves the highest activity coverage on 35 apps, while Stoat, a state-of-the-art tool, is able to trigger the highest number of unique crashes on 23 apps. By analyzing the experimental results, we provide suggestions for combining different test generation tools to achieve better performance. We also report our experience in applying these tools to industrial apps under study. Our study results give insights on how Android UI test generation tools could be improved to better handle complex industrial apps.","tags":null,"title":"An Empirical Study of Android Test Generation Tools in Industrial Cases","type":"publication"},{"authors":["Xueqing Liu","Yue Leng","Wei Yang","Chengxiang Zhai","Tao Xie"],"categories":null,"content":"","date":1527638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527638400,"objectID":"a6d3330a768a2044a7dfb70d6aa2c2b6","permalink":"http://youngwei.com/publication/clap_re/","publishdate":"2018-05-30T00:00:00Z","relpermalink":"/publication/clap_re/","section":"publication","summary":"During the development or maintenance of an Android app, the app developer needs to determine the app’s security and privacy requirements such as permission requirements. Permission requirements include two folds: (1) what permissions (i.e., access to sensitive resources, e.g., location or contact list) the app needs to request, and (2) how to explain the reason of permission usages to users. In this paper, we focus on the multiple challenges that developers face when creating the explanations for permission usages. We propose a novel framework, CLAP, that mines potential explanations from the descriptions of similar apps. CLAP leverages information retrieval and text summarization techniques to find frequent permission usages. We evaluate CLAP on a large dataset containing 1.4 million Android apps. The evaluation results show that CLAP outperforms existing stateof-the-art approaches, and has great promise to assist developers for permission requirements discovery.","tags":null,"title":"Mining Android App Description for Permission Requirements Recommendation","type":"publication"},{"authors":["Wei Yang","Mukul Prasad","Tao Xie"],"categories":null,"content":"","date":1526342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526342400,"objectID":"965a04034cf5b8ce30559ecc07b9a531","permalink":"http://youngwei.com/publication/enmobile/","publishdate":"2018-05-15T00:00:00Z","relpermalink":"/publication/enmobile/","section":"publication","summary":"Modern mobile malware tend to conduct their malicious exploits through sophisticated patterns of interactions that involve multiple entities, e.g., the mobile platform, human users, and network locations. Such malware often evade the detection by existing approaches due to their limited expressiveness and accuracy in characterizing and detecting these malware. To address these issues, in this paper, we recognize entities in the environment of an app, the app’s interactions with such entities, and the provenance of these interactions, i.e., the intent and ownership of each interaction, as the key to comprehensively characterizing modern mobile apps, and mobile malware in particular. With this insight, we propose a novel approach named EnMobile including a new entity-based characterization of mobile-app behaviors, and corresponding static analyses, to accurately characterize an app’s interactions with entities. We implement EnMobile and provide a practical application of EnMobile in a signature-based scheme for detecting mobile malware. We evaluate EnMobile on a set of 6614 apps consisting of malware from Genome and Drebin along with benign apps from Google Play. Our results show that EnMobile detects malware with substantially higher precision and recall than four state-of-the-art approaches, namely Apposcopy, Drebin, MUDFLOW, and AppContext.","tags":null,"title":"EnMobile: Entity-based Characterization and Analysis of Mobile Malware","type":"publication"},{"authors":["Zexuan Zhong","Jiaqi Guo","Wei Yang","Tao Xie","Jian-Guang Lou","Ting Liu","Dongmei Zhang"],"categories":null,"content":"","date":1517270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517270400,"objectID":"690ede48a5a96ba31024068dcf5d4f74","permalink":"http://youngwei.com/publication/semregex-aaai/","publishdate":"2018-01-30T00:00:00Z","relpermalink":"/publication/semregex-aaai/","section":"publication","summary":"Recent state-of-the-art approaches automatically generate regular expressions from natural language specifications. Given that these approaches use only synthetic data in both training datasets and validation/test datasets, a natural question arises: are these approaches effective to address various real-world situations? To explore this question, in this paper, we conduct a characteristic study on comparing two synthetic datasets used by the recent research and a real-world dataset collected from the Internet, and conduct an experimental study on applying a state-of-the-art approach on the real-world dataset. Our study results suggest the existence of distinct characteristics between the synthetic datasets and the real-world dataset, and the state-of-the-art approach (based on a model trained from a synthetic dataset) achieves extremely low effectiveness when evaluated on real-world data, much lower than the effectiveness when evaluated on the synthetic dataset. We also provide initial analysis on some of those challenging cases and discuss future directions.","tags":null,"title":"Generating Regular Expressions from Natural Language Specifications: Are We There Yet?","type":"publication"},{"authors":["Wei Yang","Tao Xie"],"categories":null,"content":"","date":1515974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515974400,"objectID":"026a1f8601da006d613493972298e057","permalink":"http://youngwei.com/publication/telemade/","publishdate":"2018-01-15T00:00:00Z","relpermalink":"/publication/telemade/","section":"publication","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads. To address the challenge, we propose Telemade, a testing framework for learning-based malware detectors.","tags":null,"title":"Telemade: A Testing Framework for Learning-Based Malware Detection Systems. ","type":"publication"},{"authors":["Wei Yang","Deguang Kong","Tao Xie","Carl A. Gunter"],"categories":null,"content":"","date":1513296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513296000,"objectID":"b02f5a89209816587da7bec0c2357f1b","permalink":"http://youngwei.com/publication/mrv/","publishdate":"2017-12-15T00:00:00Z","relpermalink":"/publication/mrv/","section":"publication","summary":"Existing techniques on adversarial malware generation employ feature mutations based on feature vectors extracted from malware. However, most (if not all) of these techniques suffer from a common limitation: feasibility of these attacks is unknown. The synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads. To address the limitation, we present Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and malware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we conduct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants. We evaluate our MRV approach on actual malware variants, and our empirical evaluation on 1,935 Android benign apps and 1,917 malware shows that MRV produces malware variants that can have high likelihood to evade detection while still retaining their malicious behaviors. We also propose and evaluate three defense mechanisms to counter MRV.","tags":null,"title":"Malware Detection in Adversarial Settings: Exploiting Feature Evolutions and Confusions in Android Apps","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"049b43a1b4527f76346e7294b31ba7b1","permalink":"http://youngwei.com/talk/mwpls-2017/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/talk/mwpls-2017/","section":"talk","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads.","tags":null,"title":"Generating Adversarial Examples with Program Transformations: Practical Attacks to Machine Learner.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508803200,"objectID":"a46e0186da8b4a4d7947e1348c865957","permalink":"http://youngwei.com/talk/sjtu2017/","publishdate":"2017-10-24T00:00:00Z","relpermalink":"/talk/sjtu2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection.In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of securitysensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and malware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we conduct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"a6ca05815811676883dc49141fcd871c","permalink":"http://youngwei.com/talk/fudan2017/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/talk/fudan2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection. In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. \n\n In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and mal- ware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we con- duct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508371200,"objectID":"651ea80d375835ecceb03376c5533af0","permalink":"http://youngwei.com/talk/ecnu2017/","publishdate":"2017-10-19T00:00:00Z","relpermalink":"/talk/ecnu2017/","section":"talk","summary":"Learning-based malware detectors may be erroneous due to two inherent limitations. First, there is a lack of differentiability: selected features may not reflect essential differences between malware and benign apps. Second, there is a lack of comprehensiveness: the used machine learning (ML) models are usually based on prior knowledge of existing malware (i.e., training dataset) so malware can evolve to evade the detection. There is a strong need for an automated framework to help security analysts to detect errors in learning-based malware detection systems. Existing techniques to generate adversarial samples for learning-based systems (that take images as inputs) employ feature mutations based on feature vectors. Such techniques are infeasible to generate adversarial samples (e.g., evasive malware) for malware detection systems because the synthesized mutations may break the inherent constraints posed by code structures of the malware, causing either crashes or malfunctioning of malicious payloads.","tags":null,"title":"Testing Learning-Based Security System: Generating Adversarial Samples for Static Analysis and Machine Learning.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1508284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508284800,"objectID":"c0398c9b862fd31a05bc8daede6d8c28","permalink":"http://youngwei.com/talk/shanghaitech2017/","publishdate":"2017-10-18T00:00:00Z","relpermalink":"/talk/shanghaitech2017/","section":"talk","summary":"The increasing popularity of smartphones has made them a target for malware. In this talk, I will introduce both defense against mobile malware and attacks that break existing malware detection. In the first half of my talk, I will introduce a malware detection approach. Namely AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. \n\n In the second half of the talk, I will present attacks that break existing malware detection. Specifically, I will introduce Malware Recomposition Variation (MRV), an approach that conducts semantic analysis of existing malware to systematically construct new malware variants for malware detectors to test and strengthen their detection signatures/models. In particular, we use two variation strategies (i.e., malware evolution attack and mal- ware confusion attack) following structures of existing malware to enhance feasibility of the attacks. Upon the given malware, we con- duct semantic-feature mutation analysis and phylogenetic analysis to synthesize mutation strategies. Based on these strategies, we perform program transplantation to automatically mutate malware bytecode to generate new malware variants.","tags":null,"title":"Defense and Attacks on Mobile Malware Detection.","type":"talk"},{"authors":["Haibing Zheng","Dengfeng Li","Beihai Liang","Xia Zeng","Wujie Zheng","Yuetang Deng","Wing Lam","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1494806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494806400,"objectID":"32c599bc2efc60bcfcd029ad6b3f6fb1","permalink":"http://youngwei.com/publication/wctester_icse17/","publishdate":"2017-05-15T00:00:00Z","relpermalink":"/publication/wctester_icse17/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Automated Test Input Generation for Android: Towards Getting There in an Industrial Case","type":"publication"},{"authors":["Dengfeng Li","Wing Lam","Wei Yang","Zhengkai Wu","Xusheng Xiao","Tao Xie"],"categories":null,"content":"","date":1492214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492214400,"objectID":"984c5506afd7c8063fee0efe55794de3","permalink":"http://youngwei.com/publication/hotsos17/","publishdate":"2017-04-15T00:00:00Z","relpermalink":"/publication/hotsos17/","section":"publication","summary":"As mobile apps are increasingly becoming data-driven, these apps tend to collect much app usage data to carry out their promised utilities and enhance user experiences. Unfortunately, some highly sensitive information in the data provides little or no benefit towards delivering the apps’ utilities. For instance, for an app whose purpose is to show video game trailers, it is unnecessary to request and send its users’ phone number and contact list to a remote server. There is a strong need for a framework to help protect users’ app usage data while retaining the app’s utility efficacy (e.g., the number of enabled features). \n \n  There are three main challenges in realizing such framework. First, it is difficult to correctly identify security-sensitive information in the app usage data. For instance, user input text (such as “My password is 12345”) can contain sensitive information, and such framework needs to understand the semantic meaning of such text in order to know whether sensitive information is present or not. Second, because utilities of apps vary dramatically, there is a need for generically applicable program analysis to measure the impact of information anonymization on the level of utility efficacy. Third, balancing privacy preservation and utility efficacy requires fine-grained analysis on privacy specification (such as a privacy policy declared by the app’s developers) and the app. To address these challenges, we propose a privacy framework that enables a mobile app’s developers to determine what sensitive information can be anonymized while maintaining a desirable level of utility efficacy.","tags":null,"title":"Towards Privacy-Preserving Mobile Apps: A Balancing Act. ","type":"publication"},{"authors":["Soteris Demetriou","Whitney Merrill","Wei Yang","Aston Zhang","Carl A. Gunter"],"categories":null,"content":"","date":1481760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481760000,"objectID":"30da4d9c443ecd193ca2d8e6a8f53b08","permalink":"http://youngwei.com/publication/pluto/","publishdate":"2016-12-15T00:00:00Z","relpermalink":"/publication/pluto/","section":"publication","summary":"In this work, we systematically explore the potential reach of advertising libraries through these channels. We design a framework called Pluto that can be leveraged to analyze an app and discover whether it exposes targeted user data—such as contact information, interests, demographics, medical conditions and so on—-to an opportunistic ad library. We present a prototype implementation of Pluto, that embodies novel strategies for using natural language processing to illustrate what targeted data can potentially be learned from an ad network using files and user inputs. Pluto also leverages machine learning and data mining models to reveal what advertising networks can learn from the list of installed apps. We validate Pluto with a collection of apps for which we have determined ground truth about targeted data they may reveal, together with a data set derived from a survey we conducted that gives ground truth for targeted data and corresponding lists of installed apps for about 300 users. We use these to show that Pluto, and hence also opportunistic ad networks, can achieve 75% recall and 80% precision for selected targeted data coming from app files and inputs, and even better results for certain targeted data based on the list of installed apps. Pluto is the first tool that estimates the risk associated with integrating advertising in apps based on the four available channels and arbitrary sets of targeted data.","tags":null,"title":"Free for All! Assessing User Data Exposure to Advertising Libraries on Android","type":"publication"},{"authors":["Xia Zeng","Dengfeng Li","Wujie Zheng","Fan Xia","Yuetang Deng","Wing Lam","Wei Yang","Tao Xie"],"categories":null,"content":"","date":1476489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476489600,"objectID":"d69584865984ae27306f414c4348456d","permalink":"http://youngwei.com/publication/wctester_fse16/","publishdate":"2016-10-15T00:00:00Z","relpermalink":"/publication/wctester_fse16/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Automated Test Input Generation for Android: Are We Really There Yet in an Industrial Case?","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1470960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470960000,"objectID":"0b3a468e04a4e31bdef6adbf7f551054","permalink":"http://youngwei.com/talk/ibm2/","publishdate":"2016-08-12T00:00:00Z","relpermalink":"/talk/ibm2/","section":"talk","summary":"Identifying similar code in software systems can assist many software engineering tasks such as program understanding and software refactoring. While most approaches focus on identifying syntactically similar code (i.e., code that looks alike), Ideally, we would like to also include code that is behaviorally or functionally similar, even if it looks completely different. Detecting these functional clones — code that functions alike — in mobile applications remains an open question because of the difficulty in exposing and comparing programs’ functionality effectively. In this talk, I will present a novel technique that detects functional clones in complex mobile app codebases by identifying and comparing their user interface and key API method calls. The key insight is that user interface usually indicate the functionality to be implemented by a program which complements existing program analysis to detect functional clones.","tags":null,"title":"Searching Functionally Similar Code via UI Prototype.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1468195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1468195200,"objectID":"0ae2e6d056e0acb527f63fb9e16dfec5","permalink":"http://youngwei.com/talk/ibm1/","publishdate":"2016-07-11T00:00:00Z","relpermalink":"/talk/ibm1/","section":"talk","summary":"Numerous apps on the mobile-app market such as team management present opportunities beyond traditional mobile and email communications, greatly enhancing the productivity and mobility of employees in companies. However, these apps may contain unwanted behaviors, such as information leakage and root exploits, and thus violates enterprise security policies. Unwanted behaviors in mobile app can evade detection during app analysis by mimicking security-sensitive behaviors of benign behaviors that provide similar functionality (e.g., sending SMS messages), and suppressing their payload to reduce the chance of being observed (e.g., executing only its payload at night). Since current approaches focus their analyses on the types of security-sensitive resources being accessed (e.g., network), these evasive techniques make differentiating between unwanted and benign app behaviors a difficult task during app analysis. In this talk, I propose that unwanted and benign behaviors within apps can be differentiated based on the contexts that trigger security-sensitive behaviors, i.e., the events and conditions that cause the security-sensitive behaviors to occur. I will first introduce AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. Then, I will introduce WHYPER, a technique that explain why sensitive user information is used by the applications to help users make better decisions in permission granting. Next, I will briefly mention the malware recomposition variation (MRV) technique that can attack the proposed contextually-aware detection technique by systematically producing malware variants. Last, I will give an introduction on Smar (Systematic Mobile App Repair), that iteratively repairs unwanted behaviors at all four levels of granularity (“where”, “when”, “what”, and “how”).","tags":null,"title":"Contextually-Aware Mobile Security: Identification, Variation and Fixing of Mobile Threats.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Dengfeng Li","Huoran Li","Xuanzhe Liu","Haoyu Wang","Yao Guo","Tao Xie"],"categories":null,"content":"","date":1460678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1460678400,"objectID":"ae5d577411751f7d6799770a14d02b1c","permalink":"http://youngwei.com/publication/jcs_journal/","publishdate":"2016-04-15T00:00:00Z","relpermalink":"/publication/jcs_journal/","section":"publication","summary":"Monkey, a random testing tool from Google, has been popularly used in industrial practices for automatic test input generation for Android due to its applicability to a variety of application settings, e.g., ease of use and compatibility with different Android platforms. Recently, Monkey has been under the spotlight of the research community: recent studies found out that none of the studied tools from the academia were actually better than Monkey when applied on a set of open source Android apps. Our recent efforts performed the first case study of applying Monkey on WeChat, a popular messenger app with over 800 million monthly active users, and revealed many limitations of Monkey along with developing our improved approach to alleviate some of these limitations. In this paper, we explore two optimization techniques to improve the effectiveness and efficiency of our previous approach. We also conduct manual categorization of not-covered activities and two automatic coverage-analysis techniques to provide insightful information about the not-covered code entities. Lastly, we present findings of our empirical studies of conducting automatic random testing on WeChat with the preceding techniques.","tags":null,"title":"Security Analytics for Mobile Apps: Achievements and Challenges.","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1458000000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458000000,"objectID":"9b7b1b37f20546dc477b3c31d0d920a4","permalink":"http://youngwei.com/talk/qualcomm2016/","publishdate":"2016-03-15T00:00:00Z","relpermalink":"/talk/qualcomm2016/","section":"talk","summary":"What an application (or “app”) does is not always what a user expects. User expectations stem from user perceptions (information they can perceive about an application). User perceptions come from two sources: app descriptions form user perception before installation, and user interfaces enrich user perception after installation. Two types of inconsistencies, corresponding to each of these sources, contribute to the gap between app behavior and user perception. (1) Install-time inconsistency involves the functionalities described in app descriptions being inconsistent with the actual app behaviors. (2) Run-time inconsistency involves the behavior indicated through user interfaces (external behavior) being inconsistent with the behavior running in the background (internal behavior). In this proposal, we aim to bridge the gap between user perception and app behavior by developing a set of automated analyses to check these two inconsistencies and warn users about potential risks.","tags":null,"title":"Validating Application Behavior against User Expectations.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Benjamin Andow","Sihan Li","Tao Xie","William Enck"],"categories":null,"content":"","date":1450137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450137600,"objectID":"e5f00ebd10d5e66e87712c6477de2c76","permalink":"http://youngwei.com/publication/appcontext/","publishdate":"2015-12-15T00:00:00Z","relpermalink":"/publication/appcontext/","section":"publication","summary":"Mobile malware attempts to evade detection during app analysis by mimicking security-sensitive behaviors of benign apps that provide similar functionality (e.g., sending SMS messages), and suppressing their payload to reduce the chance of being observed (e.g., executing only its payload at night). Since current approaches focus their analyses on the types of securitysensitive resources being accessed (e.g., network), these evasive techniques in malware make differentiating between malicious and benign app behaviors a difficult task during app analysis. We propose that the malicious and benign behaviors within apps can be differentiated based on the contexts that trigger securitysensitive behaviors, i.e., the events and conditions that cause the security-sensitive behaviors to occur. In this work, we introduce AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. We implement a prototype of AppContext and evaluate AppContext on 202 malicious apps from various malware datasets, and 633 benign apps from the Google Play Store. AppContext correctly identifies 192 malicious apps with 87.7% precision and 95% recall. Our evaluation results suggest that the maliciousness of a security-sensitive behavior is more closely related to the intention of the behavior (reflected via contexts) than the type of the security-sensitive resources that the behavior accesses.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context","type":"publication"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1450051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450051200,"objectID":"43931ad1e082b4ea06d1253a2ec361b9","permalink":"http://youngwei.com/talk/sjtu2015/","publishdate":"2015-12-14T00:00:00Z","relpermalink":"/talk/sjtu2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1437091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437091200,"objectID":"5a49ac11d3dc7acda35ec166c074502f","permalink":"http://youngwei.com/talk/sri2015/","publishdate":"2015-07-17T00:00:00Z","relpermalink":"/talk/sri2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context.","type":"talk"},{"authors":["Wei Yang"],"categories":null,"content":"","date":1424995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1424995200,"objectID":"6af637e8f1bec9a513fc4d43ec746c00","permalink":"http://youngwei.com/talk/csl2015/","publishdate":"2015-02-27T00:00:00Z","relpermalink":"/talk/csl2015/","section":"talk","summary":"To keep malware out of mobile application(app) markets, existing techniques analyze the security aspects of app behaviors and summarize patterns of these security aspects to determine what apps do. However, malware and benign apps could present the same behaviors(e.g., sending SMS). The difference is that the behaviors of malware are unexpected while the behaviors of benign apps are expected by users. User expectations (reflected via user perception in combination with user judgment) should be incorporated into security analysis to determine whether app behaviors are within user expectations. This presentation presents our recent work on bridging the semantic gap between user perceptions of the app behaviors and the actual app behaviors.","tags":null,"title":"Improving Mobile Application Security via Bridging User Expectations and Application Behaviors.","type":"talk"},{"authors":["Wei Yang","Xusheng Xiao","Rahul Pandita","William Enck","Tao Xie"],"categories":null,"content":"","date":1397520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1397520000,"objectID":"8d53210094fa198b5526ab40a6c4e515","permalink":"http://youngwei.com/publication/hotsos14/","publishdate":"2014-04-15T00:00:00Z","relpermalink":"/publication/hotsos14/","section":"publication","summary":"To keep malware out of mobile application markets, existing techniques analyze the security aspects of application behaviors and summarize patterns of these security aspects to determine what applications do. However, user expectations (reflected via user perception in combination with user judgment) are often not incorporated into such analysis to determine whether application behaviors are within user expectations. This poster presents our recent work on bridging the semantic gap between user perceptions of the application behaviors and the actual application behaviors.","tags":null,"title":"Improving Mobile Application Security via Bridging User Expectations and Application Behaviors.","type":"publication"},{"authors":["Rahul Pandita","Xusheng Xiao","Wei Yang","William Enck","Tao Xie"],"categories":null,"content":"","date":1387065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1387065600,"objectID":"60b7507c13c0822157cd22272f960284","permalink":"http://youngwei.com/publication/whyper/","publishdate":"2013-12-15T00:00:00Z","relpermalink":"/publication/whyper/","section":"publication","summary":"Application markets such as Apple’s App Store and Google’s Play Store have played an important role in the popularity of smartphones and mobile devices. However, keeping malware out of application markets is an ongoing challenge. While recent work has developed various techniques to determine what applications do, no work has provided a technical approach to answer, what do users expect? In this paper, we present the first step in addressing this challenge. Specifically, we focus on permissions for a given application and examine whether the application description provides any indication for why the application needs a permission. We present WHYPER, a framework using Natural Language Processing (NLP) techniques to identify sentences that describe the need for a given permission in an application description. WHYPER achieves an average precision of 82.8%, and an average recall of 81.5% for three permissions (address book, calendar, and record audio) that protect frequentlyused security and privacy sensitive resources. These results demonstrate great promise in using NLP techniques to bridge the semantic gap between user expectations and application functionality, further aiding the risk assessment of mobile applications.","tags":null,"title":"WHYPER: Towards Automating Risk Assessment of Mobile Applications","type":"publication"},{"authors":["Wei Yang","Mukul Prasad","Tao Xie"],"categories":null,"content":"","date":1360886400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1360886400,"objectID":"99fcd9071b7382bde04ce24d4bb208da","permalink":"http://youngwei.com/publication/orbit/","publishdate":"2013-02-15T00:00:00Z","relpermalink":"/publication/orbit/","section":"publication","summary":"As the mobile platform continues to pervade all aspects of human activity, and mobile apps on this platform tend to be faulty just like other types of software, there is a growing need for automated testing techniques for mobile applications. Model-based testing is a popular and important testing approach which operates on a model of an application’s behavior. However, such a model is often not available or of insufficient quality. To address this issue, we present a novel grey-box approach for automatically extracting a model of a given mobile application. In our approach, static analysis extracts the set of events supported by the Graphical User Interface (GUI) of the application. Then dynamic crawling reverse-engineers a model of the application, by systematically exercising these events on the running application. We also present a tool implementing this approach for the Android platform. Our empirical evaluation of this tool on several Android applications demonstrates that it can efficiently extract compact yet reasonably comprehensive models of high quality for such applications.","tags":null,"title":"A Grey-box Approach for Automated GUI-Model Generation of Mobile Applications","type":"publication"}]